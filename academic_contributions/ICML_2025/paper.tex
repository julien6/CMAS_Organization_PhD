%%%%%%%% ICML 2026 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2026} with \usepackage[nohyperref]{icml2026} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
\usepackage{icml2026}

% For preprint, use
% \usepackage[preprint]{icml2026}

% If accepted, instead use the following line for the camera-ready submission:
% \usepackage[accepted]{icml2026}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}


% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

% ---- Packages ----
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{amsmath, amssymb, amsfonts}
\usepackage{mathtools}
\usepackage{bm}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{hyperref}
\usepackage{cleveref}
% \usepackage{enumitem}
\usepackage[inline, shortlabels]{enumitem}
\usepackage{xcolor}
\usepackage{amsthm}

% ---- Optional: TikZ for figures ----
\usepackage{tikz}
\usetikzlibrary{positioning, arrows.meta, calc}

% ---- Handy commands (edit later) ----
\newcommand{\wm}{\textsc{WM}}
\newcommand{\mawm}{\textsc{MAWM}}
\newcommand{\nsm}{\textsc{NS-MAWM}}
\newcommand{\DecPOMDP}{\textsc{Dec-POMDP}}
\newcommand{\RVR}{\textsc{RVR}}
\newcommand{\KL}{\mathrm{KL}}

% Spell-checker exceptions for acronyms and domain-specific terms
% \usepackage{spellcheck}
% \spellcheck{MAWM,NS-MAWM,gridworld,SMAC,neuro-symbolic}

% --- Tickz
\usepackage{physics}
\usepackage{tikz}
\usetikzlibrary{arrows.meta,positioning,fit,calc}
\usepackage{amsmath}
\usepackage{mathdots}
% \usepackage{yhmath}
\usepackage{cancel}
\usepackage{color}
\usepackage{siunitx}
\usepackage{array}
\usepackage{multirow}
% \usepackage{amssymb}
\usepackage{gensymb}
\usepackage{tabularx}
\usepackage{extarrows}
\usepackage{booktabs}
\usetikzlibrary{fadings}
\usetikzlibrary{patterns}
\usetikzlibrary{shadows.blur}
\usetikzlibrary{shapes}

% ---- Math shortcuts ----
\newcommand{\E}{\mathbb{E}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\I}{\mathbb{I}}

\usepackage{amssymb}
\usepackage{pifont}

\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%

\usepackage[english]{babel}
\addto\extrasenglish{  
    \def\figureautorefname{Figure}
    \def\tableautorefname{Table}
    \def\algorithmautorefname{Algorithm}
    \def\sectionautorefname{Section}
    \def\subsectionautorefname{Subsection}
    \def\proofoutlineautorefname{Proof Outline}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Neuro-Symbolic Multi-Agent World Models}

\begin{document}

\twocolumn[
  \icmltitle{Invariant-Aware Neuro-Symbolic Multi-Agent World Models\\
    for Model-Based Multi-Agent Reinforcement Learning}

  % It is OKAY to include author information, even for blind submissions: the
  % style file will automatically remove it for you unless you've provided
  % the [accepted] option to the icml2026 package.

  % List of affiliations: The first argument should be a (short) identifier you
  % will use later to specify author affiliations Academic affiliations
  % should list Department, University, City, Region, Country Industry
  % affiliations should list Company, City, Region, Country

  % You can specify symbols, otherwise they are numbered in order. Ideally, you
  % should not use this facility. Affiliations will be numbered in order of
  % appearance and this is the preferred way.
  \icmlsetsymbol{equal}{*}

  \begin{icmlauthorlist}
    \icmlauthor{Julien Soulé}{equal,yyy}
    \icmlauthor{Georgios Bakirtzis}{equal,yyy,comp}
    \icmlauthor{Jean-Paul Jamont}{comp}
    \icmlauthor{Firstname4 Lastname4}{sch}
    \icmlauthor{Firstname5 Lastname5}{yyy}
    \icmlauthor{Firstname6 Lastname6}{sch,yyy,comp}
    \icmlauthor{Firstname7 Lastname7}{comp}
    %\icmlauthor{}{sch}
    \icmlauthor{Firstname8 Lastname8}{sch}
    \icmlauthor{Firstname8 Lastname8}{yyy,comp}
    %\icmlauthor{}{sch}
    %\icmlauthor{}{sch}
  \end{icmlauthorlist}

  \icmlaffiliation{yyy}{Department of XXX, University of YYY, Location, Country}
  \icmlaffiliation{comp}{Company Name, Location, Country}
  \icmlaffiliation{sch}{School of ZZZ, Institute of WWW, Location, Country}

  \icmlcorrespondingauthor{Julien Soulé}{julien.soule@hotmail.fr}
  \icmlcorrespondingauthor{Firstname2 Lastname2}{first2.last2@www.uk}

  % You may provide any keywords that you find helpful for describing your
  % paper; these are used to populate the "keywords" metadata in the PDF but
  % will not be shown in the document
  \icmlkeywords{Machine Learning, ICML}

  \vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column listing the
% affiliations and the copyright notice. The command takes one argument, which
% is text to display at the start of the footnote. The \icmlEqualContribution
% command is standard text for equal contribution. Remove it (just {}) if you
% do not need this facility.

% Use ONE of the following lines. DO NOT remove the command.
% If you have no special notice, KEEP empty braces:
\printAffiliationsAndNotice{}  % no special notice (required even if empty)
% Or, if applicable, use the standard equal contribution text:
% \printAffiliationsAndNotice{\icmlEqualContribution}

% ============================
% Abstract
% ============================
\begin{abstract}
  Model-based reinforcement learning enables planning through learned world models, but extending these approaches to multi-agent settings is challenging due to partial observability and error accumulation in joint observation dynamics. Purely neural multi-agent world models often produce semantically inconsistent predictions, violating spatial coherence, object persistence, and interaction constraints.
  We introduce \textbf{Neuro-Symbolic Multi-Agent World Models (NS-MAWM)}, which incorporate symbolic invariants and action-conditioned equivariances as differentiable consistency constraints during world model training. These constraints act as structured inductive biases that reduce long-horizon semantic drift.
  We evaluate NS-MAWM on four representative multi-agent environments with three proposed neuro-symbolic integration strategies. Experimental results show that NS-MAWM improves long-horizon prediction consistency, planning performance, and generalization compared to a purely neural baseline.
\end{abstract}

% ============================
% 1. Introduction
% ============================
\section{Introduction}
\label{sec:intro}

Learning predictive models of environment dynamics, known as \emph{World Models} (WMs)~\cite{ha2018worldmodels}, is a central paradigm in model-based reinforcement learning (MBRL)~\cite{hafner2019learning,hafner2020dreamer,hafner2021dreamerv2}. By encoding the agent's interaction history into a latent space, these models enable imagination-based planning, policy learning, and long-horizon credit assignment~\cite{schrittwieser2020}. Recent progress in this area has shown strong results in single-agent and fully observable environments; however, their extension to multi-agent settings with partial observability remains an open frontier~\cite{Wong2023,Venugopal2024MABL,agravante-etal-2023-learning}.

In such environments, observations typically consist of multiple interacting entities governed by spatial, logical, or physical rules (for instance two agents cannot occupy the same location, objects follow deterministic transitions, etc.). Yet, most world models treat observations as flat, unstructured vectors~\cite{ha2018worldmodels,hafner2019learning}, and learn monolithic latent dynamics end-to-end from raw pixels. This often leads to latent representations that fail to disentangle semantics (such as agent identity, object types) or to reflect the compositional structure of the environment~\cite{kipf2020contrastivelearningstructuredworld,bronstein2021geometric}. As a result, models may produce high-likelihood predictions that are logically inconsistent or physically implausible.

For instance, a trained WM might predict that two agents occupy the same grid cell, violating collision rules. Such symbolic inconsistencies are not penalized by standard likelihood or reconstruction losses, often going unnoticed during evaluation. Worse, these errors compound during long rollouts, degrading planning performance and breaking environment logic~\cite{talvitie2014modelbias,venkatraman2015improving}.

Several works have injected inductive biases into latent representations~\cite{kipf2020contrastivelearningstructuredworld,mondal2022eqr}, but a general framework for integrating symbolic rules into WMs is still facing the following key gaps:
%
\begin{itemize}
  \item[\textbf{G1}] \textbf{Lack of latent representations capturing multi-agent complexity.}
    Most WMs ignore the asymmetry in complex multi-agent settings between easily capturable and difficult-to-capture elements (such as static objects vs. evolving agents). They treat all observations uniformly, neglecting issues such as non-stationarity and partial observability~\cite{zhang2021worldmodelgraph}.

  \item[\textbf{G2}] \textbf{Lack of symbolic rule integration.} Most WMs treat dynamics as fully learnable black-box functions, despite the availability of known rules (such as movement or interaction patterns). While prior work explores logic layers and structured regularization~\cite{dy2018semanticloss, fan2017differentiablelearninglogicalrules}, no unified method integrates symbolic knowledge during training, causing WMs to learn what could be injected as prior structure.

  \item[\textbf{G3}] \textbf{Absence of symbolic evaluation metrics.} Model quality is typically assessed via likelihood, reconstruction error, or downstream task reward. However, these metrics fail to reflect whether predicted trajectories respect symbolic constraints, such as conservation laws or collision rules~\cite{talvitie2014modelbias}.
\end{itemize}

Building on neuro-symbolic integration frameworks~\cite{manhaeve2018deepproblog,garcez2023neurosymbolic,dy2018semanticloss,fan2017differentiablelearninglogicalrules}, we propose \textbf{NS-MAWM} to augment world models with symbolic reasoning through:
%
\begin{itemize}
  \item A \emph{structured latent space} that decomposes observations into typed entities (agents, objects) with interpretable attributes (such as position or type), enabling effective symbolic rule application.

  \item A \emph{symbolic rule formalism} that expresses environment dynamics as differentiable constraints over observations and actions, clearly specifying invariants and action-conditioned equivariances.

  \item Three neuro-symbolic integration strategies:
        \begin{enumerate*}[label={\roman*) },itemjoin={; \quad}]
          \item \textbf{Symbolic Loss Regularization}: rules are encoded as differentiable soft constraints, similarly to semantic loss or logic regularization frameworks
          \item \textbf{Symbolic Projection}: violations are corrected by projecting predictions to valid configurations, ensuring adherence to the defined rules.
          \item \textbf{Residual Symbolic Dynamics}: transitions are factorized into a symbolic process and learned residuals, allowing for a more accurate approach to learning.
        \end{enumerate*}

  \item A \emph{Rule Violation Rate (RVR)} metric that quantifies constraint violations for logical consistency evaluation.
\end{itemize}

We evaluate NS-MAWM across four discrete and continuous environments: a proposed Minecraft-like gridworld, Overcooked~\cite{Micah2020overcooked}, a Predator-Prey environment~\cite{lowe2017multi} and the SMAC environment~\cite{Ellis2023smacv2}. Our comparison includes various integration strategies alongside a vanilla WM baseline, utilizing both standard and symbolic metrics for assessment. The results demonstrate that NS-MAWM not only improves prediction accuracy but also enhances generalization to new configurations, significantly reducing symbolic violations. Among the integration strategies, for similar performance, the residual symbolic dynamics strategy shows the fastest convergence, while the combination of the symbolic loss regularization strategy and the symbolic projection one provide stronger coherence over longer time horizons.

The remainder of the paper is organized as follows: \autoref{sec:related_work} surveys related work, \autoref{sec:method} details NS-MAWM, \autoref{sec:eval} presents experiments, and \autoref{sec:conclusion} concludes.



% ============================
% 3. Related Work
% ============================

\section{Related Work}
\label{sec:related_work}

\paragraph{World Models in Model-Based Reinforcement Learning.} Learning latent dynamics from raw observations enables agents to perform planning through imagined rollouts~\cite{ha2018worldmodels,hafner2019learning,hafner2020dreamer,hafner2021dreamerv2,schrittwieser2020}. Yet, traditional world models often rely on unstructured latent spaces, learning monolithic representations without semantic compositionality. This impairs generalization to novel configurations or long-horizon planning~\cite{kipf2020contrastivelearningstructuredworld,zhang2021worldmodelgraph}.

\paragraph{Multi-Agent World Models.} Extending world models to multi-agent scenarios has been tackled in model-based MARL~\cite{Willemsen2021MAMBPO,Venugopal2024MABL,Xu2022mingling}, with approaches typically assuming centralized training and using shared encoders or joint dynamics models. However, such models struggle to preserve agent identity, handle partial observability, or represent spatial and relational constraints in a modular fashion~\cite{Micah2020overcooked,Ellis2023smacv2,lowe2017multi}. Despite structured settings being common, current approaches offer limited compositionality and poor interpretability across agents.

\paragraph{Symbolic Constraints and Neuro-Symbolic Learning.} Neuro-symbolic systems aim to integrate logical priors into differentiable learning~\cite{manhaeve2018deepproblog,garcez2023neurosymbolic}. Techniques like semantic loss~\cite{dy2018semanticloss} or differentiable logic rules~\cite{fan2017differentiablelearninglogicalrules} encode soft constraints during training, but have rarely been deployed within world models. A few recent efforts~\cite{balloch2023neurosymbolicworldmodelsadapting,agravante-etal-2023-learning} explore neuro-symbolic WMs, yet often use symbolic structure in post-processing or auxiliary training signals rather than integrating rules tightly into latent transition learning.

\paragraph{Structured Inductive Biases and Geometric Constraints.} Imposing equivariance or structure in the latent space has shown promise in enabling sample-efficient and generalizable world models~\cite{mondal2022eqr,park2022learning,bronstein2021geometric,cohen2016group}. These works introduce geometric inductive biases but often stop short of modeling logical constraints or symbolic invariants—such as collision prevention or object permanence—which are essential for multi-agent coherence.

\paragraph{Evaluation of Symbolic Consistency.} Evaluation of WMs typically relies on standard generative metrics: log-likelihood, reconstruction error, or downstream task rewards~\cite{hafner2019learning,schrittwieser2020}. Yet, these fail to detect semantic violations such as agents occupying the same space, or disappearing objects. While some works acknowledge model bias from compounding errors~\cite{talvitie2014modelbias,venkatraman2015improving}, few explicitly evaluate symbolic consistency. Dedicated metrics for symbolic validity remain largely absent from mainstream WM literature.\\

Taken together, these directions reveal three core limitations in the state of the art. First (\textbf{G1}), most world models operate over unstructured latent vectors and lack compositional representations of entities or roles. This prevents modular reasoning and hampers systematic generalization across different agent-object configurations~\cite{zhang2021worldmodelgraph}. Second (\textbf{G2}), although symbolic rules are well studied in logic-guided learning, they are rarely integrated directly into the training of world models. Instead, symbolic knowledge is often applied after rollout or as auxiliary signals, missing the opportunity to shape latent transitions and reduce hallucinations~\cite{dy2018semanticloss,manhaeve2018deepproblog}. Third (\textbf{G3}), the evaluation of WMs remains largely statistical or reward-based, without metrics that assess whether predictions obey known symbolic constraints (e.g., conservation laws, action-conditioned transitions). Without such metrics, progress on semantically coherent modeling remains difficult to quantify.


\section{Background and basics}
\label{sec:background}

\subsection{MARL framework}
\label{sec:decpomdp}

TODO

\subsection{Model-Based MARL}
\label{sec:mb-marl}

TODO

\subsection{From World Models to Multi-Agent World Models}
\label{sec:mawm}

TODO


% ============================
% 4. Method: Neuro-Symbolic MA World Models
% ============================


\section{Neuro-Symbolic Multi-Agent World Models}
\label{sec:method}

We propose \emph{Neuro-Symbolic Multi-Agent World Models (NS-MAWM)}, a framework... TODO

\include{figures/method_figure}

\subsection{Structured observation latent space and unified neuro-symbolic formalism}
\label{sec:ns}

TODO

\subsection{The three neuro-symbolic integration strategies}
\label{sec:integration_strategies}

\subsubsection{The symbolic loss regularization strategy}
\label{sec:symbolic_loss_regularization}

TODO

\subsubsection{The symbolic projection strategy}
\label{sec:symbolic_projection}

TODO

\subsubsection{The residual symbolic dynamics strategy}
\label{sec:residual_symbolic_dynamics}

TODO

\subsection{Rule Violation Rate (RVR)}
\label{sec:rvr}

TODO

\subsection{NS-MAWM global algorithm}
\label{sec:algo}

TODO

% ============================
\section{Evaluation}
\label{sec:eval}

This section evaluates... TODO

\subsection{Implementation}
\label{sec:impl_overview}

TODO...

\subsection{Environments and rule sets}
\label{sec:envs}

We consider two classes of environments: ... TODO

\subsection{Computing resources and hyperparameters}
\label{sec:resources}

TODO

\subsection{Evaluation metrics, baselines and protocol}
\label{sec:metrics_baselines_protocol}
% Comment on fait pour évaluer que NS-MAWM est mieux que les autres et permet d'atteindre les objectifs fixés dans l'intro :
%  - est-ce qu'on prend mieux en compte l'aspect multi-agent ?
%  - est-ce qu'on réduit le drift sémantique sur le long terme grâce à l'intégration symbolique ? Si oui, comment ?
%  - est-ce que ça améliore la performance en planification / RL downstream ?
%  - est-ce que ça améliore la généralisation à de nouvelles configurations d'agents/objets ?
%  - est-ce que ça améliore l'efficacité des données (moins de données nécessaires pour atteindre une certaine performance) ?
%  - est-ce qu'on peut faire une ablation pour montrer l'importance de chaque composant (invariants vs equivariances, stratégies d'intégration, etc.) ?
%  - est-ce qu'on peut tester la robustesse aux règles incomplètes ou incorrectes ?
%  - est-ce qu'on peut tester la scalabilité avec le nombre d'agents/règles ?
%  - est-ce qu'on peut évaluer correctement les performances avec des métriques symboliques (RVR) en plus des métriques classiques (log-likelihood, erreur de reconstruction, récompense downstream) ?

% 1) donner les métriques utilisées
% 2) présenter les baselines comparées pour permettre d'évaluer l'apport de NS-MAWM
% 3) expliquer le protocole expérimental (nombre de seeds, durée d'entraînement, etc.) afin de fournir un moyen scientifique de voir si on couvre bien les gaps identifiés dans l'intro en faisant le lien avec les métriques et baselines via le protocole expérimental

TODO

\subsection{Results}
\label{sec:results}

TODO

% ============================
% 7. Conclusion
% ============================
\section{Conclusion and future work}
\label{sec:conclusion}

This paper addressed a fundamental limitation of multi-agent world models: while neural world models can achieve strong short-horizon prediction accuracy, they often fail to preserve semantic consistency under long-horizon rollouts, particularly in partially observable multi-agent settings.
We introduced \textbf{Neuro-Symbolic Multi-Agent World Models (NS-MAWM)}, a framework that integrates symbolic invariants and action-conditioned equivariances as soft, differentiable consistency constraints during world model training.
By treating symbolic knowledge as an inductive bias rather than a hard restriction, NS-MAWM reduces semantic drift while preserving uncertainty and flexibility.

Empirically, we demonstrated that NS-MAWM substantially improves long-horizon semantic consistency, as measured by the proposed Rule Violation Rate (RVR), while maintaining comparable one-step predictive accuracy.
Across controlled gridworld environments and a standard multi-agent benchmark, these improvements translated into more reliable imagination rollouts, improved downstream planning performance, and higher data efficiency.
Ablation studies further showed that both invariants and equivariances contribute to performance, and that uncertainty-aware gating is critical in stochastic or partially observable regimes.

Beyond the specific instantiation presented in this work, NS-MAWM opens several promising research directions.
First, richer rule languages could be explored, including relational, temporal, or probabilistic rules that capture higher-level interaction patterns.
Second, while we focused on soft consistency constraints, investigating hybrid approaches that combine soft regularization with occasional hard projection or constraint satisfaction may further improve robustness.
Third, evaluating neuro-symbolic world models in more complex environments—such as continuous control, heterogeneous agent populations, or large-scale coordination tasks—remains an important step toward real-world applicability.

Another key direction concerns the source and reliability of symbolic knowledge.
In this work, rules were specified manually, which is appropriate for controlled settings but may not scale.
Future work could explore learning rules directly from data, combining representation learning with structure discovery, or adapting rules online as the environment changes.
Handling partial, incorrect, or conflicting rules, as well as stochastic events that temporarily violate invariants, is another important challenge.
The proposed gating mechanism is a first step in this direction, but more principled uncertainty-aware or Bayesian treatments are worth exploring.

Finally, scalability and transfer remain open questions.
As the number of agents or rules increases, efficient rule evaluation and selection becomes critical.
Investigating modular rule sets, rule sharing across agents, and transfer of learned constraints across domains may significantly broaden the applicability of neuro-symbolic world models.

\paragraph{Take-home message.}
Semantic consistency is a first-class requirement for reliable multi-agent world models.
By integrating neuro-symbolic consistency constraints into model-based MARL, NS-MAWM provides a principled and effective way to reduce long-horizon drift, improve interpretability, and enhance downstream decision-making.
We hope this work encourages further research at the intersection of world modeling, multi-agent systems, and neuro-symbolic learning.


\section*{Impact Statement}

This paper presents work whose goal is to advance the field of Machine Learning by improving the reliability of model-based multi-agent reinforcement learning.
By reducing semantic inconsistencies in learned world models, this work may contribute to safer and more interpretable decision-making in multi-agent systems.
We do not identify ethical concerns specific to this work beyond those commonly associated with reinforcement learning research.


% ============================
% Acknowledgements (remove for submission if needed)
% ============================
% \section*{Acknowledgements}

% ============================
% References
% ============================
\bibliography{references}
\bibliographystyle{icml2026}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\appendix

\section{Rule Set Details}
\label{app:rules}
% TODO:
% - list rules formally
% - applicability masks
% - examples

\section{Additional Experimental Results}
\label{app:more}
% TODO:
% - ablations, extra environments, hyperparams

\section{Architectures and Hyperparameters}
\label{app:hparams}
% TODO:
% - full hyperparam tables

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
