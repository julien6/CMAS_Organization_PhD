\AtBeginSection[]{
    \begin{frame}
        \frametitle{}
        \tableofcontents[currentsection]
    \end{frame}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{AOMEA approach}

\subsection{Overview}

\begin{frame}{AOMEA approach}{Overview}

    \begin{figure}[h!]
        \centering
        \include{figures/approach}
        \caption{A summary view of our approach to MAS design}
        \label{fig:design_approach}
    \end{figure}

    We introduce AOMEA as an approach for MAS design that automates the preliminary design of a MAS according to some design constraints. Organizational specifications obtained after training allow the development of a curated MAS.
    The underlying idea of our approach is to consider that a joint-policy or joint-history can be described in terms of organizational specifications, at least partially.
    We refer to that broad approach as \textquote{Organization oriented MARL} (OMARL).
    %
    % As a high-level description, AOMEA considers the environment with agents that are to achieve some goals. It automatically enables finding relevant insights under the form of organizational specifications. They are to transparently express how agents could individually act and collaborate to reach the goals. Then, the MAS design process can be assisted in light of these indications. An illustrative representation of our approach is presented in \autoref{fig:design_approach}.
    %
    AOMEA consists of 4 sequential phases: modeling, solving, analyzing, and developing (respectively $1.x$, $2.x$, $3.x$, $4.x$ in arrow labels in \autoref{fig:design_approach}).

    \textbf{Phase 1: Modeling} \quad In that phase, the designer has to manually develop a simulation of the target environment ($1.1$ in \autoref{fig:design_approach}) where agents must cooperate to achieve the designer's goal efficiently ($1.2$ in \autoref{fig:design_approach}) with the help of quantitative feedback. When developing the simulated environment, the designer can link parts of an agent's policy (as observations-actions couples) with known organizational specifications of any chosen organizational model.
    For instance, in \textquote{leader-follower} organizations, the actions that send orders to other follower agents, are characteristics of leader agents.
    Optionally, the designer may also want to restrict the set of possible policies agents can explore regarding given organizational specifications as constraints to meet design requirements or to help agents converge as well ($1.3$ in \autoref{fig:design_approach}).

    \textbf{Phase 2: Solving} \quad In that phase, relying on the established relations between observation-action couples and organizational specifications, a MARL algorithm is used jointly with the chosen MAS organizational model through an OMARL process. It automatically enables finding optimal policies satisfying the given design organizational specifications ($2.1$ in \autoref{fig:design_approach}) that lead to the best expected cumulative reward; and getting the associated organizational specifications ($2.2$ in \autoref{fig:design_approach}). For instance, when training agents regarding the \textquote{leader-follower} organization, some agents may be forbidden to send orders while some other may be forced to. After training, the OMARL process characterizes emergent roles, links between roles, or sub-goals organized in plans to reach the goal.

    \textbf{Phase 3: Analyzing} \quad In that phase, the designer observes the trained agents' policies ($3.2$ in \autoref{fig:design_approach}) and takes into account the inferred associated organizational specifications ($3.1$ in \autoref{fig:design_approach}) to understand how these agents can reach the goal. In light of these raw results, the designer can extract valuable design patterns from noisy or useless agents' decisions. The interest is to provide at least some indications of the organizational specifications capable of achieving the goal and to satisfy the design constraints. We refer to these valuable indications as curated organizational specifications ($3.3$ in \autoref{fig:design_approach}). For instance, after having trained several agents in a \textquote{predator-prey} environment, it is possible to analyze that a \textquote{leader} predator with \textquote{follower} predators, appears to be more efficient for catching prey.

    \textbf{Phase 4: Developing} \quad In that phase, the designer takes into account the curated organizational specifications as a blueprint for implementing a MAS. From that point, a regular MAS development with one of the available methods that is used jointly with the chosen organizational model can be applied. Unlike the trained agents which may cause unexpected behavior, manually implemented agents enable giving safety guarantees required for sensitive environments. Finally, implemented agents are launched in simulations to assess whether the implemented MAS can effectively achieve the goal.

\end{frame}


\subsection{Theoretical core}

\begin{frame}{AOMEA approach}{Overview}


    To implement an OMARL process, we propose the \emph{Partial Relations with Agent History and Organization Model} algorithm (PRAHOM) to link agents' policies and their training to an organizational model.
    It is a synthesis of two processes that fall into the OMARL purposes. The first process gets the specifications from the agents' policies, and the second process gets the joint-policies satisfying the given design specifications. An illustrative view of \emph{PRAHOM} is given in \autoref{fig:prahom_process}.
    Here we just present the underlying idea at a high-level description for these two processes to avoid unnecessary formalism. More information on the use and implementation of \emph{PRAHOM} can be found in \autoref{PettingZoo-wrapper}.
    % Since \emph{PRAHOM} relies on joint-histories instead of joint-policies, it is agnostic of the approximation function used for implementing the agents' policies such as neural networks based ones

    \begin{figure}[h!]
        \centering
        \include{figures/prahom_process}
        \caption{A summary view of the PRAHOM process}
        \label{fig:prahom_process}
    \end{figure}


    \textbf{Inferring Organizational Specifications}

    Rather than using joint-policies directly, we use the joint-histories since they may be built with observed resulting actions when observations are received during a series of test episodes. Indeed, for a given policy $\pi \in \Pi$, the associated history is by definition $h \in h_{joint} = \langle(\omega_k,a_k) | k \in \mathbb{N}\rangle$ and the $(\omega_k,a_k) \in \pi$.
    Then, due to the difficulty of inferring information related to organizational specifications, it is possible to associate each observation or action with organization specifications as a \textquote{many to many} relation. It sets up a first frame for identifying organizational specifications in histories. We address that problem in the remainder of this section.

    One can define some relations between $\mathcal{M}OISE^+$ specifications and joint-histories. Their premises come from noticing some specifications in the $\mathcal{M}OISE^+$ organizational model can be mapped to subsets of actions from a single suboptimal joint-policy.
    From these relations, it is possible to use empirical or statistical approaches to infer organizational specifications out of joint-histories. Below we informally describe key points for understanding that process.

    As we have only one group, we do not consider the inter-links and inter-compatibilities. Additionally, as a simplification, we consider only one social scheme.
    First, we look at the individual level by trying to figure out the roles, links, sub-groups, individual goals, missions, and plans played by agents by sampling history subsequences $h \in H$ and comparing with known history subsequences whose we know the associated role via the established relations.

    After analyzing several joint-policies, we try to reinforce a global view of the goals, missions, plans, and the knowledge of the mission to the goal; with the partially inferred information at the individual level.
    In the end, our process tries to synthesize the knowledge inferred until having a better view of the agent cardinality per sub-group, the agent cardinality for each mission, the role cardinality, the compatibilities between roles, the permissions, and obligations.

    \textbf{Constraining Policies Space}

    We consider a given MARL algorithm that iteratively converges towards a joint-policy so that each agent's policy is updated at each step until a finite horizon.
    We favored the Proximal Policy Optimization for its proven effectiveness in cooperative multi-agent environments without the need for domain-specific algorithmic modifications or architectures~\cite{Yu2022}.
    To constrain the possible joint-policies to the ones satisfying the design organizational specifications $os_{init}$, we propose to constrain the action and observation sets for each agent according to $os_{init}$ at each step. Ultimately, it constrains an agent to a role by forbidding actions related to other roles.

    First, we use the established relations between organizational specifications and action-observation couples, to determine the authorized or forbidden actions playable by agents at each step.
    Then, it first computes the authorized actions set $A_{step}$ according to the current history $h_{joint,i}$. Then, an action is chosen among authorized actions. That action $a_{step} \in A_{step}$ is added in history to be used for updating the agent's policy in the next step. Then, the MARL algorithm updates the joint-policy hence the agents' policies with the current action and observation.
    Finally, an analysis of the current suboptimal joint-policy $\pi_{joint}$ satisfying $os_{init}$ is triggered periodically. It enables iteratively improving the efficiency of joint-policies and the accuracy of the inferred organizational specifications.
    We can note the restriction implied by $os_{init}$ in the possible joint-policies might prevent the MARL algorithm from finding a joint-policy that satisfies the minimal expected cumulative reward defined by the designer.

\end{frame}


\subsection{Engineering tool}

\begin{frame}[fragile]{AOMEA approach}{Engineering tool}


    PettingZoo is a library that offers a standardized API that simplifies the development of environments with agents and facilitates the application of MARL algorithms.
    We developed \emph{PRAHOM PettingZoo Wrapper}\label{PettingZoo-wrapper}, a tool to help automate the setting up of \emph{PRAHOM} for a given PettingZoo environment.
    It is a \emph{PoC} linking joint-histories with $\mathcal{M}OISE^+$ specifications to provide functions to infer raw organizational specifications or constrain the training.

    \begin{lstlisting}[language=Python, caption=PRAHOM PettingZoo Wrapper basic use, label={lst:wrapper_basic_use}]
    from omarl_experiments import prahom_wrapper
    env=PettingZoo_env.parallel_env(render_mode="human")
    specs_to_hist={"structural_specifications":{"roles":{"follower":{"23":41,"14":[74,0]}}...},"functional_specifications":{"links":{"(leader,follower,aut)":".*14.*?89"}...}...}
    policy_specs_constr={"agent_0":{"structural_specifications":"roles":["follower"]}}
    env=prahom_wrapper(env,action_to_specs,training_specs)
    env.train("default_PPO")
    trained_specs,agent_to_specs=env.prahom_specs()
    \end{lstlisting}

    In \autoref{lst:wrapper_basic_use}, we detailed a basic use of the wrapper to augment a PettingZoo environment (l. 5) with known relations between histories and organizational specifications (l. 3) and the design constraints agents are to satisfy (l. 4).
    During training, \textquote{"agent\_0"} is constrained to role \textquote{follower} so all of its actions must be chosen regarding the relations between organizational specifications and expected histories (or shortened histories expressions).
    After training, \emph{PRAHOM PettingZoo Wrapper} infers organizational specifications from joint-histories in 5 episodes, and the agents' instantiation for each one (l. 7).

    This process first uses known relations between histories and organizational specifications (l. 3): an agent's history that contains the observation $14$ (\textquote{order received}) and the action $74$ (\textquote{apply order}) or $0$ (\textquote{do nothing}), is a \textquote{follower}. Similarly, history can be linked to organizational specifications with regular expressions such as for \emph{links} (l.3).
    Then, it generalizes several joint-histories as new organizational specifications relying on their respective general definition.
    %
    For instance, a role is thought to be inferred by measuring similarity between histories in several ways: sequence clustering (with a dendrogram); K-nearest neighbors (with PCA of histories); statistical analysis (specially action frequency in various visualizations); etc.
    %
    Techniques are also used to infer goals: frequency analysis of common observations of agents with the same role; analysis of threshold states triggering an improvement of the reward (with a state transition graph).

    From the roles and goals obtained, an empiric approach allows inferring the other organizational specifications such as compatibilities, permissions and obligations.
    Due to that empiric approach and the specific scope of the techniques, results may be incomplete or noisy. Yet, since results are compliant with $\mathcal{M}OISE^+$, it is possible to use them in MAS design methods in light of the identified organizational specifications.

\end{frame}
