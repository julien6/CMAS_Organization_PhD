%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% LaTeX Template for ECAI Papers 
%%% Prepared by Ulle Endriss (version 1.0 of 2023-12-10)

%%% To be used with the ECAI class file ecai.cls.
%%% You also will need a bibliography file (such as mybibfile.bib).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Start your document with the \documentclass{} command.
%%% Use the first variant for the camera-ready paper.
%%% Use the second variant for submission (for double-blind reviewing).

% \documentclass{ecai} 

\documentclass[doubleblind]{ecai}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Load any packages you require here. 

\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
% \usepackage{enumitem}
\usepackage{graphicx}
\usepackage{color}

\usepackage[T1]{fontenc}
\usepackage{graphicx}
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}

\usepackage{amsmath,amssymb,amsfonts}
\usepackage[inline, shortlabels]{enumitem}
\usepackage{tabularx}
\usepackage{caption}
% \usepackage{titlesec}
\usepackage[english]{babel}
\captionsetup{font=it}
\usepackage{ragged2e}
\usepackage{hyperref}
\usepackage{pifont}
\usepackage{footmisc}
\usepackage{multirow}
\usepackage{algorithm2e}

% --- Tickz
\usepackage{physics}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{mathdots}
\usepackage{yhmath}
\usepackage{cancel}
\usepackage{color}
\usepackage{siunitx}
\usepackage{array}
\usepackage{multirow}
\usepackage{amssymb}
\usepackage{gensymb}
\usepackage{tabularx}
\usepackage{extarrows}
\usepackage{booktabs}
\usetikzlibrary{fadings}
\usetikzlibrary{patterns}
\usetikzlibrary{shadows.blur}
\usetikzlibrary{shapes}

% ---------

\usepackage{pdfpages}
\usepackage{booktabs}
\usepackage{csquotes}
\usepackage{lipsum}  
\usepackage{arydshln}
\usepackage{smartdiagram}
\usepackage[inkscapeformat=png]{svg}
\usepackage{textcomp}
\usepackage{tabularray}\UseTblrLibrary{varwidth}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
% \usepackage{cite}
\usepackage{amsmath}
\newcommand{\probP}{\text{I\kern-0.15em P}}
\usepackage{etoolbox}
\usepackage{listings}
\usepackage{etoolbox}
\patchcmd{\thebibliography}{\section*{\refname}}{}{}{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Define any theorem-like environments you require here.

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{definition}{Definition}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Define any new commands you require here.

% \newcommand{\BibTeX}{B\kern-.05em{\sc i\kern-.025em b}\kern-.08em\TeX}

\setlength\tabcolsep{0.5pt}

\newcommand{\before}[1]{\textcolor{red}{#1}}
\newcommand{\after}[1]{\textcolor{green}{#1}}

\newcommand{\old}[1]{\textcolor{orange}{#1}}
\newcommand{\rem}[1]{\textcolor{red}{#1}}
\newcommand{\todo}[1]{\textcolor{orange}{\newline \textit{\textbf{TODO:} #1}} \newline \newline }


\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
 
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
 
\lstset{style=mystyle}


\newcounter{relation}
\setcounter{relation}{0}
\renewcommand{\therelation}{\arabic{relation}}
\newcommand{\relationautorefname}{Relation}

\newenvironment{relation}[1][]{%
    \refstepcounter{relation}%
    \noindent \raggedright \textit{\textbf{Relation. \therelation}} \hfill$}
{%
$ \hfill \phantom{x}

}

\newcounter{proof}
\setcounter{proof}{0}
\renewcommand{\theproof}{\arabic{proof}}
\newcommand{\proofautorefname}{Proof}

\renewenvironment{proof}[1][]{
    \refstepcounter{proof}
    \noindent \raggedright \textit{\textbf{Proof. \theproof}}

    \setlength{\leftskip}{1em}

}
{

\
\setlength{\leftskip}{0pt}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frontmatter}

    %%% Use this command to specify your submission number.
    %%% In doubleblind mode, it will be printed on the first page.

    \paperid{10}
    %%% Use this command to specify the title of your paper.

    \title{Towards Assisted MAS Design: A Library for Explainable MARL with Organizational Model}

    % JS: keywords:
    %     Multi-Agent Reinforcement Learning
    %     Explainability
    %     Organizational Models
    %     Cooperative Intelligence

    %%% Use this combinations of commands to specify all authors of your 
    %%% paper. Use \fnms{} and \snm{} to indicate everyone's first names 
    %%% and surname. This will help the publisher with indexing the 
    %%% proceedings. Please use a reasonable approximation in case your 
    %%% name does not neatly split into "first names" and "surname".
    %%% Specifying your ORCID digital identifier is optional. 
    %%% Use the \thanks{} command to indicate one or more corresponding 
    %%% authors and their email address(es). If so desired, you can specify
    %%% author contributions using the \footnote{} command.

    \author[A,B]{\fnms{Julien}~\snm{Soulé}\thanks{Corresponding Author. Email: julien.soule@lcis.grenoble-inp.fr}}
    \author[A]{\fnms{Jean-Paul}~\snm{Jamont}}
    \author[A]{\fnms{Michel}~\snm{Occello}}
    \author[B]{\fnms{Louis-Marie}~\snm{Traonouez}}
    \author[C]{\fnms{Paul}~\snm{Théron}}

    \address[A]{Univ. Grenoble Alpes, Grenoble INP, LCIS, 26000, Valence, France}
    \address[B]{Thales Land and Air Systems, BL IAS, Rennes, France}
    \address[C]{AICA IWG, La Guillermie, France}

    %%% Use this environment to include an abstract of your paper.

    \begin{abstract}
        % Context
        Designing a MAS requires searching for an organization as a set of agents' policies that allow achieving a goal under given or environmental constraints with collaboration mechanisms to be described.
        %
        % Issue        
        An empirical approach to finding a suitable organization in some environments usually relies on a trial and error process which may prove costly to converge towards an adequate MAS. Both the environment's limitations such as high complexity, or dimensionality, and the designers' limitations such as access time or experimentation constraints may hinder an efficient design process.
        % Contribution
        We propose the \emph{PRAHOM Wrapper} which augments the \emph{PettingZoo}simulation framework to enable both automatically finding suited agents' policies satisfying design constraints through MARL, and explicating the emerging organizational mechanisms into organizational specifications likely to guide the design towards a suitable interpretable MAS.
        % Results
        Empirical evaluations conducted in a cooperative Atari-like game environment show alignment with hand-crafted expectations.
        
    \end{abstract}

\end{frontmatter}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

% Context:
The Multi-Agent System (MAS) design requires designers to have specific knowledge of the deployment environment to propose agents' internal logic likely to allow them collectively to achieve the given objective.
%
The designers' knowledge may prove limited due to the complexity of the environment; or due to access constraints (temporal, spatial, or legal) limiting the possibilities of its empirical understanding.

Designing a MAS can be seen through the \textbf{organization} which we see as the set of \textbf{policies} of the agents
\footnote{For an agent, a policy is a relation between observations and actions.}
considered both from an individual point of view and from a global point of view. The organizational mechanisms induced by these policies can be explained through \textbf{organizational models}.

The design of a MAS then becomes the search for an organization allowing the given objective to be achieved adequately under environmental constraints.
Even if most design methods such as GAIA~\cite{Cernuzzi2014} or KB-ORG~\cite{Sims2008} facilitate the search for an adequate organization for a given environment and objective~\cite{Mefteh2013}; they do not make it possible to fully automate the search for agent policies satisfying the given requirements and explaining the organization.

We propose \emph{PRAHOM Wrapper} (Partial Relations with Agent History and Organization Model Wrapper), a software layer for the Multi-Agent simulation framework \emph{PettingZoo} which allows to:
%
i) Train agent policies to achieve a given objective in an environment and respecting possible Organizational Specifications (OS);\quad
ii) Determine organizational specifications %\MO: from%
by analyzing the behavior of trained agents.
%
It combines a MARL (Multi-Agent Reinforcement Learning) process with the $\mathcal{M}OISE^+$~\cite{Hubner2007} organizational model.

Section II provides an overview of the \emph{PRAHOM Wrapper} positioning among related works.
Section III presents the functionalities offered by \emph{PRAHOM Wrapper} and its use in an Atari game-like environment.
Section IV concludes on \emph{PRAHOM Wrapper} by discussing its limitations and future work.

% ==================================================== = ==================================================== == =


\section{Related works and positioning}

MARL is a machine learning paradigm where agents learn to make decisions by interacting with an environment. The goal is for a set of agents to maximize the cumulative reward over time through a process of trial and error.
MARL makes it possible to automatically converge towards policies enabling the given objective to be achieved. Reinterpreting these individual policies into organizational specifications requires work on explainability at a collective level that is rarely addressed in the literature.

\paragraph{\textbf{Frameworks for MARL with organizational aspects}}
%
Some proposed frameworks attempt to include organizational concepts within the MARL framework.
Kazhdan and. al.~\cite{Kazhdan2020} present a library to improve the explainability of MARL systems by bringing them closer to symbolic models, in particular to infer roles.%todo
%
Wang et. al.~\cite{Wang2020} introduce an approach in which similar emerging roles are pushed to jointly specialize on specific tasks.

\paragraph{\textbf{Characterization of emerging collective strategies}}
%
Heuillet and. al.~\cite{Heuillet2022} propose an approach to explain cooperative strategies using Shapley values. Its effectiveness has been shown in the context of applications on multi-agent particle environments by explaining certain decisions taken.
%
Jaques and. al.~\cite{Jaques2019} propose a mechanism to benefit from communication between agents by rewarding agents having a causal influence on other agents. This approach leads to learned communication protocols allowing for overall more efficient collective behavior.

\paragraph{\textbf{Adaptation of MARL to meet requirements}}
%
\emph{Specification-Guided Reinforcement Learning} aims to generate policies that accomplish a specific task using external specifications to guide learning in achieving an objective under given constraints~\cite{Bansal2022}.% ~\cite{Jothimurugan2023}%
%
~Jothimurugan et. al.~\cite{Jothimurugan2021} propose logical specification learning as exploiting the compositional structure of specifications to generate policies for complex tasks.

\

Unlike these works, our originality is to explicitly use an organizational model as a general means of expressing policies at a collective level and/or constraining their learning regarding requirements.


% ==================================================== ===========================

\section{\emph{PRAHOM Wrapper}}

\subsection{Overview}

\begin{figure}[h!]
\centering
\input{figures/prahom_wrapper.tex}
\caption{Technical view of \emph{PRAHOM Wrapper}}
\label{fig:prahom_wrapper_technical_view}

\

\phantom{X}

\

\end{figure}

% As part of the development of the CybMASDE simulation tool,
% \footnote{\emph{Cyberdefense Multi Agent System Development Environment} is a simulator for Cyberdefense MAS available at \url{https://github.com/julien6/CybMASDE}}
\emph{PRAHOM Wrapper}\label{PettingZoo-wrapper}
\footnote{Additional information on \emph{PRAHOM Wrapper} and an interactive demo are available at: \url{https://github.com/julien6/omarl_experiments}}
was developed as a \emph{PoC} design support tool on a \emph{PettingZoo} environment by linking \textbf{histories}\footnote{A history is an n-tuple of (observation, action)} from agent to $\mathcal{M}OISE^+$ specifications. \emph{PettingZoo} is a library that offers a standard API simplifying the development of multi-agent environments and facilitating the application of MARL algorithms. An overview of the technical operation is given in \autoref{fig:prahom_wrapper_technical_view}.
%Through a case study, we propose to present the functions to extract the resulting suboptimal raw organizational specifications. Likewise, during training, we present the integration of constraints on the observations received and the actions taken.

A \emph{PettingZoo} environment implements the Markovian model \emph{Dec-POMDP} (Decentralized-Partially Observable Markov Decision Process)~\cite{Oliehoek2016} allowing the application of MARL techniques.
We call \textbf{solve}/\textbf{solve sub-optimally} the Dec-POMDP for a team, the search for a joint policy ($\Pi_{joint}$) allowing to maximize/exceed a cumulative reward threshold on a finite horizon (\textquote{Training} in \autoref{fig:prahom_wrapper_technical_view}). For this, the \emph{Proximal Policy Optimization} (PPO) algorithm was integrated via the \emph{Stable BaseLines3} library and taking into account possible designer constraints (by external correction, learning, or internal policy modification).


To explain the joint policy, \emph{PRAHOM Wrapper} analyzes the joint histories of the $H_{joint}$ agents to generate organizational specifications. For this, several techniques are available (sequence clustering, frequency analysis, sub-sequence identification\dots) to which figures and supports are associated (Principal Component Analysis - PCA, dendrogram\dots)
% \jp{I think you haven't already talked about principal component analyses}.
% js: I tell myself that an ACP is something quite well known all the same...

% Based on \emph{PRAHOM Wrapper}, the \emph{PRAHOM} algorithm allows you to:
% i) \textbf{Determine organizational specifications} of $\mathcal{M}OISE^+$ by analyzing the agents' histories after (sub-optimal) resolution;
% ii) \textbf{Constrain joint policies} to those satisfying the organizational specifications of $\mathcal{M}OISE^+$.


% Indeed, a \emph{Dec-POMDP} considers several agents in a way similar to a MAS. It makes it possible to model the uncertainty of the environment for the changes induced by the actions and the observations received. Its reward function is common to agents, which promotes the formation of actions oriented towards collaboration~\cite{Beynier2013}.

% Formally, a Dec-POMDP is a 7-tuple $(S,\{A_i\},T,R,\{\Omega_i\},O,\gamma)$ , where: $S = \{s_1, . . s_{|S|}\}$ is the set of possible states; $A_{i} = \{a_{1}^{i},..,a_{|A_{i}|}^{i}\}$ the set of possible actions for the agent $i$; $T$ so that $T(s,a,s') = \probP{(s'|s,a)}$ the set of conditional transition probabilities between states; $R: S \times A \times S \rightarrow \mathbb{R}$ the reward function; $\Omega_{i} = \{o_{1}^{i},..,o_{|\Omega_{i}|}^{i}\}$ the set of observations for the agent $ag_i $ ; $O$ so that $O(s',a,o) = \probP{(o|s',a)}$ the set of conditional observation probabilities; $\gamma \in [0,1]$, the discount factor.


\subsection{Toy environment: \emph{Moving Company}}

We imagined and developed the Atari-like game environment \emph{Moving Company} illustrated in \autoref{fig:env_moving_company}.
It consists of moving agents that must collaborate to move a package from a starting cell to a final cell as quickly as possible. Agents can move except in the drop-off zones (in orange in \autoref{fig:env_moving_company}) but can pick up and drop off the package there. All observations and actions are \emph{one-hot} encoded. This environment is designed to be simple while having the advantage of bringing into play organizational mechanisms that can be evaluated manually.
The \emph{PRAHOM Wrapper} code used for \emph{Moving Company} is summarized in \autoref{lst:wrapper_mc}.

\begin{figure}[h!]
\centering
\includegraphics[width=0.154\textwidth]{figures/moving_company_1.png}
\includegraphics[width=0.154\textwidth]{figures/moving_company_2.png}
\includegraphics[width=0.154\textwidth]{figures/moving_company_3.png}
\caption{Visual renderings of \emph{Moving Company} with three moving agents and a package.}
\label{fig:env_moving_company}

\

\end{figure}

\section{Using \emph{PRAHOM Wrapper}}

Given the \emph{Moving Company} environment, \emph{PRAHOM Wrapper} is used following two sequential optional steps to integrate constraints, and two sequential steps to get the full organizational specifications describing the solution found after training.

\subsection{Setup and configuration}

In this step, we prepare the use of \emph{PRAHOM Wrapper} (yellow boxes in \autoref{fig:prahom_wrapper_technical_view}).
After instantiating the \emph{Moving Company} environment (line 1), we define some known relationships between sub-histories and known organizational specifications (lines 2, 3, and 4). Likewise, we define organizational constraints (line 5). Then, \emph{PRAHOM Wrapper} wraps the environment with any relationships and pre-established constraints (line 9). Constraints and relationships can be mappings or functions to the extent that both associate an agent with its constraints and history with known organizational specifications, respectively.

The designer can also modify the default values relating to the modes of compliance with constraints, the methods used for historical analysis, the different expected organizational specifications, and the figures and supports associated with the generated specifications.

\subsection{Constrained training of agents}

The designer can then classically proceed with learning in the enveloped environment. Otherwise, it can use the integrated PPO algorithm (green box in \autoref{fig:prahom_wrapper_technical_view}). We use this functionality (line 10) with the default setting: an indefinite number of iterations, a learning time of 1 hours, centralized learning and decentralized execution mode, no optimization of hyper-parameters, saving the best policy and restoring from the last checkpoint if it exists.
\emph{PRAHOM Wrapper} then makes it possible to force the agents to respect the given constraint (line 5). Here, if \textquote{agent\_0} observes that a packet is in the cell superior to its own, it must take it (action $5$).

\subsection{Generation and evaluation of organizational specifications}

We generate the organizational specifications (blue box in \autoref{fig:prahom_wrapper_technical_view}) with the default profile. It starts by generating and analyzing joint histories played over 5 episodes with the best-learned policy (line 10).
\emph{PRAHOM Wrapper} takes priority into using the proposed \emph{Knowledge-based Organizational Specification Identification Approach} (KOSIA) to identify some organizational specifications thanks to the relations between organizational specifications and histories: if we see that the history of an agent contains action $3$ (move left) then this agent has the role \textquote{horizontal\_mover}.
For instance, we implemented KOSIA as a mixed pattern-matching engine and directed graph to find similar joint-histories to a given one hence finding the associated organizational specifications.

With no sufficient relations between histories and pre-established organizational specifications, \emph{PRAHOM Wrapper} uses the proposed \emph{General Organizational Specification Inference Approach} (GOSIA) which relies on an empirical approach to infer the rest of the organizational specifications. GOSIA is based on some proposed definitions for each $\mathcal{M}OISE^+$ organizational specification regarding joint-histories or other organizational specifications, to use suggested specific statistical, unsupervised learning techniques to infer them incrementally. GOSIA proceeds incrementally by inferring: i) roles and their inheritance;\quad ii) the possible organizations; \quad iii) the links between roles and sub-groups; \quad iv) the goals, plans, and missions; \quad v) the compatibilities, obligations, permissions, and cardinalities.

For instance, a role can be inferred by measuring similarity between histories in several complementary ways: by sequence clustering (linked to a dendrogram); by searching for the K-nearest neighbors (linked to a PCA of histories); by statistical analysis (frequency, variance of actions linked to various visualizations); etc.
Some techniques are also used to infer goals: frequency analysis of common observations of agents with the same role; and analysis of recurring threshold states triggering a notable improvement in the evolution of the reward (linked to a state transition graph).

From the roles and objectives obtained, \emph{PRAHOM Wrapper} infers other organizational specifications such as compatibilities between roles, permissions, and obligations. This results in the specifications specific to the organization (line 11).


\begin{lstlisting}[language=Python, caption={View of \emph{PRAHOM Wrapper} use for \emph{Moving Company}}, label={lst:wrapper_mc}]
env=moving_company_v0.raw_env(render_mode="human")
roles=organizational_model(structural_specifications(roles=["role_0","role_1""role2"],...)
jt_histories=joint_histories(env.possible_agents).add_joint_history(jth)
osj_rel=osj_relation(env.possible_agents).link_os(roles,jt_histories,env.possible_agents)
roles_agents_pc=joint_policy_constraint([osj_rel.get_joint_histories
(roles,env.possible_agents)])
train_env=moving_company_v0.parallel_env()
eval_env=moving_company_v0.parallel_env()
env=prahom_wrapper(env,osj_rel,roles_agents_pc,label_to_obj)
env.train_under_constraints(train_env,eval_env)
raw_specs=env.generate_specs()
\end{lstlisting}

\paragraph{Means for assessing results}

Results are presented in the form of a JSON object complying with the $\mathcal{M}OISE^+$ model containing the determined organizational specifications. It is coupled with the couple between organizational specifications and the concerned agents.

Yet, the inferred organizational specifications by GOSIA may not be accurate for the used techniques require an important fine tuning which may be different depending on the environment. To enable users to better assess the determined organizational specifications, \emph{PRAHOM Wrapper} also allows for generating figures that are indeed visual representations of the five GOSIA steps.

For instance, the inference of roles relies on hierarchical clustering which is represented as a dendrogram as in \autoref{fig:dendrogram}. Here, we can see agents' histories do not have any Common Longest Sub-sequence (cls), they make up three distinct roles: \textquote{agent\_0}, \textquote{agent\_1}, \textquote{agent\_2} are respectively \textquote{downwards bringer}, \textquote{leftwards bringer}, \textquote{upwards bringer}.
Another example is the inference of goals via an analysis of transitioned states by successful agents as in \autoref{fig:transition}. Here, we considered three joint-histories where agents collectively go through seven states and compared their similarities. Thus, sub-goals belong to these seven states while their organization as plans must be necessarily sequential.

\begin{figure}[!]
    \centering
    \includegraphics[width=0.47\textwidth]{academic_contributions/Organizational_MARL/ECAI_demo/figures/dendrogram.png}
    
    \caption{Dendrogram after hierarchical clustering of joint-histories}

    \phantom{X}
    
    \label{fig:dendrogram}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.49\textwidth]{academic_contributions/Organizational_MARL/ECAI_demo/figures/transition.png}
    
    \caption{State transition diagram obtained after clustering of states crossed according to three joint-histories}
    \label{fig:transition}

    \phantom{X}
    
\end{figure}


\section{Conclusion and perspective}

\emph{PRAHOM Wrapper} provides a means to constrain the agent learning to automatically determine organizational specifications based on histories, thus being agnostic of the MARL algorithm.
The current version involves simple statistical and unsupervised learning techniques for historical analysis to identify organizational specifications.

However, these techniques present limitations for identifying links between roles (communications, representations) leading to incomplete specifications.
Work on hierarchical learning is likely to help characterize emerging organizations throughout learning.


\paragraph{Perspective of complementary help from LLMs}

Despite, being at an early stage of experimenting in our contribution, we also obtained promising results with the \emph{EleutherAI} \emph{gpt-neo-2.7B} pre-trained transformer using \emph{Transformers}' \emph{Huggingface} library towards three main purposes:
\begin{enumerate*}[label=\roman*),itemjoin={;\quad}]
    \item Labeling and tagging the inferred organizational specification from related joint-histories in a human-like manner
    \item Giving a human-like textual description of each organizational specification regarding associated histories
    \item Giving a general human-like textual description of the whole organization
\end{enumerate*}

%Ultimately, we also aim to improve the applicability of \emph{PRAHOM Wrapper} by enriching its interface and its integration in industrial and research contexts.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Use this environment to include acknowledgements (optional).
%%% This will be omitted in doubleblind mode.

\begin{ack}
    This work was supported by \emph{Thales Land Air Systems} within the framework of the \emph{Cyb'Air} chair and the \emph{AICA IWG}.
\end{ack}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Use this command to include your bibliography file.

\newpage

% \bibliographystyle{abbrv}
\bibliography{references}

\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
