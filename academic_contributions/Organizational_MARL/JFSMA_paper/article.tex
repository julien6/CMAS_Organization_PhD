\documentclass[contribution]{jfsma}

\usepackage[T1]{fontenc}
\usepackage{graphicx}
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
\usepackage{amsthm}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{tabularx}
\usepackage{caption}
\usepackage{listings}
% \usepackage{titlesec}
% \usepackage[english]{babel}  
% \captionsetup{font=it}
\usepackage{ragged2e}
\usepackage{xurl}
\usepackage{hyperref}
\renewcommand{\figureautorefname}{Figure}
\renewcommand{\tableautorefname}{Table}
% \renewcommand{\equationautorefname}{Équation}
% \renewcommand{\sectionautorefname}{Section}
% \renewcommand{\subsectionautorefname}{Sous-section}
% \renewcommand{\subsubsectionautorefname}{Sous-sous-section}
\usepackage{pifont}
\usepackage{footmisc}
\usepackage{multirow}
\usepackage{enumitem}
\usepackage{algorithm2e}
\usepackage{float}
\usepackage{listings}
\usepackage{xcolor}
% \usepackage[inline, shortlabels]{enumitem}
% \usepackage[hyphens]{url}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
 
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
 
\lstset{style=mystyle}

% --- Tickz
\usepackage{physics}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{mathdots}
\usepackage{yhmath}
\usepackage{cancel}
\usepackage{color}
\usepackage{siunitx}
\usepackage{array}
\usepackage{multirow}
\usepackage{amssymb}
\usepackage{gensymb}
\usepackage{tabularx}
\usepackage{extarrows}
\usepackage{booktabs}
\usetikzlibrary{fadings}
\usetikzlibrary{patterns}
\usetikzlibrary{shadows.blur}
\usetikzlibrary{shapes}

% ---------
% \usepackage{titlesec}
\usepackage{pdfpages}
\usepackage{booktabs}
\usepackage{csquotes}
\usepackage{lipsum}  
\usepackage{arydshln}
\usepackage{smartdiagram}
\usepackage[inkscapeformat=png]{svg}
\usepackage{textcomp}
\usepackage{tabularray}\UseTblrLibrary{varwidth}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\usepackage{cite}
\usepackage{amsmath}
\newcommand{\probP}{\text{I\kern-0.15em P}}
\usepackage{etoolbox}
\patchcmd{\thebibliography}{\section*{\refname}}{}{}{}

\setlength\tabcolsep{0.5pt}

\newcommand{\before}[1]{\textcolor{red}{#1}}
\newcommand{\after}[1]{\textcolor{green}{#1}}

\newcommand{\old}[1]{\textcolor{orange}{#1}}
\newcommand{\rem}[1]{\textcolor{red}{#1}}
\newcommand{\todo}[1]{\textcolor{orange}{\newline \textit{\textbf{TODO:} #1}} \newline \newline }



\newcounter{relation}
\setcounter{relation}{0}
\renewcommand{\therelation}{\arabic{relation}}
\newcommand{\relationautorefname}{Relation}

\newenvironment{relation}[1][]{%
    \refstepcounter{relation}%
    \noindent \raggedright \textit{\textbf{Relation. \therelation}} \hfill$}
{%
$ \hfill \phantom{x}

}

\newcounter{proof}
\setcounter{proof}{0}
\renewcommand{\theproof}{\arabic{proof}}
\newcommand{\proofautorefname}{Proof}

\renewenvironment{proof}[1][]{
    \refstepcounter{proof}
    \noindent \raggedright \textit{\textbf{Proof. \theproof}}

    \setlength{\leftskip}{1em}

}
{

\
\setlength{\leftskip}{0pt}
}

\titre{Une Approche basée sur l'Apprentissage par Renforcement pour l'Ingénierie Organisationelle d'un SMA}


\auteur{Julien Soulé\up{a,b}}{julien.soule@lcis.grenoble-inp.fr}
\auteur{Jean-Paul Jamont\up{a}}{jean-paul.jamont@lcis.grenoble-inp.fr}
\auteur{Michel Occello\up{a}}{michel.occello@lcis.grenoble-inp.fr}
%%%Si besoin d'ajouter des auteurs à la ligne :
\auteurSuite{Louis-Marie Traonouez\up{b}}{louis-marie.traonouez@thalesgroup.com}
\auteurSuite{Paul Théron\up{c}}{paul.theron@orange.fr}

\institution{\up{a}%
  Univ. Grenoble Alpes, Grenoble INP, LCIS, 26000, Valence, France}
\institution{\up{b}%
  Thales Land and Air Systems, BL IAS, Rennes, France}
\institution{\up{c}%
  AICA IWG, La Guillermie, France}

% TODO: est-ce qu'on peut utiliser "dissemination" alors que le papier AIAI n'est pas publié à proprement parler?

\begin{document}

\maketitle

\begin{resume}

  Les SMAs de Cyberdéfense doivent assurer la protection de systèmes en réseau hétérogènes et distribués allant de la détection d’anomalies à l’exécution de contre-mesures. 
  %
  L’organisation est au cœur de ces SMAs et impacte la façon dont les agents interagissent entre eux et avec leur environnement pour favoriser l’atteinte d’un objectif de Cyberdéfense tout en satisfaisant les contraintes de l’environnement.
  %
  Néanmoins, la complexité et le manque de lisibilité de certains environnements rendent difficile et non sûre une recherche empirique d’une organisation adaptée.
  %
  La recherche d’une organisation adéquate est un problème  rencontré pour la conception de la plupart des SMAs et dépasse la problématique de ces applications spécifiques.
  %
  Cet article propose une approche générique et un outil permettant de faciliter la conception de l’organisation en combinant un processus d’apprentissage par renforcement et un modèle organisationnel. L’outil suggère des spécifications organisationnelles pour aider le concepteur.
  
\end{resume}

\motscles{Organisations, Ingénierie multi-agents, Simulation multi-agents, Apprentissage multi-agent}

\bigskip

\begin{abstract}

  The Cyberdefense MASs must ensure the protection of heterogeneous and distributed networked systems ranging from anomaly detection to countermeasure execution.
  %
  Organization lies at the core of these MASs and impacts how agents interact and with their environment to foster the achievement of a Cyberdefense objective while meeting the constraints of the environment.
  %
  However, the complexity and lack of readability of some environments make difficult and unsafe an empirical search for a suitable organization.
  %
  The search for an adequate organization is a problem encountered in the design of most MASs and goes beyond the issues of these specific applications.
  %
  This article proposes a generic approach and a tool to facilitate the organization's design by combining a reinforcement learning process and an organizational model. The tool suggests organizational specifications to help the designer.
\end{abstract}

\keywords{Organizations, Multi-agent engineering, Multi-agent simulation, Multi-agent learning}

\section{Introduction}

% Contexte:

%% Introduire le concept de SMA de Cyberdefense en le supportant par l'AICA
Les SMAs de Cyberdéfense~\cite{Kott2023, Singh2015} doivent assurer la protection d'environnements cyber-pyhysiques complexes.  La détection et l'identification des attaques sont essentielles pour raisonner sur les menaces en cours, tandis que l'élaboration et l'exécution des contre-mesures permettent de répondre efficacement à ces menaces et de minimiser les dommages potentiels. Dans ce contexte, le groupe \emph{AICA International Work Group} a proposé l'\emph{Autonomous Intelligent Cyberdefense Agent} (AICA)
\footnote{La recherche sur les AICA a été initiée le cadre du groupe \emph{NATO IST-152} puis de l'\emph{AICA International Work Group} : \url{https://www.aica-iwg.org/}. }
qui peut être vu comme un SMA de Cyberdéfense. L'ingénierie du SMA de Cyberdéfense a été identifiée par ce groupe de travail comme un défi important, en particulier pour ce qui concerne les aspects organisationnels. % est mise en avant en raison notamment du manque de compréhension visuelle et intuitive des environnements en réseau et de leurs spécificités propres.
Un tel système doit être performant contre les attaques malgré les contraintes environnementales. Il peut notamment renforcer sa résilience en favorisant par exemple la redondance, la diversité, l'autonomie et l'adaptabilité de ses composants et de ses interactions.

% L'organisation d'un tel système doit en effet renforcer sa résilience en favorisant par exemple la redondance, la diversité, l'autonomie et l'adaptabilité de ses composants et de ses interactions.
% -> JS : Trop tôt pour parler d'organisation. On peut vouloir un SMA capable de s'adapter sans le voir au travers du prisme de l'organisation nécessairement, non ?

%% Elargir le sujet des SMAC/AICA au contexte des SMA en général
Au-delà du contexte de la cyberdéfense, la conception d'un SMA repose sur les démarches proposées dans des méthodes de conception telles que GAIA~\cite{Wooldridge2000,Cernuzzi2014}, ADELFE~\cite{Mefteh2015}, MaSE~\cite{Deloach2001}, DIAMOND~\cite{Jamont2015} ou KB-ORG~\cite{Sims2008}.
Ces méthodes reposent généralement sur un processus itératif procédant par essais et erreurs guidés par l'expérience du concepteur pour élaborer la logique interne des agents. Cependant, la complexité et le manque de connaissance des systèmes cibles peuvent rendre coûteuse l'application de ces méthodes et ne garantissent pas de converger vers un SMA répondant aux exigences de performance~\cite{Mefteh2013}.


% Problème en 2 temps : 
% - l'organisation comme moyen de poser la problématique de conception comme un problème d'optimisation sous contraintes
% - le constat qu'il n'existe pas de méthode pour générer une organisation de façon automatisée sans connaissance préalables

Le concept d'organisation se réfère à la fois aux agents à travers leurs logiques internes et aux supports explicitant comment les agents coordonnent leurs activités pour atteindre de manière collaborative un objectif commun~\cite{Picard2009}. L'organisation occupe une place fondamentale dans la conception du SMA.
%
% JS : "L'organisation, qui désigne la structure et les règles qui..."
% -> En fait je pense que cette phrase confond l'organisation et le support de l'organisation: On ne peut pas résumer l'organisation à des structures, fonctions... cela n'en est simplement que la représentation...
%
% De mon point de vue:
% - les seules choses qui existent véritablement sont les agents et leur comportements issus de leurs logiques internes (règles).
% - l'ensemble des agents forment l'entité de l'organisation (cf. Gauthier Picard) dans le sens où l'on est sûr que l'organisation est "contenue" dans les agents même si on ne cherche pas nécéssairement à rendre l'organisation explicite
% - cette entité de l'organisation (ou organisation) peut être explicitée au travers d'un support (modèle organisationel) qui met éventuellement en jeu des structures (roles...), fonctions...
%
% -> Même si tu prends des SMAs centrés organisation et conscients de l'organisation (cf. Gauthier Picard), cette vision reste valable:
% -> Si on prend des agents qui partageraient une représentation commune de l'organisation et qui pourraient la manipuler, on ne peut pas dire que l'ensemble des agents sont strictement égaux à leur représentation
%
%
Dans ce travail, nous abordons la conception d'un SMA comme un problème d’optimisation consistant à trouver l’organisation qui satisfait les contraintes de déploiement de l’environnement et qui favorise la meilleure performance dans l’atteinte d’un objectif.
En utilisant des connaissances prédéfinies, certaines méthodes pourraient automatiser certaines parties de la recherche d'une organisation de SMA appropriée, comme KB-ORG~\cite{Sims2008}.

Cependant, il n'y a aucun moyen agnostique de l'environnement cible permettant d'automatiser totalement la recherche des logiques internes des agents (que nous appelons également \textbf{politiques}) qui satisfait les exigences données tout en explicitant les mécanismes organisationnels. %émergents. -> JS : j'enlève "émergent" car les mecanismes organisationels ne sont pas tous émérgents. Certains sont intentionellement voulus.

% Contribution : On introduit AOMEA en résumant cela comme Résolution du pb en jouant sur les politiques des agents + interpretation en spec. org. pour la conception
Nous introduisons \emph{AOMEA} (Assisted Multi-Agent System Organization Engineering Approach), une approche de conception SMA dont l'idée sous-jacente est de lier un processus \emph{Multi-Agent Reinforcement Learning} donné à un modèle organisationnel qui relie les politiques des agents entrainés à des spécifications organisationnelles explicites. Ainsi, pour des agents entrainés répondant aux exigences données, les spécifications organisationnelles associées peuvent suggérer au concepteur des mécanismes organisationnels à mettre en place pour développer un SMA adéquat.% vis à vis de son objectif et les contraintes données.

% Résultats

% Nous avons appliqué AOMEA dans trois jeux Atari spatiaux avec différents degrés de coopération requis entre les agents afin qu'ils atteignent un objectif le plus efficacement possible ; et en outre en respectant les spécifications organisationnelles comme contraintes de conception. Les spécifications organisationnelles obtenues sont en effet exploitables, cohérentes avec les attentes et respectent les contraintes de conception.
%Nous avons également appliqué notre approche, dans un environnement d'essaim de drones de Cyberdéfense dont les spécifications organisationnelles résultantes ont conduit à développer un SMA avec des scores comparables aux principaux.

La section II commence par présenter les concepts fondamentaux d'AOMEA que nous utilisons pour lier le modèle organisationnel et MARL.
% et la motivation pour intégrer un modèle organisationnel SMA dans un processus MARL afin d'améliorer le processus de conception SMA.
Dans la section III, nous présentons AOMEA depuis l’approche jusqu’à l’outil mis en œuvre. Nous avons évalué AOMEA dans quatre environnements simulés et nous discutons des résultats obtenus dans la section IV. Enfin, la section V conclut sur la viabilité d'AOMEA et met en évidence les limitations et les travaux futurs.

% ================================================== =================================================== =

\section{Cadre théorique}

% // Mettre en avant les briques du raisonnement en raison du titre pour préparer l'introduction de la contribution avec AOMEA sans les justifier (sans faire de comparaison avec l'existant, pas d'édt, dire juste les points forts)

% Organisation
% -> moise (justificateur parmi les existants)

% Méthodologies SMA (ALAADIN, GAIAI mais pas de moyens pour trouver une organisation automatiquemenet)

% MARL (basiques) // DECPOMDP (basiques)

Nous présentons les bases du modèle organisationnel $\mathcal{M}OISE^+$ et les bases MARL sur lesquelles est construite notre contribution.

\subsection{Le modèle organisationnel  MOISE+}

% définition, modèle AEIO, focus Moise, Dec-POMDP

% Un agent est une entité immergée dans un environnement qui perçoit l'observation et prend la décision d'agir de manière autonome dans l'environnement pour atteindre les objectifs qui lui sont assignés.
% Les types d'agents incluent des agents réactifs pilotés par les événements pour gérer les incertitudes dans un environnement ou des agents cognitifs proactifs qui exploitent les interactions avec d'autres agents. Un SMA est un ensemble d'agents dans un environnement partagé où chaque agent n'a qu'une perception locale. Ces agents doivent être dotés de capacités d'auto/réorganisation qui leur permettent de modifier de manière adaptative leur structure organisationnelle en fonction de leur environnement.

Un SMA est fortement lié à l'entité de l'organisation (ou simplement \textbf{organisation}) que nous considérons toujours exister à travers les interactions des agents en cours d'exécution même si elle peut être implicite.
%
% Ces méthodes sont essentielles pour garantir que SMA puisse coordonner, communiquer et exécuter efficacement des tâches dans un environnement distribué et souvent dynamique.
% Les méthodes les plus remarquables incluent
% \emph{Tropos} qui est une méthodologie de développement logiciel orientée agent qui met l'accent sur l'analyse précoce des exigences et l'affinement continu de ces exigences tout au long des phases de conception et de mise en œuvre~\cite{Bresciani2004} ;
% \emph{Gaia}, une méthodologie pour l'analyse et la conception de SMA, axée sur la structure organisationnelle du système~\cite{Zambonelli2003} ; \emph{DIAMOND} qui s'appuie sur une approche itérative en quatre phases pour améliorer le développement de systèmes physiques multi-agents ; et {ADELFE} qui utilisent les compétences et les attitudes lors de la conception pour créer des systèmes auto-organisés et répondre aux exigences finales.
% Dans le cadre des travaux méthodologiques, il convient également de noter le modèle AEIO (Voyelles) qui met l'accent sur la structuration des entités au sein des systèmes multi-agents en incorporant les agents, l'environnement, les interactions et l'organisation comme composants clés.
%
Un \textbf{modèle organisationnel} spécifie (au moins partiellement) l'organisation : si l'organisation est connue explicitement, le modèle organisationnel sert de support à son implémentation ; si l'organisation est émergente, le modèle organisationnel sert de support à sa description. Nous faisons référence aux \textbf{spécifications organisationnelles} comme les composants utilisés dans un modèle organisationnel pour caractériser l'organisation.
En particulier, les notions de rôles, de groupes/équipes, et de normes sont fréquemment utilisées dans les modèles organisationnels.
% tels que AGRE, $\mathcal{M}OISE^+$, OMNI, OperA, and TÆMS~\cite{Lacomme2011}.

% \input{tables/organizational_models.tex}

% Les modèles ISLANDER, OMNI ou OperA proposent une approche normative du SMA où les agents sont associés à des rôles de façon dynamique ce qui n'est pas couvert par $\mathcal{M}OISE^+$. Néanmoins, 

$\mathcal{M}OISE^+$~\cite{Hubner2007} permet de lier les politiques des agents à des spécifications organisationnelles. % JS : 
Le cadre complet et formel permet une description détaillée sur les aspects structurels, fonctionnels et normatifs là où \emph{AGRE}~\cite{Ferber2004}, ISLANDER~\cite{Esteva2002}, OMNI~\cite{Dignum2005} ou STEAM~\cite{Tambe1999} peuvent présenter des capacités limitées de description ou sont moins avancées.
% ODML est conçu pour la dynamique organisationnelle des SMA et peut manquer de généricité pour comparer plusieurs SMAs entre eux.
Les modèles STEAM et TÆMS~\cite{Vincent2000} se basent respectivement sur les notions d'équipe et de tâche pour décrire la réponse fonctionnelle du SMA tandis que les aspects normatifs et structurels sont peu couverts.
$\mathcal{M}OISE^+$ considère trois types de spécifications :

Les \textbf{spécifications structurelles} décrivent les moyens que les agents peuvent exploiter pour atteindre un objectif. Elles comprennent l'ensemble des \emph{rôles}, des sous-groupes, des \emph{liens} intra-groupe et inter-groupe, des \emph{compatibilités} intra-groupe et inter-groupe, ainsi que le rôle et le sous-groupe \emph {cardinalités}.
Un \emph{link} indique si deux rôles sont liés en raison de liens de connaissance, de communication ou d'autorité. Une \emph{compatibilité} indique si deux rôles peuvent être adoptés par le même agent. Les \emph{cardinalités} de rôle et de sous-groupe font respectivement référence au nombre minimal et maximal de rôles et de sous-groupes.

Les \textbf{spécifications fonctionnelles} décrivent la manière d'atteindre un objectif. Elles comprennent des \emph{schèmes sociaux} et des \emph{ordres de préférence}. Un \emph{schéma social} est décrit par des objectifs globaux, des étiquettes de mission avec des plans et le cardinal des agents engagés dans une mission. Un \emph{ordre de préférence} signifie qu'un agent a une préférence sociale pour s'engager dans une mission spécifique parmi plusieurs possibles.

Les \textbf{spécifications déontiques} permettent de relier les spécifications fonctionnelles et structurelles à travers un ensemble de \emph{permissions} et d'\emph{obligations}. Une \emph{permission} signifie qu'un agent jouant le rôle $\rho_a$ est autorisé à s'engager dans la mission $m$ pour une contrainte de temps donné $tc$. De même, une \emph{obligation} signifie qu'un agent jouant le rôle $\rho_a$ doit s'engager dans la mission $m$ pour une contrainte de temps donné $tc$. Une contrainte de temps $tc $ spécifie un ensemble de périodes déterminant si une autorisation ou une obligation est valide.

% Pourtant, ces travaux méthodologiques s'appuient largement sur l'expérience des concepteurs humains alors qu'aucun d'entre eux ne permet d'automatiser l'assistance au processus de conception SMA en garantissant une efficacité suffisante tout en prenant en compte les aspects organisationnels dans un contexte multi-agents.

\subsection{L'apprentissage par renforcement multi-agent}

L'apprentissage par renforcement est un paradigme d'apprentissage automatique dans lequel les agents apprennent à prendre des décisions en interagissant avec un environnement. L’objectif est que l’agent maximise la récompense cumulée au fil du temps grâce à un processus d’essais et d’erreurs.
MARL étend ce concept à plusieurs agents qui apprennent simultanément à adapter leurs stratégies tout en considérant les actions et les influences des autres agents. Cela pousse les agents à s’appuyer sur des mécanismes de coopération, de compétition et de coordination.
% JS: c'est pas un trop lourd ? on peut virer manuelle je pense et on garde classique ?
% JS : "classique" ça me parait flou 
MARL permet de converger automatiquement vers les politiques des agents qui permettent d'atteindre l'objectif donné. Pourtant, contrairement à une conception classique, la logique des agents entrainés n'est pas explicitement spécifiée d'un point de vue collectif. Peu de travaux tentent d’aborder cette question et peu sont orientés à des fins méthodologiques.
Kazhdan et. al.~\cite{Kazhdan2020} a proposé des moyens pour extraire des modèles symboliques des systèmes MARL qui améliorent l'interprétabilité des systèmes MARL.
Wang et. al.~\cite{Wang2020} a introduit une approche MARL orientée rôles dans laquelle les rôles sont émergents et les agents ayant des rôles similaires ont tendance à partager leur apprentissage et à se spécialiser dans certaines sous-tâches.
Tosic et. al~\cite{Tosic2010} ont proposé un cadre pour aborder la coordination dans les SMA collaboratifs en s'appuyant sur les capacités de communication des systèmes multi-agents.
Zheng et. al.~\cite{Zheng2018} a présenté une plateforme pour MARL qui vise à faciliter la recherche sur l'intelligence collective artificielle en fournissant un ensemble complet de mesures d'évaluation pour comparer les performances d'algorithmes MARL.

Des modèles Markoviens sont nécessaires pour modéliser l'environnement et appliquer les techniques MARL. En tant qu'outil couramment utilisé, le Dec-POMDP~\cite{Oliehoek2016} considère plusieurs agents de façon analogue à un ensemble. Il s'appuie sur des processus stochastiques pour modéliser l'incertitude de l'environnement pour les changements induits par les actions, les observations reçues, mais aussi les communications. Sa fonction de récompense est commune aux agents ce qui favorise la formation d'actions orientées pour la collaboration~\cite{Beynier2013}. Formellement, un Dec-POMDP est un 7-tuple $(S,\{A_i\},T,R,\{\Omega_i\},O,\gamma)$ , où : $S = \{s_1, .. s_{|S|}\}$ est l''ensemble des états possibles ; $A_{i} = \{a_{1}^{i},..,a_{|A_{i}|}^{i}\}$ l'ensemble des actions possibles pour l'agent $i$ ; $T$ pour que $T(s,a,s') = \probP{(s'|s,a)}$ l'ensemble des probabilités de transition conditionnelles entre les états ; $R : S \times A \times S \rightarrow \mathbb{R}$ la fonction de récompense ; $\Omega_{i} = \{o_{1}^{i},..,o_{|\Omega_{i}|}^{i}\}$  l'ensemble d'observations pour l'agent $ag_i$ ; $O$ pour que $O(s',a,o) = \probP{(o|s',a)}$  l'ensemble des probabilités d'observation conditionnelles ; $\gamma \in [0,1]$, l'horizon.

Nous appelons \textbf{résoudre} le Dec-POMDP pour l'équipe $t$ la recherche d'une politique conjointe $\pi_{joint,i} \in \Pi_{joint}$ qui maximise la récompense cumulée attendue sur un horizon fini.
Nous faisons référence à la \textbf{résolution sous-optimale} du Dec-POMDP à une espérance de $s$ comme étant la recherche des politiques conjointes $\pi_{joint,i} \in \Pi_{joint}$ qui obtiennent la récompense cumulative attendue sur un épisode à une espérance minimale ou égale à $s \in \mathbb{R}$.


% ================================================== =================================================== =

\section{Approche AOMEA}

% Mettre d'abord en avant le shcéma général de l'approche
% Donner la philosophie de l'approche

% 	Aperçu global (Fig. 1)
% 	noyau théorique
% 	Ingénierie
% Implémentation (vers une implémentation de type PoC)

\subsection{Vue d'ensemble}

\begin{figure}[h!]
  \centering
  \include{figures/approach}
  \caption{Une vue récapitulative de notre approche de la conception SMA}
  \label{fig:design_approach}
\end{figure}

Nous présentons AOMEA comme une approche de conception de SMA qui automatise la conception préliminaire d'un SMA en fonction de certaines contraintes de conception. Les spécifications organisationnelles obtenues après l'entrainement permettent l’élaboration d’un SMA raffiné.
L’idée sous-jacente de notre approche est de considérer qu’une politique conjointe ou un historique conjoint peuvent être décrits en termes de spécifications organisationnelles, au moins partiellement.
Nous appelons cette approche large \textquote{Organization oriented MARL} (OMARL).
%
% En tant que description de haut niveau, AOMEA considère l'environnement avec des agents qui doivent atteindre certains objectifs. Il permet de trouver automatiquement des informations pertinentes sous la forme de spécifications organisationnelles. Ils doivent exprimer de manière transparente comment les agents pourraient agir et collaborer individuellement pour atteindre les objectifs. Le processus de conception du SMA peut alors être assisté à la lumière de ces indications. Une représentation illustrative de notre approche est présentée dans \autoref{fig:design_approach}.
%
AOMEA se compose de 4 phases séquentielles : modélisation, résolution, analyse et développement (respectivement $1.x$, $2.x$, $3.x$, $4.x$ dans les étiquettes de flèche dans \autoref{fig:design_approach}).

\textbf{Phase 1 : Modélisation} \quad Dans cette phase, le concepteur doit développer manuellement une simulation de l'environnement cible ($1.1$ dans \autoref{fig:design_approach}) où les agents doivent coopérer pour atteindre efficacement l'objectif du concepteur ($1.2 $ in \autoref{fig:design_approach}) à l'aide de retours quantitatifs. Lors du développement de l'environnement simulé, le concepteur peut relier des parties de la politique d'un agent (sous forme de couples observation-action) avec les spécifications organisationnelles connues de tout modèle organisationnel choisi.
Par exemple, dans les organisations \textquote{leader-follower}, les actions qui envoient des ordres à d'autres agents suiveurs sont des caractéristiques des agents leaders.
Facultativement, le concepteur peut restreindre l'ensemble des politiques possibles que les agents peuvent explorer par rapport aux spécifications organisationnelles données en tant que contraintes pour répondre aux exigences de conception ou pour aider les agents à converger ($1.3$ dans \autoref{fig:design_approach}).

\textbf{Phase 2 : Résolution} \quad Dans cette phase, en s'appuyant sur les relations établies entre les couples observation-action et les spécifications organisationnelles, un algorithme MARL est utilisé conjointement avec le modèle organisationnel SMA choisi à travers un processus OMARL. Il permet automatiquement de trouver des politiques optimales satisfaisant les spécifications organisationnelles de conception données ($2.1$ dans \autoref{fig:design_approach}) qui conduisent à la meilleure récompense cumulée attendue ; et obtenir les spécifications organisationnelles associées ($2.2$ dans \autoref{fig:design_approach}). Par exemple, lors de l'entrainement des agents concernant l'organisation \textquote{leader-follower}, certains agents peuvent se voir interdire d'envoyer des ordres tandis que d'autres peuvent y être forcés. Après l'entrainement, le processus OMARL caractérise les rôles émergents, les liens entre les rôles ou les sous-objectifs organisés en plans de mission.

\textbf{Phase 3 : Analyse} \quad Dans cette phase, le concepteur observe les politiques des agents entrainés ($3.2$ dans \autoref{fig:design_approach}) et prend en compte les spécifications organisationnelles associées déduites ($3.1$ dans \autoref{fig:design_approach}) pour comprendre comment ces agents peuvent atteindre l'objectif. À la lumière de ces résultats bruts, le concepteur peut extraire des modèles de conception pertinents en excluant les actions bruyantes ou inutiles des agents. L'intérêt est de fournir au moins quelques indications sur les spécifications organisationnelles capables d'atteindre l'objectif et de satisfaire les contraintes de conception. Nous appelons ces indications pertinentes des spécifications organisationnelles raffinées ($3.3$ dans \autoref{fig:design_approach}). Par exemple, après avoir entrainé plusieurs agents dans un environnement \textquote{prédateur-proie}, il est possible d'analyser qu'un prédateur \textquote{leader} avec des prédateurs \textquote{follower}, semble être plus efficace pour attraper des proies.

\textbf{Phase 4 : Développement} \quad Dans cette phase, le concepteur prend en compte les spécifications organisationnelles raffinées comme modèle pour la mise en œuvre d'un SMA. À partir de là, un développement du SMA avec l'une des méthodes disponibles utilisées conjointement avec le modèle organisationnel choisi peut être appliqué. Contrairement aux agents entrainés qui peuvent provoquer des comportements inattendus, les agents implémentés manuellement permettent de donner les garanties de sécurité requises pour les environnements sensibles. Enfin, les agents implémentés sont lancés dans des simulations pour évaluer si le SMA implémenté peut effectivement atteindre l'objectif.

\subsection{Cœur de l'approche}

Pour implémenter un processus OMARL, nous proposons l'algorithme \emph{Partial Relations with Agent History and Organization Model} (PRAHOM) pour lier les politiques des agents et leur entrainement à un modèle organisationnel.
Il s'agit d'une synthèse de deux processus qui entrent dans le cadre des objectifs de l'OMARL. Le premier processus détermine les spécifications organisationnelles des politiques des agents, le second processus entraine les politiques conjointes en satisfaisant les spécifications organisationnelles données. Une vue illustrative de \emph{PRAHOM} est donnée dans \autoref{fig:prahom_process}.
Ici, nous présentons une description de haut niveau de ces deux processus. Plus d'informations sur l'utilisation et l'implémentation de \emph{PRAHOM} peuvent être trouvées dans \autoref{PettingZoo-wrapper}.
% Puisque \emph{PRAHOM} s'appuie sur des historiques conjointes plutôt que sur des politiques conjointes, il est indépendant de la fonction d'approximation utilisée pour mettre en œuvre les politiques des agents telles que celles basées sur les réseaux de neurones

\begin{figure}[h!]
  \centering
  \include{figures/prahom_process}
  \caption{Une vue récapitulative du processus PRAHOM}
  \label{fig:prahom_process}
\end{figure}

\subsubsection{Processus 1 : Déduire des spécifications organisationnelles}

Plutôt que d'utiliser directement les politiques conjointes, nous utilisons les historiques conjoints, car ils peuvent être construits avec les actions résultantes observées lorsque les observations sont reçues au cours d'une série d'épisodes de test. En effet, pour une politique donnée $\pi \in \Pi$, l'historique associé est par définition $h \in h_{joint} = \langle(\omega_k,a_k) | k \in \mathbb{N}\rangle$ et le $(\omega_k,a_k) \in \pi$.
Ensuite, en raison de la difficulté de déduire des informations liées aux spécifications organisationnelles, il est possible d'associer des séquences de couples observation-action aux spécifications de l'organisation sous la forme d'une relation \textquote{plusieurs à plusieurs}. Cela met en place un premier cadre d’identification des spécifications organisationnelles dans les historiques. Le reste de cette section aborde cette difficulté.

Le concepteur peut définir certaines relations entre les spécifications $\mathcal{M}OISE^+$ et les historiques conjoints. Leurs prémisses viennent du fait que certaines spécifications du modèle organisationnel $\mathcal{M}OISE^+$ peuvent être mappées à des sous-ensembles d'actions d'une seule politique commune sous-optimale.
À partir de ces relations, il est possible d’utiliser des approches empiriques ou statistiques pour déduire des spécifications organisationnelles à partir d’historiques communes.
%JS
%JPJ je te laisse reprendre au besoin. Penser a dire (si ce n'est pas fait) dans les perspective qu'il faudra lever cette hypothese -> Ça me va
Pour simplifier l'étude, nous ne considérons dans un premier temps qu'un seul groupe d'agents et nous ne prenons donc pas en compte les inter-liens et les inter-compatibilités. De même, nous ne considérons qu’un seul schéma social.
Premièrement, nous examinons le niveau individuel en essayant de comprendre les rôles, les liens, les sous-groupes, les objectifs individuels, les missions et les plans joués par les agents en échantillonnant les sous-séquences historiques $h \in H$ et en les comparant avec les sous-séquences historiques connues afin de déterminer des rôles.

Après avoir analysé plusieurs politiques conjointes, le processus tente de renforcer une vision globale des objectifs, des missions, des plans et de la connaissance de la mission par rapport à l'objectif ; avec les informations partiellement déduites au niveau individuel.
Au final, notre processus tente de synthétiser les connaissances inférées jusqu'à avoir une meilleure vision de la cardinalité des agents par sous-groupe, de la cardinalité des agents pour chaque mission, de la cardinalité des rôles, des compatibilités entre rôles, des autorisations et des obligations.

\subsubsection{Processus 2 : Contraindre l'espace des politiques}

Nous considérons un algorithme MARL donné qui converge itérativement vers une politique commune de sorte que la politique de chaque agent soit mise à jour à chaque étape jusqu'à un horizon fini.
Nous privilégions l'algorithme \emph{Proximal Policy Optimization} (PPO) pour son efficacité prouvée dans des environnements multi-agents coopératifs sans nécessiter de modifications algorithmiques ou d'architectures spécifiques au domaine~\cite{Yu2022}.
Pour contraindre les politiques conjointes possibles à celles satisfaisant les spécifications organisationnelles de conception $os_{init}$, nous proposons de contraindre les ensembles d'actions et d'observations pour chaque agent en fonction de $os_{init}$ à chaque étape. Par exemple, nous pouvons contraindre un agent à converger vers un rôle donné en interdisant les actions liées à d’autres rôles. Nous utilisons cette idée pour mettre en place notre processus visant à guider l'entrainement en fonction des contraintes organisationnelles de conception.

Dans un premier temps, nous utilisons les relations précédemment établies entre spécifications organisationnelles et couples action-observation, pour déterminer les actions autorisées ou interdites jouables par les agents à chaque étape.
Ensuite, il calcule d'abord l'ensemble d'actions autorisées $A_{step}$ en fonction de l'historique actuel $h_{joint,i}$. Ensuite, une action est choisie parmi les actions autorisées. Cette action $a_{step} \in A_{step}$ est ajoutée à l'historique pour être utilisée pour mettre à jour la politique de l'agent à l'étape suivante. Ensuite, l'algorithme MARL met à jour la politique commune, donc les politiques des agents, avec l'action et l'observation en cours.
Enfin, une analyse de la politique conjointe sous-optimale actuelle $\pi_{joint}$ satisfaisant $os_{init}$ est déclenchée périodiquement. Il permet d’améliorer de manière itérative l’efficacité des politiques conjointes et l’exactitude des spécifications organisationnelles qui en découlent.
Nous pouvons noter que la restriction impliquée par $os_{init}$ dans les éventuelles politiques conjointes pourrait empêcher l'algorithme MARL de trouver une politique commune qui satisfasse la récompense cumulative minimale attendue définie par le concepteur.

\subsection{Outil d'ingénierie}

%%%%%%%% DEBUT DES MODIFICATIONS %%%%%%%%%%%%%%
Dans le cadre de CybMASDE\footnotemark[1]
%
\footnotetext[1]{\emph{Cyberdefense Multi Agent System Developpment Environment} est un simulateur pour SMA de Cyberdéfense et disponible à \url{https://github.com/julien6/CybMASDE}}
%
, nous proposons \emph{PRAHOM Wrapper}\label{PettingZoo-wrapper} comme outil augmentant la bibliothèque \emph{PettingZoo} qui fournit une API standardisée pour le développement d'environnements et l'application d'algorithmes MARL.
%
\emph{PRAHOM Wrapper} fournit des moyens d'inférer des spécifications organisationnelles à partir d'agents entraînés ou contraindre leur entraînement.
% Lors de l'entraînement, des actions/observations sont masquées ou mis en avant pour contraindre l'apprentissage d'un agent selon les spécifications organisationnelles données.
%
\autoref{lst:wrapper_basic_use} présente une utilisation simple du wrapper pour augmenter un environnement \emph{PettingZoo} (ligne 5) avec des relations connues entre les spécifications organisationnelles et les historiques attendus (ligne 3) ainsi que les spécifications organisationnelles qui contraignent les politiques possibles des agents (ligne 4).

Ici, l'entrainement est effectué avec une fonctionnalité de \emph{PRAHOM Wrapper} qui utilise PPO et la configuration par défaut (ligne 6).
Pendant l'entrainement, \textquote{agent\_0} est contraint au rôle \textquote{follower}. Ainsi ses actions doivent être choisies d'après les historiques attendus (exprimables de diverses façons en plus de listes). Ces contraintes peuvent être satisfaites selon trois modes disponibles : i) masquer/corriger de façon externe aux politiques les observations reçues et actions choisies  ; ii) enseigner les contraintes aux politiques courantes ; iii) modifier en interne les politiques pour respecter les contraintes.

Après entrainement, \emph{PRAHOM Wrapper} infère les spécifications organisationnelles à partir de plusieurs historiques conjoints (lié chacun à un épisode) ; ainsi que l'instanciation de l'organisation généralisée pour chaque historique conjoint (ligne 7).
Ce processus d'inférence utilise d'abord les relations connues entre les historiques et les spécifications organisationnelles (ligne 3) : l'historique d'un agent qui contient l'observation $14$ (\textquote{commande reçue}) et l'action $74$ (\textquote{appliquer l’ordre}), est un \textquote{follower}. De même, pour les liens entre les rôles en utilisant des expressions régulières pour les historiques (ligne 3).
%
Ensuite, en s'appuyant sur la définition donnée de chaque spécification organisationnelle vis-à-vis des historiques, \emph{PRAHOM Wrapper} généralise plusieurs historiques conjoints.
% pour obtenir de nouvelles spécifications organisationnelles.
%
Par exemple, un rôle est obtenu en mesurant la similarité entre des historiques. Cela peut être fait de plusieurs manières : clustering de séquences (avec un dendrogramme) ; K-voisins les plus proches (avec ACP des historiques) ; analyse statistique (en particulier, fréquence d'action dans diverses visualisations) ; etc.

À partir des premières spécifications organisationnelles obtenues, un algorithme proposé déduit empiriquement d'autres spécifications organisationnelles telles que les compatibilités.
Ces résultats peuvent être incomplets ou bruités en raison des limites des techniques et de l'algorithme d'inférence des spécifications organisationnelles. Cependant, les résultats étant conformes à $\mathcal{M}OISE^+$, ils peuvent aider à la conception SMA à la lumière des spécifications organisationnelles proposées.
%%%%%%%% FIN DES MODIFICATIONS %%%%%%%%%%%%%%

\begin{lstlisting}[language=Python, caption={Utilisation basique de \emph{PRAHOM Wrapper}}, label={lst:wrapper_basic_use}]
from omarl_experiments import prahom_wrapper
env=PettingZoo_env.parallel_env(render_mode="human")
specs_to_hist={"structural_specifications":{"roles":{"follower":{"23":41,"14":[74,0]}}...},"functional_specifications":{"links":{"(leader,follower,aut)":".*14.*?89"}...}...}
policy_specs_constr={"agent_0":{"structural_specifications":"roles":["follower"]}}
env=prahom_wrapper(env,action_to_specs,training_specs)
env.train("default_PPO")
trained_specs,agent_to_specs=env.prahom_specs()
\end{lstlisting}

% =============

% \begin{itemize}
% \item Questions au niveau du système multi-agents (approche centrée sur le système)
% \begin{itemize}
% \item Nombre d'agents, quelle hétérogénéité ?
% \item Quel est le support commun (Environnement) partagé par les agents ?
% \item Quels mécanismes de communication sont disponibles pour les agents ?
% \item Quels sont les langages de communication, les ontologies, les protocoles d'interaction utilisés par les agents ?
% \item Quelle est l’organisation au sein de laquelle les agents opèrent ? Comment est-il établi ?
% \item Comment les agents coordonnent-ils leurs actions ? Comment assurer un fonctionnement cohérent ?
% \end{itemize}

% \item Questions au niveau de l'agent (approche centrée sur l'agent)
% \begin{itemize}
% \item Que représente un agent ? Quelles actions doivent être encapsulées dans un agent ?
% \item Comment les agents représentent-ils l'environnement et l'organisation dans lesquels ils opèrent ?
% \item Comment les agents gèrent-ils les interactions avec d'autres agents ?
% \item Quelle est la structure interne des agents ?
% \end{itemize}
% \end{itemize}

% ================================================== =================================================== =

\section{Évaluation dans des environnements de jeu coopératif}

% Évaluation
% Afin de vérifier et démontrer l'approche, est appliquée sur l'étude de cas suivante.
% 	Étude de cas

\subsection{Protocole expérimental}

Afin d'évaluer AOMEA, nous utilisons \emph{PRAHOM} dans des environnements simulés disponibles composés d'agents devant atteindre un objectif avec les meilleures performances à travers diverses stratégies collectives. Ces exemples présentent aussi l'avantage d'être facilement compréhensibles.
Nous avons sélectionné trois environnements de type Atari pour leur rendu visuel qui constitue un moyen pratique d'évaluer les résultats avec des observations manuelles\footnotemark[2].
Considérant la recherche sur les AICA, nous avons également considéré un environnement de Cyberdéfense comme une première tentative d'application de \emph{PRAHOM} dans un environnement de Cyberdéfense non "visuel" :

\footnotetext[2]{Des explications supplémentaires et les exemples discutés utilisant le \emph{PRAHOM Wrapper} sont disponibles sur \url{https://github.com/julien6/omarl_experiments?tab=readme-ov-file\#predator-prey-with-communication}}

\begin{itemize}
  \item \textquote{Drone swarm - 3rd CAGE Challenge}~\cite{cage_challenge_3_announcement} (CYB) se compose d'agents cyber-défenseurs déployés sur des drones en réseau essayant de lutter contre les programmes malware déployés de manière malveillante. Nous pouvons nous attendre à ce que les agents \allowbreak isolent collectivement les drones compromis ;
  \item \textquote{Pistonball} (PBL)~\cite{Terry2021} se compose d'une série de pistons pour amener une balle de droite à gauche, nécessitant ainsi la représentation des voisins ;
  \item \textquote{Predator-prey with communication}~\cite{Lowe2017} (PPY) se compose de prédateurs surveillés par un leader pour mieux attraper des proies plus rapides, nécessitant ainsi des stratégies de chasse collectives ;
  \item \textquote{Knights Archers Zombies}~\cite{Terry2021} (KAZ) consiste en trois chevaliers et deux archers apprenant à tuer le plus de zombies, ce qui nécessite ainsi un positionnement spatial efficace des agents.
\end{itemize}

Nous avons appliqué AOMEA dans trois cas :
\begin{itemize}
  \item Pas de spécifications organisationnelles (NTS) : les agents doivent apprendre les stratégies collectives les plus efficaces sans aucune contrainte ni indication.
  \item Spécifications organisationnelles partiellement contraignantes (PTS) : certaines contraintes ou indications sont données pour aider à converger plus rapidement ou à répondre à des exigences.
  \item Spécifications organisationnelles entièrement contraignantes (FTS) : des politiques conjointes élaborées manuellement sont données, car elles constituent une référence concernant les politiques conjointes apprises.
\end{itemize}

\

\noindent Ici, nous ne présentons pas le détail des contraintes données dans NTS et FTS (disponibles dans le référentiel Git\footnotemark[2]).
%
\begin{figure*}[h!]
  \centering
  \includegraphics[width=0.76\linewidth]{figures/prahom_learning_curve.png}
  \caption{Récompense moyenne pour chaque itération dans l'environnement PBL pour les cas NTS, PTS et FTS}
  \label{fig:prahom_learning_curve}
\end{figure*}
%
\begin{figure*}[h!]
  \centering
  \includegraphics[width=0.75\linewidth]{figures/prahom_pca_analysis.png}
  \caption{ACP des historiques des agents entrainés dans l'environnement PBL}
  \label{fig:prahom_pca_analysis}
\end{figure*}
%
Nous évaluons dans le tableau~\ref{tab:training_AOMEA_results}, l'impact de \emph{PRAHOM} sur les critères suivants : les ratios de temps de convergence entre PTS, NTS et FTS pour atteindre un seuil de récompense cumulée. La stabilité est le rapport entre la moyenne des récompenses cumulées sur la récompense maximale après plusieurs épisodes. La stabilité des performances montre si les agents atteignent l'objectif de façon générale en évaluant plusieurs environnements générés avec différents paramètres.

\input{tables/training_OMARL_results.tex}

\subsection{Analyse}

La \autoref{fig:prahom_learning_curve} montre l'évolution de la récompense dans les cas NTS, FTS et PTS pour l'environnement PBL. De manière générale, on peut remarquer que le temps de convergence est plus long pour NTS que pour PTS qui est également plus long que pour FTS. On constate, comme attendu, que l’espace de recherche diminuant, le temps de convergence est raccourci. Par exemple, nous remarquons une convergence plus rapide vers une solution sous-optimale dans l’environnement PBL en fournissant des spécifications organisationnelles. Bien que le PTS converge plus rapidement que le NTS vers une récompense cumulée comparable, le NTS peut surpasser le PTS parce que les politiques des agents entrainés sont conçues sur mesure pour résoudre le problème de manière beaucoup plus fine que ne peuvent les spécifications organisationnelles du concepteur. La faible stabilité des performances de l'environnement CYB indique que les agents ont des difficultés à trouver des stratégies générales à la différence des agents des autres environnements.

Nous prenons également en compte les critères suivants après l'entrainement : rôles, liens et performance globale. Une analyse qualitative est présentée dans le tableau~\ref{tab:trained_AOMEA_results}
%
\input{tables/trained_OMARL_results.tex}
%
% //TODO : schémas Moise+ et comparaison avec ceux attendus
%
Pour l'environnement PBL, les historiques des agents entrainés sont proches. Cela est visible dans l'ACP présentée à la \autoref{fig:prahom_pca_analysis} généré en exprimant les historiques des agents sous forme de vecteurs contenant les couples observation-action. Nous pouvons remarquer que l'historique de la plupart des agents se trouve dans la zone inférieure gauche (encerclée en rouge). Cela montre que la plupart des pistons semblent agir d'une façon similaire qu'on peut associer à un rôle. Nous ne pouvons déterminer aucune autre spécification organisationnelle en raison de l'absence de communication entre agents. Pour l'environnement KAZ, on peut remarquer deux rôles distincts : les archers ont tendance à s'éloigner des zombies, tandis que les chevaliers ont tendance à s'en approcher. Pour l'environnement PPY, nous pouvons observer que les spécifications de sortie indiquent des liens d'autorité entre le prédateur leader et les prédateurs simples pour permettre des stratégies collectives pour encercler les proies. Enfin, l’environnement CYB montre que les communications entre agents bleus permettent essentiellement d’isoler les drones suspectés ou de tenter de les réparer.

Pour l'environnement CYB, nous avons développé notre SMA raffiné via un simple arbre de décision élaboré à la main tel que préconisé dans AOMEA à la lumière des spécifications organisationnelles que nous obtenons en supprimant le bruit. Notre approche ne suggère pas de rôles généraux, mais des modèles stratégiques pertinents ont été identifiés. Par exemple, concernant les liens entre les rôles des agents, nous remarquons que les agents qui envoient des messages semblent fréquemment repérés comme suspects par leurs voisins. De plus, un agent cyber-défenseur se trouvant dans le rayon de communication d’un drone suspecté a tendance à couper sa communication et à la réactiver par la suite. Même si ces informations sont peu nombreuses, le score moyen que nous obtenons avec notre SMA affiné est d'environ -2000, ce qui est en effet proche des 5 meilleurs scores sur les 20 participants. Cela montre l'applicabilité d'AOMEA au contexte de la Cyberdéfense.

\section{Conclusion}

% Dans cet article, nous avons présenté AOMEA, une nouvelle approche générale de conception SMA qui vise à faciliter la conception SMA lorsqu'elle ne peut pas être facilement réalisée par les concepteurs dans des environnements de déploiement très complexes.
Les méthodes multi-agents s'appuient sur les connaissances du concepteur pour concevoir une organisation SMA adaptée, mais ne fournissent pas de moyens automatiques pour déterminer les mécanismes organisationnels pertinents.
% uniquement à partir des exigences de conception et de l'objectif global.
Les techniques MARL ont été appliquées avec succès pour entrainer automatiquement des agents à atteindre un objectif donné sans caractérisation explicite des stratégies collectives émergentes.
L'originalité d'AOMEA est d'enrichir un processus MARL d'un modèle organisationnel explicite vers un objectif méthodologique pour aborder ces problématiques. Nous avons d'abord exposé comment AOMEA est destiné à être utilisé dans l'ingénierie SMA en tant qu'outil supplémentaire pour aider au processus de conception.
Ensuite, nous avons proposé de lier les politiques des agents (modélisées dans un Dec-POMDP) avec $\mathcal{M}OISE^+$ à travers le processus \emph{PRAHOM} qui est au cœur d'AOMEA. Sous les conditions simplificatrices d'un groupe et d'un schéma social unique, \emph{PRAHOM} permet de déterminer partiellement les spécifications organisationnelles à partir des historiques conjoints et de contraindre l'entrainement des politiques par rapport à des spécifications organisationnelles.
De plus, nous avons implémenté le wrapper \emph{PRAHOM PettingZoo} comme preuve de concept pour appliquer AOMEA.
Enfin, nous avons appliqué notre approche dans quatre environnements \emph{PettingZoo} pour évaluer l'impact pendant et après l'entrainement. Les performances obtenues se révèlent comparables à ceux connus.

Même si \emph{PRAHOM} est agnostique à l'égard de l'algorithme MARL, car il utilise l'historique des agents pour déduire des spécifications organisationnelles, reconstruire a posteriori les comportements collectifs des agents peut s'avérer difficile. En effet, une perspective majeure pour améliorer \emph{PRAHOM} est d'aller plus loin avec les techniques d'apprentissage non supervisé en plus des approches statistiques empiriques pour identifier des spécifications organisationnelles pertinentes à partir d'historiques conjoints. De plus, les travaux issus de l’apprentissage hiérarchique peuvent contribuer à mieux caractériser les stratégies émergentes durant l’apprentissage.
%À terme, nous visons également à améliorer l'applicabilité d'AOMEA en développant des interfaces dédiées construites autour de \emph{PRAHOM} le rendant plus accessible aux contextes industriels et de recherche.


% \begin{thebibliography}{9}
% {\small
% \bibitem{bar} U. Nexpert, \emph{Le livre,} Son Editeur, 1929.

% \bibitem{foo} I. Troiseu-Pami, Un article intéressant, \emph{Journal de
%     Spirou}, Vol. 17, pp. 1-100, 1987
% }
% \end{thebibliography}
\section*{Remerciements}

Ce travail est financé par \emph{Thales Land Air Systems} dans le cadre des travaux conjoints de la chaire \emph{Cyb'Air} et de l'\emph{AICA IWG}.

\section*{References}
\small
\bibliographystyle{plain}
\bibliography{references}


\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-SMAter: "jfsmaLatex"
%%% ispell-local-dictionary: "francais"
%%% TeX-command-extra-options: "-shell-escape"
%%% End: 