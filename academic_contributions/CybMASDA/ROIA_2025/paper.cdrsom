\begingroup
%  Article : ROIA_-1__1_0_0_0
%  Fichier : paper.tex
%  Date prod. : 2025/12/14
\SomLine
    {\firstname {Julien} \lastname {Soulé}\unskip ,\penalty -2 \space \cdr@count@hasaddr =\z@ \ignorespaces \firstname {Jean-Paul} \lastname {Jamont}\unskip ,\penalty -2 \space \cdr@count@hasaddr =\z@ \ignorespaces \firstname {Michel} \lastname {Occello}\unskip ,\penalty -2 \space \cdr@count@hasaddr =\z@ \ignorespaces \firstname {Louis-Marie} \lastname {Traonouez}\unskip , \penalty -1 \cdr@count@hasaddr =\z@ \firstname {Paul} \lastname {Théron}}
    {\firstname {Julien} \lastname {Soulé}\unskip ,\penalty -2 \space \cdr@count@hasaddr =\z@ \ignorespaces \firstname {Jean-Paul} \lastname {Jamont}\unskip ,\penalty -2 \space \cdr@count@hasaddr =\z@ \ignorespaces \firstname {Michel} \lastname {Occello}\hasaddress {}{Université Grenoble Alpes, Grenoble INP, LCIS, 26000, Valence, France}\hasemail {}{julien.soule@lcis.grenoble-inp.fr}\hasemail {}{jean-paul.jamont@lcis.grenoble-inp.fr}\hasemail {}{michel.occello@lcis.grenoble-inp.fr}\unskip ,\penalty -2 \space \cdr@count@hasaddr =\z@ \ignorespaces \firstname {Louis-Marie} \lastname {Traonouez}\hasaddress {}{Thales Land and Air Systems, BU IAS, 35000, Rennes, France}\hasemail {}{louis-marie.traonouez@thalesgroup.com}\unskip , \penalty -1 \cdr@count@hasaddr =\z@ \firstname {Paul} \lastname {Théron}\hasaddress {}{AICA IWG, 06600, Antibes, France}\hasemail {}{paul.theron@orange.fr}}
    {french}
    {MOISE+MARL: an organizational framework for explainability and control in multi-agent reinforcement learning}
    {MOISE+MARL : un cadre organisationnel pour l’explicabilité et le contrôle en apprentissage par renforcement multi-agent}
    {\ignorespaces  Multi-agent reinforcement learning agents can develop interpretable behaviors such as implicit roles or objectives, suggesting a hypothetical emergent organization. To fully exploit this analogy, we introduce \textsc {MOISE+MARL}, an organizational framework that couples the organizational model $\mathcal {M}OISE^+$ with a Markovian model in order to improve both the control and the explainability of the learned policies. \textsc {MOISE+MARL} guides or constrains agents through roles and objectives by dynamically adjusting their actions and rewards, and integrates an analysis method that allows inferring implicit organizational specifications \textit {a posteriori} from the agents’ trajectories. \textsc {MOISE+MARL} was evaluated on four environments and several multi-agent reinforcement learning algorithms. The results show that agents’ policies converge faster, are more stable, and become more explainable. The analysis method is validated by the consistency between the predefined organizational specifications and the inferred ones. }
    {\ignorespaces  Des agents en apprentissage par renforcement multi-agent peuvent développer des comportements interprétables comme des rôles ou objectifs implicites, suggérant une hypothétique organisation émergente. Afin d’exploiter pleinement cette analogie, nous introduisons MOISE+MARL, un cadre organisationnel qui couple le modèle organisationnel $\mathcal {M}OISE^+$ à un modèle Markovien afin d’améliorer le contrôle et l’explicabilité des politiques apprises. MOISE+MARL guide ou contraint les agents selon des rôles et des objectifs en ajustant dynamiquement leurs actions et récompenses, et intègre une méthode d’analyse permettant d’inférer a posteriori des spécifications organisationnelles implicites à partir des trajectoires des agents. MOISE+MARL a été évalué sur quatre environnements et plusieurs algorithmes d'apprentissage par renforcement multi-agent. Les résultats montrent que les politiques des agents convergent plus rapidement, sont plus stables et deviennent plus explicables. La méthode d'analyse est confirmé par la cohérence entre les spécifications organisationnelles définies et celles inférées. }
    {1}
    {28}
\endgroup
