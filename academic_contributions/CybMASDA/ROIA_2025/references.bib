@inproceedings{soule2024paper-jfsma,
  author    = {Soule, Julien and Jamont, Jean-Paul and Occello, Michel and Traonouez, Louis-Marie and Théron, Paul},
  title     = {Une Approche bas{\'{e}}e sur l'Apprentissage par Renforcement pour l'Ing{\'{e}}nierie Organisationelle d'un {SMA}},
  booktitle = {32èmes
               journ{\'{e}}es francophones sur les syst{\`{e}}mes multi-agents},
  year      = {2024}
}

@inproceedings{maisonhaute2024,
  author    = {Tiziano Maisonhaute and
               Fabien Michel and
               Jean{-}Christophe Souli{\'{e}}},
  title     = {{\'{E}}tat de l'art sur les approches en apprentissage par renforcement
               multi-agent},
  booktitle = {32{\'{e}}me journ{\'{e}}es francophones sur les syst{\`{e}}mes multi-agents},
  year      = {2024}
}

@inproceedings{soule2024aomea,
  author    = {Soule, Julien and Jamont, Jean-Paul and Occello, Michel and Traonouez, Louis-Marie and Théron, Paul},
  title     = {A MARL-Based Approach for Easing {SMA} Organization Engineering},
  booktitle = {Proc. of the 20th Int. Conf. Artificial Intelligence Applications and Innovations},
  year      = {2024},
  doi       = {10.1007/978-3-031-63223-5\_24}
}

@article{soule2025moisemarl,
  title   = {An organizationally-Oriented Approach to Enhancing Explainability and Control in Multi-Agent Reinforcement Learning},
  author  = {Soule, Julien and Jamont, Jean-Paul and Occello, Michel and Traonouez, Louis-Marie and Théron, Paul},
  journal = {Proc. of the 24th Int. Conf. on Autonomous Agents and Multiagent Systems},
  year    = {2025},
  note    = {à paraitre}
}

@article{yu2021mappo,
  title   = {The Surprising Effectiveness of PPO in Cooperative Multi-Agent Games},
  author  = {{Chengjie Yu et al.}},
  journal = {NeurIPS},
  year    = {2021}
}

@inproceedings{akiba2019optuna,
  author    = {{Akiba Takuya et al.}},
  title     = {Optuna: A Next-generation Hyperparameter Optimization Framework},
  year      = {2019},
  isbn      = {9781450362016},
  doi       = {10.1145/3292500.3330701},
  booktitle = {Proc. of the 25th ACM SIGKDD Int. Conf. on Knowledge Discovery \& Data Mining}
}

@article{foerster2018counterfactual,
  title   = {Counterfactual multi-agent policy gradients},
  author  = {Foerster, Jakob and others},
  journal = {Int. Conf. on Machine Learning},
  year    = {2018}
}

@article{rashid2018qmix,
  title   = {QMIX: Monotonic value function factorisation for deep multi-agent reinforcement learning},
  author  = {{Tabish Rashid et al.}},
  journal = {Proc. of the 35th Int. Conf. on Machine Learning},
  year    = {2018}
}

@misc{Maxwell2021,
  title         = {CybORG: A Gym for the Development of Autonomous Cyber Agents},
  author        = {{Standen Maxwell et al.}},
  year          = {2021},
  eprint        = {2108.09118},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR}
}

@article{overcookedai,
  title   = {Overcooked-AI: A Benchmark for Multi-Agent Learning under Partial Observability},
  author  = {{Micah Carroll et al.}},
  journal = {Proc. of the IEEE/RSJ Int. Conf. on Intelligent Robots and Systems},
  year    = {2020}
}

@article{lowe2017multi,
  title   = {Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments},
  author  = {{Ryan Lowe et al.}},
  journal = {NeurIPS},
  year    = {2017},
  volume  = {30}
}

@article{hu2021marlib,
  title   = {MarlLib: A comprehensive library for multi-agent reinforcement learning},
  author  = {{Qi Hu et al.}},
  journal = {arXiv preprint arXiv:2106.05912},
  year    = {2021}
}

@misc{kwiatkowski2024,
  title         = {Gymnasium: A Standard Interface for Reinforcement Learning Environments},
  author        = {{Ariel Kwiatkowski et al.}},
  year          = {2024},
  eprint        = {2407.17032},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2407.17032}
}

@article{terry2020pettingzoo,
  title   = {PettingZoo: Gym for multi-agent reinforcement learning},
  author  = {{Justin K Terry et al.}},
  journal = {Proc. of the NeurIPS 2020 Track on Datasets and Benchmarks},
  year    = {2020}
}

@inproceedings{ferber2003,
  title     = {{Agent/Group/Roles: Simulating with Organizations}},
  author    = {Ferber, Jacques and Gutknecht, Olivier and Michel, Fabien},
  url       = {https://hal-lirmm.ccsd.cnrs.fr/lirmm-00269714},
  booktitle = {{4th Int. Workshop on Agent-Based Simulation}},
  year      = {2003}
}

@book{Oliehoek2016,
  title  = {A Concise Introduction to Decentralized POMDPs},
  author = {Frans A. Oliehoek and Christopher Amato},
  year   = {2016},
  isbn   = {978-3-319-28929-8},
  url    = {https://link.springer.com/book/10.1007/978-3-319-28929-8}
}

@inproceedings{Beynier2013,
  title     = {A Decentralized Approach for Reinforcement Learning in Cooperative Multi-agent Systems},
  author    = {Aurélie Beynier and Alain Mouaddib},
  booktitle = {Proc. of the 23rd Int. Joint Conf. on Artificial Intelligence},
  year      = {2013}
}

@article{Albrecht2024,
  title   = {Survey on Recent Advances in Cooperative Multi-Agent Reinforcement Learning},
  author  = {Stefano V. Albrecht and Jacob Y. Foerster},
  journal = {Journal of Artificial Intelligence Research},
  year    = {2024}
}

@inproceedings{achiam2017cpo,
  title     = {Constrained Policy Optimization},
  author    = {{Joshua Achiam et al.}},
  booktitle = {Proc. of the 34th Int. Conf. on Machine Learning},
  year      = {2017}
}

@inproceedings{ray2019benchmarking,
  title     = {Benchmarking Safe Exploration in Deep Reinforcement Learning},
  author    = {{Alex Ray et al.}},
  booktitle = {arXiv:1910.01708},
  year      = {2019}
}

@article{garcia2015comprehensive,
  title   = {A comprehensive survey on safe reinforcement learning},
  author  = {Garcia, Javier and Fernandez, Fernando},
  journal = {Journal of Machine Learning Research},
  year    = {2015}
}

@article{alshiekh2018safe,
  title   = {Safe reinforcement learning via shielding},
  author  = {{Mohammed Alshiekh et al.}},
  journal = {Proc. of the 32nd AAAI Conf. on Artificial Intelligence},
  year    = {2018}
}

@inproceedings{ghavamzadeh2006hrl,
  title     = {Hierarchical reinforcement learning with cooperative agents},
  author    = {Ghavamzadeh, Mohammad and Mahadevan, Sridhar},
  booktitle = {Proc. of the 23rd Int. Conf. on Machine Learning},
  year      = {2006}
}

@article{foerster2018communication,
  title   = {Learning to Communicate with Deep Multi-Agent Reinforcement Learning},
  author  = {{Jakob Foerster et al.}},
  journal = {NeurIPS},
  year    = {2018}
}

@inproceedings{wilson2008learning,
  title     = {Learning and transferring roles in multi-agent MDPs},
  author    = {{Andrew Wilson et al.}},
  booktitle = {Proc. of AAAI},
  year      = {2008}
}

@article{berenji2000learning,
  title   = {Learning, cooperation, and coordination in multi-agent systems},
  author  = {Berenji, Hamid R and Vengerov, David},
  journal = {Inference Systems Corporation, Technical report},
  year    = {2000}
}

@article{yusuf2020inferential,
  title   = {Inferential Reasoning for Heterogeneous Multi-Agent Missions},
  author  = {Yusuf, Sagir M and Baber, Christopher},
  journal = {Int. Journal of Electrical and Computer Engineering},
  year    = {2020}
}

@inproceedings{serrino2019finding,
  title     = {Finding Friend and Foe in Multi-Agent Games},
  author    = {Serrino, Jack and Kleiman-Weiner, Max and others},
  booktitle = {NeurIPS},
  year      = {2019}
}

@article{Hubner2007,
  title   = {Developing organised multiagent systems using the MOISE+ model: programming issues at the system and agent levels},
  issn    = {1746-1383},
  url     = {http://dx.doi.org/10.1504/IJAOSE.2007.016266},
  doi     = {10.1504/ijaose.2007.016266},
  journal = {Int. Journal of Agent-Oriented Software Engineering},
  author  = {{Hubner,  Jomi F et. al.}},
  year    = {2007}
}

@phdthesis{SaoMai2024,
  author = {Sao Mai, N.},
  title  = {The intrinsic motivation of reinforcement and imitation learning for sequential tasks},
  school = {HAL Archive},
  year   = {2024},
  url    = {https://hal.science/tel-04853270}
}

@article{Matsuyama2025,
  author        = {{K. Matsuyama et al.}},
  title         = {CORD: Generalizable Cooperation via Role Diversity},
  journal       = {arXiv preprint},
  year          = {2025},
  archiveprefix = {arXiv},
  eprint        = {2501.02221},
  url           = {https://arxiv.org/abs/2501.02221}
}

@article{Qi2024,
  author  = {Qi, Y. and Cao, J. and Wu, B.},
  title   = {Bidirectional Q-learning for recycling path planning of used appliances under strong and weak constraints},
  journal = {Communications in Transportation Research},
  year    = {2024},
  url     = {https://www.sciencedirect.com/science/article/pii/S2772424724000362}
}

@article{Xie2024,
  author  = {{Z. Xie et al.}},
  title   = {Roco: Role-Oriented Communication for Efficient Multi-Agent Reinforcement Learning},
  journal = {SSRN Electronic Journal},
  year    = {2024},
  url     = {https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5060074}
}

@incollection{Isakov2024,
  author    = {{A. Isakov et al.}},
  title     = {Cooperative-Competitive Decision-Making in Resource Management: A Reinforcement Learning Perspective},
  booktitle = {Advances in Machine Learning and Automated Learning},
  year      = {2024},
  doi       = {10.1007/978-3-031-77731-8_34},
  url       = {https://link.springer.com/chapter/10.1007/978-3-031-77731-8_34}
}

@article{Wen2024,
  author        = {{W. Wen et al.}},
  title         = {Role Play: Learning Adaptive Role-Specific Strategies in Multi-Agent Interactions},
  journal       = {arXiv preprint},
  year          = {2024},
  archiveprefix = {arXiv},
  eprint        = {2411.01166},
  url           = {https://arxiv.org/abs/2411.01166}
}
