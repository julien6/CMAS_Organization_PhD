@article{moerland2020model,
  title   = {Model-based reinforcement learning: A survey},
  author  = {Moerland, Thomas M and Broekens, Joost and Jonker, Catholijn M},
  journal = {arXiv preprint arXiv:2006.16712},
  year    = {2020}
}




@misc{hafner2020dream,
  title         = {Dream to Control: Learning Behaviors by Latent Imagination},
  author        = {Danijar Hafner and Timothy Lillicrap and Jimmy Ba and Mohammad Norouzi},
  year          = {2020},
  eprint        = {1912.01603},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/1912.01603}
}



@article{hochreiter1997long,
  title   = {Long short-term memory},
  author  = {Hochreiter, Sepp and Schmidhuber, Jürgen},
  journal = {Neural computation},
  volume  = {9},
  number  = {8},
  pages   = {1735--1780},
  year    = {1997}
}





@inProc.{gaia1998,
  title     = {The Gaia Methodology for Agent-Oriented Analysis and Design},
  author    = {Wooldridge, Michael and Jennings, Nicholas R. and Kinny, David},
  booktitle = {Autonomous Agents and Multi-Agent Systems},
  pages     = {285--312},
  year      = {1998}
}




@inProc.{adelfe2002,
  author    = {Bernon, Carole
               and Gleizes, Marie-Pierre
               and Peyruqueou, Sylvain
               and Picard, Gauthier},
  editor    = {Petta, Paolo
               and Tolksdorf, Robert
               and Zambonelli, Franco},
  title     = {ADELFE: A Methodology for Adaptive Multi-agent Systems Engineering},
  booktitle = {Engineering Societies in the Agents World III},
  year      = {2003},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {156--169},
  isbn      = {978-3-540-39173-9}
}



@INProc.{Jamont2007,
  author={Jamont, Jean-Paul and Occello, Michel},
  booktitle={19th IEEE Int. Conf. on Tools with Artificial Intelligence(ICTAI 2007)}, 
  title={Designing Embedded Collective Systems: The DIAMOND Multiagent Method}, 
  year={2007},
  volume={2},
  number={},
  pages={91-94},
  keywords={Artificial intelligence},
  doi={10.1109/ICTAI.2007.34}}




@article{ha2018recurrent,
  title   = {Recurrent world models facilitate policy evolution},
  author  = {Ha, David and Schmidhuber, Jürgen},
  journal = {arXiv preprint arXiv:1809.01999},
  year    = {2018}
}



@article{hu2022marllib,
  author  = {Hu, Bowen and others},
  title   = {MARLlib: A Scalable Multi-Agent Reinforcement Learning Library},
  journal = {arXiv preprint arXiv:2207.09981},
  year    = {2022}
}



@article{Jamont2O15,
  author  = {Jamont, Jean-Paul and Occello, Michel},
  title   = {Meeting the challenges of decentralised embedded applications using multi-agent systems},
  journal = {Int. Journal of Agent-Oriented Software Engineering},
  volume  = {5},
  number  = {1},
  pages   = {22-68},
  year    = {2015},
  doi     = {10.1504/IJAOSE.2015.078435},
  url     = {https://www.inderscienceonline.com/doi/abs/10.1504/IJAOSE.2015.078435},
  eprint  = { https://www.inderscienceonline.com/doi/pdf/10.1504/IJAOSE.2015.078435}
}




@article{lowe2017multi,
  author  = {Lowe, Ryan and Wu, Yi and others},
  title   = {Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  year    = {2017}
}




@article{spieker2021constraint,
  title   = {Constraint-Guided Reinforcement Learning: Augmenting the Agent-Environment-Interaction},
  author  = {Spieker, Helge},
  journal = {arXiv preprint arXiv:2104.11918},
  year    = {2021}
}





@article{kalweit2020deep,
  title   = {Deep Constrained Q-Learning},
  author  = {Kalweit, Gabriel and Huegle, Maria and Werling, Moritz and Boedecker, Joschka},
  journal = {arXiv preprint arXiv:2003.09398},
  year    = {2020}
}





@article{achiam2017constrained,
  title   = {Constrained Policy Optimization},
  author  = {Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  journal = {arXiv preprint arXiv:1705.10528},
  year    = {2017}
}




@article{Sims2008,
  author  = {Sims, Mark
             and Corkill, Daniel
             and Lesser, Victor},
  title   = {Automated organization design for multi-agent systems},
  journal = {Autonomous Agents and Multi-Agent Systems},
  year    = {2008},
  month   = {Apr},
  day     = {01},
  volume  = {16},
  number  = {2},
  pages   = {151-185},
  issn    = {1573-7454},
  doi     = {10.1007/s10458-007-9023-8},
  url     = {https://doi.org/10.1007/s10458-007-9023-8}
}



@article{harper2024autogenesisagent,
  title   = {AutoGenesisAgent: Self-Generating Multi-Agent Systems for Complex Tasks},
  author  = {Harper, Jeremy},
  journal = {arXiv preprint arXiv:2404.17017},
  year    = {2024}
}





@article{smith2024automated,
  title   = {Automated Design of Agentic Systems},
  author  = {Smith, John and Doe, Jane},
  journal = {arXiv preprint arXiv:2408.08435},
  year    = {2024}
}




@misc{crawford2024bmw,
  title         = {BMW Agents -- A Framework For Task Automation Through Multi-Agent Collaboration},
  author        = {Noel Crawford and Edward B. Duffy and Iman Evazzade and Torsten Foehr and Gregory Robbins and Debbrata Kumar Saha and Jiya Varma and Marcin Ziolkowski},
  year          = {2024},
  eprint        = {2406.20041},
  archiveprefix = {arXiv},
  primaryclass  = {cs.MA},
  url           = {https://arxiv.org/abs/2406.20041}
}



@article{zhou2025mentor,
  author   = {Zhou, Xinglin and Yuan, Yifu and Yang, Shaofu and Hao, Jianye},
  journal  = {IEEE Transactions on Emerging Topics in Computational Intelligence},
  title    = {MENTOR: Guiding Hierarchical Reinforcement Learning With Human Feedback and Dynamic Distance Constraint},
  year     = {2025},
  volume   = {9},
  number   = {2},
  pages    = {1292-1306},
  keywords = {Training;Hafnium;Reinforcement learning;Trajectory;Manuals;Computational intelligence;Uncertainty;Space exploration;Optimization;Dynamic scheduling;Dynamic distance constraint;hierarchical reinforcement learning;reinforcement learning from human feedback},
  doi      = {10.1109/TETCI.2025.3529902}
}




@inProc.{zabounidis2023concept,
  title     = {Concept Learning for Interpretable Multi-Agent Reinforcement Learning},
  author    = {Zabounidis, Renos and Campbell, Joseph and Stepputtis, Simon and Hughes, Dana and Sycara, Katia P.},
  booktitle = {Proc. of The 6th Conf. on Robot Learning},
  pages     = {1828--1837},
  year      = {2023},
  editor    = {Liu, Karen and Kulic, Dana and Ichnowski, Jeff},
  volume    = {205},
  series    = {Proc. of Machine Learning Research},
  month     = {14--18 Dec},
  publisher = {PMLR},
  pdf       = {https://Proc..mlr.press/v205/zabounidis23a/zabounidis23a.pdf},
  url       = {https://Proc..mlr.press/v205/zabounidis23a.html},
  abstract  = {Multi-agent robotic systems are increasingly operating in real-world environments in close proximity to humans, yet are largely controlled by policy models with inscrutable deep neural network representations. We introduce a method for incorporating interpretable concepts from a domain expert into models trained through multi-agent reinforcement learning, by requiring the model to first predict such concepts then utilize them for decision making. This allows an expert to both reason about the resulting concept policy models in terms of these high-level concepts at run-time, as well as intervene and correct mispredictions to improve performance. We show that this yields improved interpretability and training stability, with benefits to policy performance and sample efficiency in a simulated and real-world cooperative-competitive multi-agent game.}
}




@misc{iturria2024explainable,
  title         = {Explainable Multi-Agent Reinforcement Learning for Extended Reality Codec Adaptation},
  author        = {Pedro Enrique Iturria-Rivera and Raimundas Gaigalas and Medhat Elsayed and Majid Bavand and Yigit Ozcan and Melike Erol-Kantarci},
  year          = {2024},
  eprint        = {2411.14264},
  archiveprefix = {arXiv},
  primaryclass  = {cs.NI},
  url           = {https://arxiv.org/abs/2411.14264}
}




@article{liu2025,
  author   = {Liu, Zichuan and Zhu, Yuanyang and Wang, Zhi and Gao, Yang and Chen, Chunlin},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title    = {MIXRTs: Toward Interpretable Multi-Agent Reinforcement Learning via Mixing Recurrent Soft Decision Trees},
  year     = {2025},
  volume   = {47},
  number   = {5},
  pages    = {4090-4107},
  keywords = {Decision trees;History;Q-learning;Training;Visualization;Decision making;Knowledge engineering;Electronic mail;Data mining;Closed box;Explainable reinforcement learning;multi-agent reinforcement learning;recurrent structure;soft decision tree;value decomposition},
  doi      = {10.1109/TPAMI.2025.3540467}
}




@misc{poupart2025perspectives,
  title         = {Perspectives for Direct Interpretability in Multi-Agent Deep Reinforcement Learning},
  author        = {Yoann Poupart and Aurélie Beynier and Nicolas Maudet},
  year          = {2025},
  eprint        = {2502.00726},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2502.00726}
}



@misc{li2025from,
  title         = {From Explainability to Interpretability: Interpretable Policies in Reinforcement Learning Via Model Explanation},
  author        = {Peilang Li and Umer Siddique and Yongcan Cao},
  year          = {2025},
  eprint        = {2501.09858},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2501.09858}
}



@inProc.{miryoosefi2022,
  title     = {A Simple Reward-free Approach to Constrained Reinforcement Learning},
  author    = {Miryoosefi, Sobhan and Jin, Chi},
  booktitle = {Proc. of the 39th Int. Conf. on Machine Learning},
  pages     = {15666--15698},
  year      = {2022},
  editor    = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume    = {162},
  series    = {Proc. of Machine Learning Research},
  month     = {17--23 Jul},
  publisher = {PMLR},
  pdf       = {https://Proc..mlr.press/v162/miryoosefi22a/miryoosefi22a.pdf},
  url       = {https://Proc..mlr.press/v162/miryoosefi22a.html}
}





@inProc.{hammar2023scalable,
  author    = {Hammar, Kim
               and Stadler, Rolf},
  editor    = {Fu, Jie
               and Kroupa, Tomas
               and Hayel, Yezekael},
  title     = {Scalable Learning of Intrusion Response Through Recursive Decomposition},
  booktitle = {Decision and Game Theory for Security},
  year      = {2023},
  publisher = {Springer Nature Switzerland},
  address   = {Cham},
  pages     = {172--192},
  isbn      = {978-3-031-50670-3}
}




@inProc.{Pavon2003,
  author    = {Pav{\'o}n, Juan
               and G{\'o}mez-Sanz, Jorge},
  editor    = {Ma{\v{r}}{\'i}k, Vladim{\'i}r
               and P{\v{e}}chou{\v{c}}ek, Michal
               and M{\"u}ller, J{\"o}rg},
  title     = {Agent Oriented Software Engineering with INGENIAS},
  booktitle = {Multi-Agent Systems and Applications III},
  year      = {2003},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {394--403},
  abstract  = {INGENIAS is both a methodology and a set of tools for development of multi-agent systems (MAS). As a methodology, it tries to integrate results from other proposals and considers the MAS from five complementary viewpoints: organization, agent, tasks/goals, interactions, and environment. It is supported by a set of tools for modelling (graphical editor), documentation and code generation (for different agent platforms). INGENIAS is the result of the experience developing MAS in different areas, such as workflow management systems, recommender systems, Robocode teams, and PC assistants.},
  isbn      = {978-3-540-45023-8}
}





@inProc.{Bernon1999,
  author    = {Jennings, Nicholas R.},
  editor    = {Garijo, Francisco J.
               and Boman, Magnus},
  title     = {Agent-Oriented Software Engineering},
  booktitle = {Multi-Agent System Engineering},
  year      = {1999},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {1--7},
  abstract  = {Increasingly many computer systems are being viewed in terms of autonomous agents. Agents are being espoused as a new theoretical model of computation that more closely reflects current computing reality than Turing Machines. Agents are being advocated as the next generation model for engineering complex, distributed systems. Agents are also being used as an overarching framework for bringing together the component AI sub-disciplines that are necessary to design and build intelligent entities. Despite this intense interest, however, a number of fundamental questions about the nature and the use of agents remain unanswered. In particular:what is the essence of agent-based computing?what makes agents an appealing and powerful conceptual model?what are the drawbacks of adopting an agent-oriented approach?what are the wider implications for AI of agent-based computing?},
  isbn      = {978-3-540-48437-0}
}





@inProc.{Hindriks2014,
  author    = {Hindriks, Koen V.},
  editor    = {Dalpiaz, Fabiano
               and Dix, J{\"u}rgen
               and van Riemsdijk, M. Birna},
  title     = {The Shaping of the Agent-Oriented Mindset},
  booktitle = {Engineering Multi-Agent Systems},
  year      = {2014},
  publisher = {Springer Int. Publishing},
  address   = {Cham},
  pages     = {1--14},
  abstract  = {In the past twenty years we have seen an enormous growth and development of new techniques, technologies, and tools that support the engineering of Multi-Agent Systems (MAS). The 1990s perhaps are best characterized as the period in which the foundations were laid and the more theoretical underpinnings of the MAS field were explored. Besides a continuation of this foundational work, since 2000 the agent-based community has also been increasingly able to demonstrate the great potential for applying the MAS technology that has been developed in a very broad and diverse range of application domains.},
  isbn      = {978-3-319-14484-9}
}



@inbook{Zhang2021,
  author    = {Zhang, Kaiqing
               and Yang, Zhuoran
               and Ba{\c{s}}ar, Tamer},
  editor    = {Vamvoudakis, Kyriakos G.
               and Wan, Yan
               and Lewis, Frank L.
               and Cansever, Derya},
  title     = {Multi-Agent Reinforcement Learning: A Selective Overview of Theories and Algorithms},
  booktitle = {Handbook of Reinforcement Learning and Control},
  year      = {2021},
  publisher = {Springer Int. Publishing},
  address   = {Cham},
  pages     = {321--384},
  isbn      = {978-3-030-60990-0},
  doi       = {10.1007/978-3-030-60990-0_12}
}




@article{Anastassacos2020,
  title        = {Partner Selection for the Emergence of Cooperation in Multi-Agent Systems Using Reinforcement Learning},
  volume       = {34},
  url          = {https://ojs.aaai.org/index.php/AAAI/article/view/6190},
  doi          = {10.1609/aaai.v34i05.6190},
  abstractnote = {&lt;p&gt;Social dilemmas have been widely studied to explain how humans are able to cooperate in society. Considerable effort has been invested in designing artificial agents for social dilemmas that incorporate explicit agent motivations that are chosen to favor coordinated or cooperative responses. The prevalence of this general approach points towards the importance of achieving an understanding of both an agent's internal design and external environment dynamics that facilitate cooperative behavior. In this paper, we investigate how partner selection can promote cooperative behavior between agents who are trained to maximize a purely selfish objective function. Our experiments reveal that agents trained with this dynamic learn a strategy that retaliates against defectors while promoting cooperation with other agents resulting in a prosocial society},
  number       = {05},
  journal      = {Proc. of the AAAI Conf. on Artificial Intelligence},
  author       = {Anastassacos, Nicolas and Hailes, Stephen and Musolesi, Mirco},
  year         = {2020},
  month        = {Apr.},
  pages        = {7047-7054}
}





@inProc.{Papoudakis2021,
  author    = {Papoudakis, Georgios and Christianos, Filippos and Sch\"{a}fer, Lukas and Albrecht, Stefano},
  booktitle = {Proc. of the Neural Information Processing Systems Track on Datasets and Benchmarks},
  editor    = {J. Vanschoren and S. Yeung},
  pages     = {},
  title     = {Benchmarking Multi-Agent Deep Reinforcement Learning Algorithms in Cooperative Tasks},
  volume    = {1},
  year      = {2021}
}




@article{Nguyen2020,
  author  = {Nguyen, Thanh Thi and Nguyen, Ngoc Duy and Nahavandi, Saeid},
  journal = {IEEE Transactions on Cybernetics},
  title   = {Deep Reinforcement Learning for Multiagent Systems: A Review of Challenges, Solutions, and Applications},
  year    = {2020},
  volume  = {50},
  number  = {9},
  pages   = {3826-3839},
  doi     = {10.1109/TCYB.2020.2977374}
}




@misc{Yuan2023,
  title         = {A Survey of Progress on Cooperative Multi-agent Reinforcement Learning in Open Environment},
  author        = {Lei Yuan and Ziqian Zhang and Lihe Li and Cong Guan and Yang Yu},
  year          = {2023},
  eprint        = {2312.01058},
  archiveprefix = {arXiv},
  primaryclass  = {cs.MA},
  url           = {https://arxiv.org/abs/2312.01058}
}




@article{berenji2000learning,
  author = {Hamid, Dr and Berenji, R. and Vengerov, David},
  year   = {2000},
  month  = {11},
  pages  = {},
  title  = {Learning, Cooperation, and Coordination in Multi-Agent Systems}
}



@article{soule2025moisemarl,
  title   = {An organizationally-Oriented Approach to Enhancing Explainability and Control in Multi-Agent Reinforcement Learning},
  author  = {Soule, Julien and Jamont, Jean-Paul and Occello, Michel and Traonouez, Louis-Marie and Théron, Paul},
  journal = {Proc. of the 24th Int. Conf. on Autonomous Agents and Multiagent Systems},
  year    = {2025}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



@inProc.{yusuf2020inferential,
  author = {Yusuf, Sagir and Baber, Chris},
  year   = {2020},
  month  = {06},
  pages  = {},
  title  = {Inferential Reasoning for-Heterogeneous Multi-Agent-Mission}
}



@inProc.{serrino2019finding,
  author    = {Serrino, Jack and Kleiman-Weiner, Max and Parkes, David C and Tenenbaum, Josh},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Finding Friend and Foe in Multi-Agent Games},
  volume    = {32},
  year      = {2019}
}




@inProc.{akiba2019optuna,
  author    = {Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
  title     = {Optuna: A Next-generation Hyperparameter Optimization Framework},
  year      = {2019},
  isbn      = {9781450362016},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3292500.3330701},
  doi       = {10.1145/3292500.3330701},
  abstract  = {The purpose of this study is to introduce new design-criteria for next-generation hyperparameter optimization software. The criteria we propose include (1) define-by-run API that allows users to construct the parameter search space dynamically, (2) efficient implementation of both searching and pruning strategies, and (3) easy-to-setup, versatile architecture that can be deployed for various purposes, ranging from scalable distributed computing to light-weight experiment conducted via interactive interface. In order to prove our point, we will introduce Optuna, an optimization software which is a culmination of our effort in the development of a next generation optimization software. As an optimization software designed with define-by-run principle, Optuna is particularly the first of its kind. We will present the design-techniques that became necessary in the development of the software that meets the above criteria, and demonstrate the power of our new design through experimental results and real world applications. Our software is available under the MIT license (https://github.com/pfnet/optuna/).},
  booktitle = {Proc. of the 25th ACM SIGKDD Int. Conf. on Knowledge Discovery \& Data Mining},
  pages     = {2623-2631},
  numpages  = {9},
  keywords  = {machine learning system, hyperparameter optimization, black-box optimization, Bayesian optimization},
  location  = {Anchorage, AK, USA},
  series    = {KDD '19}
}




@misc{warehouse_management,
  title        = {Warehouse Management},
  author       = {Soulé, Julien},
  publisher    = {GitHub},
  year         = 2024,
  url          = {https://github.com/julien6/OMARLE},
  howpublished = {https://github.com/julien6/OMARLE}
}




@inProc.{Carroll2019,
  author    = {Carroll, Micah and Shah, Rohin and Ho, Mark K and Griffiths, Tom and Seshia, Sanjit and Abbeel, Pieter and Dragan, Anca},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {On the Utility of Learning about Humans for Human-AI Coordination},
  volume    = {32},
  year      = {2019}
}




@misc{Standen2021,
  title         = {CybORG: A Gym for the Development of Autonomous Cyber Agents},
  author        = {Maxwell Standen and Martin Lucas and David Bowman and Toby J. Richer and Junae Kim and Damian Marriott},
  year          = {2021},
  eprint        = {2108.09118},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR},
  url           = {https://arxiv.org/abs/2108.09118}
}




@article{Ha2018,
  doi       = {10.5281/ZENODO.1207631},
  url       = {https://zenodo.org/record/1207631},
  author    = {Ha, David and Schmidhuber, Jürgen},
  title     = {World Models},
  publisher = {Zenodo},
  year      = {2018},
  copyright = {Creative Commons Attribution 4.0}
}




@book{Oliehoek2016,
  author    = {Oliehoek, Frans A. and Amato, Christopher},
  title     = {A Concise Introduction to Decentralized POMDPs},
  year      = {2016},
  isbn      = {3319289276},
  publisher = {Springer Publishing Company, Incorporated},
  edition   = {1st},
  abstract  = {This book introduces multiagent planning under uncertainty as formalized by decentralized partially observable Markov decision processes (Dec-POMDPs). The intended audience is researchers and graduate students working in the fields of artificial intelligence related to sequential decision making: reinforcement learning, decision-theoretic planning for single agents, classical multiagent planning, decentralized control, and operations research.}
}




@inProc.{Matignon2007,
  author    = {Matignon, Laetitia and Laurent, Guillaume J. and Le Fort-Piat, Nadine},
  booktitle = {2007 IEEE/RSJ Int. Conf. on Intelligent Robots and Systems},
  title     = {Hysteretic Q-learning : an algorithm for Decentralized Reinforcement Learning in Cooperative Multi-Agent Teams},
  year      = {2007},
  volume    = {},
  number    = {},
  pages     = {64-69},
  keywords  = {Hysteresis;Learning;Robot kinematics;Multiagent systems;Distributed control;Convergence;Stochastic processes;Game theory;Intelligent robots;USA Councils},
  doi       = {10.1109/IROS.2007.4399095}
}





@inProc.{Hubner2002,
  author    = {H{\"u}bner, Jomi Fred
               and Sichman, Jaime Sim{\~a}o
               and Boissier, Olivier},
  editor    = {Bittencourt, Guilherme
               and Ramalho, Geber L.},
  title     = {A Model for the Structural, Functional, and Deontic Specification of Organizations in Multiagent Systems},
  booktitle = {Advances in Artificial Intelligence},
  year      = {2002},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {118--128},
  abstract  = {A Multiagent System (MAS) that explicitly represents its organization normally focuses either on the functioning or the structure of this organization. However, addressing both aspects is a prolific approach when one wants to design or describe a MAS organization. The problem is to define these aspects in such a way that they can be both assembled in a single coherent specification. The ℳOISE+ model --- described here through a soccer team example --- intends to be a step in this direction since the organization is seen under three points of view: structural, functional, and deontic.},
  isbn      = {978-3-540-36127-5}
}





@article{Hubner2007,
  author  = {Hubner, Jomi F. and Sichman, Jaime S. and Boissier, Olivier},
  title   = {Developing organised multiagent systems using the MOISE+ model: programming issues at the system and agent levels},
  journal = {Int. Journal of Agent-Oriented Software Engineering},
  volume  = {1},
  number  = {3-4},
  pages   = {370-395},
  year    = {2007},
  doi     = {10.1504/IJAOSE.2007.016266}
}
