\documentclass[11pt,a4paper,sans]{moderncv}        

\moderncvstyle{banking}
\moderncvcolor{red}                                
\usepackage{dirtytalk}
\usepackage[utf8]{inputenc}
\usepackage[scale=0.85]{geometry}
\usepackage{graphicx}
\usepackage{ragged2e}
\usepackage{setspace}
\usepackage{parskip}
\setstretch{1.05}

\AfterPreamble{
  \hypersetup{
    colorlinks=false,
    pdfborder={0 0 1},
    pdfborderstyle={/S/U/W 1},
    linkbordercolor={0 0 1},
    urlbordercolor={0 0 1},
    citebordercolor={0 0 1}
  }
}

\name{Julien}{Soulé}
\title{Postdoctoral Researcher Job No.~W24316, RIKEN Center for Advanced Intelligence Project}
\address{35 Rue Mathieu de la Drôme, Valence}{26000}{France}
\phone[mobile]{+33 6 77 63 12 13}
\email{julien.soule@hotmail.fr}
\homepage{julien6.github.io/home/}

\begin{document}

\recipient{\phantom{a}}{\phantom{a}}
\date{}
\opening{}
\closing{{\phantom{s}}}

\makelettertitle

\justifying

\vspace{-3cm}
\noindent
I am writing to express my strong interest in the Postdoctoral Researcher position in \textbf{Robot Learning} at the \textit{RIKEN Center for Advanced Intelligence Project}, within the \textit{Robot Learning Team}.
My research lies at the intersection of \textbf{Multi-Agent Systems (MAS)}, \textbf{Multi-Agent Reinforcement Learning (MARL)}, and \textbf{world-model learning}, with the overarching goal of developing principled frameworks that make robotic and multi-agent learning \textbf{interpretable}, \textbf{controllable}, and \textbf{systematically designable}.
During my PhD, I approached the design of intelligent systems as an optimization problem over a joint policy space constrained by both physical dynamics and high-level organizational structures encoding roles, goals, and safety requirements.
This formal yet pragmatic perspective naturally bridges \textbf{simulation-based MARL} and \textbf{embodied robot learning}, aligning with the Robot Learning Team’s mission to combine \textbf{Reinforcement Learning (RL)}, imitation learning, and motion planning to enable robots to learn complex and adaptive behaviors in the physical world.

\vspace{0.6em}
\section*{1. Research in the Past}

During my doctoral studies at \textit{Université Grenoble Alpes} (UGA) and \textit{Thales~LAS} (France), I developed a \textbf{methodological framework for assisting the design and training of MAS}, implemented in the open-source \href{https://github.com/julien6/CybMASDE}{\textbf{CybMASDE platform}}.
This framework supports the entire lifecycle of MAS development (from \textit{formal specification} to \textit{learning}, \textit{analysis}, and \textit{deployment}) by combining \textit{Dec-POMDP}-based modeling, \textbf{MARL} using environments such as \textit{Gym} and \textit{PettingZoo}, and scalable training backends (\textit{MARLlib}, \textit{JAX}/\textit{JaxMARL}).
In addition, I incorporated \textbf{unsupervised behavior analysis} tools to extract coordination patterns and latent organizational roles from simulation traces.
Bridging \textbf{symbolic organizational design} and \textbf{learning-based control}, this framework makes cooperative-system development more systematic and reproducible.
Agents learn under high-level constraints (roles and goals), yielding interpretable, constraint-aware behaviors.
Validated in simulation (e.g., drone fleets, cyber-defense), it readily transfers to \textbf{multi-robot learning} to improve coordination, data efficiency, and explainability.

\subsection*{Main contributions}

\begin{itemize}
  \item \textbf{MARL-assisted system design.}
        I proposed a methodological framework that formulates multi-agent system (MAS) design as a \textit{constrained policy-optimization problem}, integrating symbolic task structures with RL dynamics.
        The approach supports iterative \textbf{design--train--analyze--transfer} cycles, enabling systematic exploration of organizational configurations and learning architectures.
        Implemented in the \href{https://github.com/julien6/CybMASDE}{\textbf{CybMASDE platform}}, it provides automated evaluation tools and reproducible pipelines for multi-agent training in simulation \href{https://link.springer.com/chapter/10.1007/978-3-031-63223-5_24}{\textbf{(AIAI~2024)}}; \href{https://sciety-labs.elifesciences.org/articles/by?article_doi=10.21203/rs.3.rs-7166037/v1}{\textbf{(JAAMAS~2025, under revision)}}.
        This methodology offers a foundation for transferring learned coordination principles to multi-robot scenarios, where design--train--deploy cycles can facilitate collaborative skill acquisition.

  \item \textbf{Organization-guided MARL.}
        I designed an \href{https://github.com/julien6/MOISE-MARL}{\textbf{organization-oriented MARL framework}} that integrates symbolic constraints (roles, goals, and norms) into the training process.
        This formulation reduces non-stationarity and instability in decentralized training while ensuring safety and interpretability in complex tasks.
        Experiments demonstrated faster convergence and clearer role specialization \href{https://arxiv.org/abs/2503.23615}{\textbf{(AAMAS~2025)}}; \href{https://arxiv.org/abs/2505.21559}{\textbf{(IEEE CLOUD~2025)}}.
        These hierarchical and role-based structures extend naturally to robotics, where they can guide multi-arm manipulation, heterogeneous team coordination, and collaborative motion planning.

  \item \textbf{World-model-based multi-agent learning.}
        Building on \textbf{World Models} \href{https://link.springer.com/chapter/10.1007/978-3-031-63223-5_24}{(Ha \textit{et al.}, 2018)}, I extended this idea to multi-agent settings by learning latent generative models that capture both environmental and inter-agent dynamics.
        Implemented with \textit{PyTorch} and \textit{scikit-learn}, these models act as \textit{digital twins} for efficient model-based RL and planning under uncertainty.
        They support sample-efficient training and interpretable representation learning (crucial in robotics where data collection is expensive).
        I also explored theoretical aspects of model brittleness and causal interpretability \href{https://sciety-labs.elifesciences.org/articles/by?article_doi=10.21203/rs.3.rs-7166037/v1}{\textbf{(JAAMAS~2025, under revision)}}.
        These insights open the path toward \textbf{neuro-symbolic world-models} combining predictive accuracy with semantic structure.

  \item \textbf{Behavior analysis and explainability.}
        I developed trajectory-analysis methods leveraging Unsupervised Learning techniques that extract implicit roles, subgoals, and coordination patterns from agent behaviors.
        These techniques reveal organizational regularities in emergent coordination, providing post-hoc explanations for MARL outcomes \href{https://arxiv.org/abs/2503.23615}{\textbf{(AAMAS~2025)}}.
        In robotic systems, such tools could serve to monitor policy evolution, validate safety constraints, and enhance transparency in human-robot collaboration.
\end{itemize}

Together, these contributions establish a methodological continuum (from \textbf{modeling} to \textbf{learning}, \textbf{analysis}, and \textbf{transfer}) that unifies symbolic reasoning and learning-based control.
This foundation provides a stepping stone toward developing \textbf{adaptive, safe, and explainable robotic collectives}, aligning directly with the objectives of the RIKEN Robot Learning Team.

\vspace{0.6em}
\section*{2. Research Plan (2--3 Years)}
Building on the methodological foundations developed during my PhD, my wished postdoctoral project aims to advance the integration of \textbf{world-model learning}, \textbf{imitation learning}, and \textbf{RL} for embodied multi-robot systems, enabling robots to acquire, refine, and share \emph{cooperative skills} through predictive modeling, demonstrations, and interaction while preserving interpretability, safety, and structured control. This vision matches the \textit{RIKEN Robot Learning Team}'s mission to teach robots physical skills from limited experience using models, priors, and human demonstrations. The work is planned over two to three years in two phases: the first develops a unified predictive world-model framework and integrates it with imitation and RL for sample-efficient skill acquisition, and the second extends these principles to hierarchical coordination and human--robot collaboration to produce generalizable, explainable, and human-aligned robot behaviors. All experiments will pair simulation with real-robot validation, leveraging the team’s manipulation and cooperative-motion platforms.

\vspace{0.4em}
\subsection*{Short-Term Objectives (Years 1--2)}

\textbf{Objective 1 -- World-Model-Based Multi-Robot Learning.}
In the first stage, I plan to design a \textbf{shared latent world-model architecture} that jointly represents physical dynamics, inter-robot interactions, and task constraints.
Unlike traditional per-agent models, this shared predictive model will encode spatial and relational dependencies among robots and manipulated objects, allowing coordinated planning through a common latent representation.
The world-model will act as a simulation backbone for long-horizon prediction and uncertainty-aware policy optimization.
I aim to develop compact generative and contrastive models that fuse visual, proprioceptive, and task signals, combined with relational graph encoders and transformer dynamics to capture inter-agent structure.
Trained on cooperative tasks (dual-arm manipulation, collaborative transport, handover), these models are intended to enable sample-efficient model-based RL and safe sim-to-real transfer.

\textbf{Objective 2 -- Integrating Imitation and RL.}
To further accelerate learning and improve safety, I will integrate \textbf{imitation learning (IL)} and \textbf{RL} within the world-model framework.
The system will first use human or scripted demonstrations to acquire a coarse behavioral prior, then employ model-based RL to refine and generalize the learned skills.
This combination will be realized through \textbf{behavior cloning, offline RL, and model-predictive control (MPC)} using simulated rollouts generated by the world-model.
By performing most of the adaptation in predictive latent space, the approach minimizes hardware wear and mitigates risk during real-robot operation.


\textbf{Expected outcomes within two years:}
\begin{itemize}
  \item A reproducible \textbf{world-model-based framework} for multi-robot cooperation, integrating predictive modeling, imitation, and RL.
  \item \textbf{Open-source benchmark environments and datasets} for embodied multi-robot learning, designed in collaboration with the RIKEN Robot Learning Team.
  \item At least \textbf{one international conference publication} (e.g., ICRA, AAMAS, IROS, CoRL, RSS) and one \textbf{journal article} (IEEE~T-RO or RAL) demonstrating the benefits of predictive and imitation-guided multi-robot learning.
  \item At least one \textbf{robotic demonstration at RIKEN} showcasing cooperative manipulation, adaptive coordination, and safety-aware planning.
\end{itemize}

\vspace{0.4em}
\subsection*{Mid-Term Objectives (Years 3--4)}

\textbf{Objective 3 -- Hierarchical and Organizational Coordination.}
Building on the learned world-model framework, the second phase will focus on enabling \textbf{hierarchical and organization-aware control}.
The key objective is to allow robots to autonomously \emph{decompose tasks into subgoals}, \emph{allocate roles dynamically}, and \emph{coordinate at multiple time scales}. This will develop hierarchical policies linking low-level control and high-level task abstraction via the shared world-model.
I will explore \textbf{goal-conditioned hierarchical RL}, \textbf{transformer-based coordination}, and \textbf{option-based hierarchies} combined with symbolic constraints (roles, dependencies, safety).
The aim is to enforce \textbf{organizational consistency} (teams that satisfy task structure and safety) improving scalability and transfer, and extending my organization-guided MARL work to embodied robots.

\textbf{Objective 4 -- Human-Robot Collaboration and Explainability.}
In the later stage, I will extend the framework toward \textbf{human-robot collaboration}, aiming to make robot behaviors transparent, predictable, and aligned with human intent.
This will be achieved by incorporating \textbf{human feedback and imitation} into the learning loop (through preference-based RL, corrective demonstrations, or natural-language guidance) using the world-model as a safe simulator for iterative refinement. The robot will learn from demonstrations and use the world-model’s semantics to explain actions (e.g., via causal or goal-based analyses). By modeling human intent and interaction constraints, this advances trustworthy, human-compatible robotics. Experiments will show bidirectional adaptation in shared tasks like cooperative assembly and tool handling.

\textbf{Expected outcomes within three years:}
\begin{itemize}
  \item A unified \textbf{framework for hierarchical and explainable robot learning}, integrating organizational coordination, human feedback, and predictive modeling.
  \item At least \textbf{two high-impact journal papers} (e.g., IEEE~T-RO, Science Robotics, Autonomous Robots) and one \textbf{open-source release} demonstrating large-scale coordination and human-in-the-loop adaptation.
  \item \textbf{Collaborative multi-robot experiments at RIKEN} showcasing role allocation, cooperative manipulation, and interpretable action planning.
  \item Preparation of a \textbf{JSPS or EU project proposal} on \textit{Embodied Multi-Agent World Models for Human-Robot Collaboration}, establishing a bridge between RIKEN and international partners.
\end{itemize}


\vspace{0.4em}
\section*{Long-Term Perspectives}

My long-term objective is to pursue an \textbf{academic career} advancing \textbf{multi-agent learning}, \textbf{robotics}, and \textbf{representation learning}. I will focus on three complementary thrusts: (i) scalable hierarchical architectures that fuse symbolic task structure with learned latent dynamics for interpretable, safe coordination; (ii) open, reproducible benchmarks, datasets, and sim-to-real pipelines for embodied multi-robot learning; and (iii) human-in-the-loop methods to align robot objectives with human preferences and safety constraints. These efforts will be supported by open-source software, reproducible experiments, and clear evaluation protocols. I am also willing to help students, build interdisciplinary collaborations, secure competitive funding, and finally ensure my research produces practical, trustworthy robotic-based systems that meaningfully advance human progress and knowledge.

\vspace{-1cm}
\makeletterclosing

\end{document}
