\frametitle{Structured and Safe Model-Based Reinforcement Learning (MBRL)}

    \tikzstyle{box}=[rectangle, rounded corners, draw=blue!60, fill=blue!5, thick,
    text width=9.5cm, align=left, inner sep=5pt]
    \tikzstyle{arrow}=[-Stealth, thick, blue!60]

    \centering
    \begin{tikzpicture}[node distance=0.8cm]
        % --- RL Fundamentals ---
        \node[box] (rl) {
            \textbf{Reinforcement Learning (RL)}\\
            \textit{MDP:} learn policy $\pi(a|s)$ to maximize expected reward.\\
            Model-Free (PPO, SAC) vs. Model-Based (Dreamer, PETS).\\
            Foundations: $S$, $A$, $P$, $R$, $\gamma$.
        };

        % --- Model-Based RL ---
        \node[box, below=of rl] (mbrl) {
        \textbf{Model-Based RL (World Models)}\\
        Learn environment dynamics $f_\theta(s,a)\!\to\!s'$.\\
        \textit{Components:} encoder, dynamics, decoder.\\
        Benefits: efficiency, planning, counterfactuals, safety.\\
        Issues: model bias, OOD generalization.\\
        {\footnotesize Ha \& Schmidhuber (2018), Hafner et al. (DreamerV3, 2023)}
        };

        % --- Structure ---
        \node[box, below=of mbrl] (structure) {
        \textbf{Structural Bias \& Inductive Priors}\\
        Embed hierarchy, symmetry, modularity, graphs.\\
        Improves interpretability and generalization.\\
        {\footnotesize Mohan, Zhang \& Lindauer (JAIR 2024)}
        };

        % --- Neurosymbolic ---
        \node[box, below=of structure] (neurosym) {
        \textbf{Neurosymbolic / Physics-Informed Models}\\
        Combine neural latent dynamics with symbolic rules or physical laws.\\
        Methods: differentiable logic, PINNs, graph predicates.\\
        My link: integrate MOISE+ roles/goals as symbolic priors.\\
        {\footnotesize Djeumou et al. (L4DC 2022)}
        };

        % --- Compositionality ---
        \node[box, below=of neurosym] (comp) {
        \textbf{Compositional Reasoning for Safety}\\
        Decompose world model into modules (perception, dynamics, constraints).\\
        Verify each module separately for scalable safety.\\
        {\footnotesize Bakirtzis et al. (JMLR 2025)}
        };

        % --- Safety ---
        \node[box, below=of comp] (safety) {
            \textbf{Safety-Constrained RL \& Verification}\\
            Formulation: Constrained MDPs, Lagrangian methods, shields, barrier functions.\\
            Logic-based specs (LTL/STL) and runtime monitoring.\\
            Embed constraints inside world model (logic layers).\\
            Metrics: violation rate, safe-return, OOD robustness.
        };

        % --- Multiobjective ---
        \node[box, below=of safety] (multi) {
        \textbf{Multi-Objective / Preference-Based RL}\\
        Balance safety vs. performance; Pareto optimization, successor features.\\
        {\footnotesize Felten et al. (JAIR 2024), Yang et al. (ICML 2025)}
        };

        % --- My Research ---
        \node[box, below=of multi] (mine) {
            \textbf{My Research Line: MAMAD $\rightarrow$ Structured MBRL}\\
            MAMAD: hybrid MARL + MOISE+ for structured MAS design.\\
            TEMM: unsupervised role discovery for explainability.\\
            CybMASDE: end-to-end MAS design/training platform.\\
            Next: modular, neurosymbolic world models for safe MBRL.\\
            \textit{Projects:} Constraint-Aware Dreamer; Graph-Constraint World Models.
        };

        % --- arrows ---
        \draw[arrow] (rl) -- (mbrl);
        \draw[arrow] (mbrl) -- (structure);
        \draw[arrow] (structure) -- (neurosym);
        \draw[arrow] (neurosym) -- (comp);
        \draw[arrow] (comp) -- (safety);
        \draw[arrow] (safety) -- (multi);
        \draw[arrow] (multi) -- (mine);

    \end{tikzpicture}

