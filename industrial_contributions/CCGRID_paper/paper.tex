\RequirePackage[2020-02-02]{latexrelease}
\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.

\usepackage{xcolor}
\usepackage[hang, flushmargin]{footmisc}
\usepackage[
colorlinks=false, % don't highlight links in color
linkbordercolor=green, % set border color for internal links
citebordercolor=green, % set border color for citations
filebordercolor=magenta, % set border color for file links
urlbordercolor=cyan, % set border color for URLs
pdfborder={0 0 1}, % determine border around links
linkcolor=black,
citecolor=black,
filecolor=black,
urlcolor=black,
]{hyperref}
\usepackage{footnotebackref}

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\usepackage[english]{babel}
\addto\extrasenglish{  
    \def\figureautorefname{Figure}
    \def\tableautorefname{Table}
    \def\algorithmautorefname{Algorithm}
    \def\sectionautorefname{Section}
    \def\subsectionautorefname{Subsection}
}

\newcommand{\supertiny}{\fontsize{1}{2}\selectfont}

\usepackage{catoptions}
\makeatletter

\def\Autoref#1{%
  \begingroup
  \edef\reserved@a{\cpttrimspaces{#1}}%
  \ifcsndefTF{r@#1}{%
    \xaftercsname{\expandafter\testreftype\@fourthoffive}
      {r@\reserved@a}.\\{#1}%
  }{%
    \ref{#1}%
  }%
  \endgroup
}
\def\testreftype#1.#2\\#3{%
  \ifcsndefTF{#1autorefname}{%
    \def\reserved@a##1##2\@nil{%
      \uppercase{\def\ref@name{##1}}%
      \csn@edef{#1autorefname}{\ref@name##2}%
      \autoref{#3}%
    }%
    \reserved@a#1\@nil
  }{%
    \autoref{#3}%
  }%
}
\makeatother

\usepackage[T1]{fontenc}
\usepackage{graphicx}
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}

\usepackage{amsmath,amssymb,amsfonts}
\usepackage[inline, shortlabels]{enumitem}
\usepackage{tabularx}
\usepackage{caption}
\usepackage{listings}
% \usepackage{titlesec}
\usepackage{ragged2e}

\usepackage{xurl}
% \usepackage[hyphens]{url}
\usepackage{pifont}
\usepackage{multirow}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{float}
\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
 
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
 
\lstset{style=mystyle}

% --- Tickz
\usepackage{physics}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{mathdots}
\usepackage{yhmath}
\usepackage{cancel}
\usepackage{color}
\usepackage{siunitx}
\usepackage{array}
\usepackage{multirow}
\usepackage{amssymb}
\usepackage{gensymb}
\usepackage{tabularx}
\usepackage{extarrows}
\usepackage{booktabs}
\usetikzlibrary{fadings}
\usetikzlibrary{patterns}
\usetikzlibrary{shadows.blur}
\usetikzlibrary{shapes}

% ---------
% \usepackage{titlesec}
\usepackage{pdfpages}
\usepackage{booktabs}
\usepackage{csquotes}
\usepackage{lipsum}  
\usepackage{arydshln}
\usepackage{smartdiagram}
\usepackage{textcomp}
\usepackage{tabularray}\UseTblrLibrary{varwidth}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\usepackage{cite}
\usepackage{amsmath}
\newcommand{\probP}{\text{I\kern-0.15em P}}
\usepackage{etoolbox}
\patchcmd{\thebibliography}{\section*{\refname}}{}{}{}

\setlength\tabcolsep{0.5pt}

\newcommand{\before}[1]{\textcolor{red}{#1}}
\newcommand{\after}[1]{\textcolor{green}{#1}}

\newcommand{\old}[1]{\textcolor{orange}{#1}}
\newcommand{\rem}[1]{\textcolor{red}{#1}}
\newcommand{\todo}[1]{\textcolor{orange}{\newline \textit{\textbf{TODO:} #1}} \newline \newline }



\newcounter{relation}
\setcounter{relation}{0}
\renewcommand{\therelation}{\arabic{relation}}
\newcommand{\relationautorefname}{Relation}

\newenvironment{relation}[1][]{%
    \refstepcounter{relation}%
    \noindent \raggedright \textit{\textbf{Relation. \therelation}} \hfill$}
{%
$ \hfill \phantom{x}

}

\makeatletter
\newcommand{\linebreakand}{%
  \end{@IEEEauthorhalign}
  \hfill\mbox{}\par
  \mbox{}\hfill\begin{@IEEEauthorhalign}
}
\makeatother

% =======================================

\begin{document}

\title{Hybrid MARL and Organizational Models for Optimizing Horizontal Scalability in Kubernetes}

\author{

    \IEEEauthorblockN{Julien Soulé}
    \IEEEauthorblockA{\textit{Thales LAS / IAS / La Ruche}}
    %Rennes, France \\
    \IEEEauthorblockA{\textit{Univ. Grenoble Alpes,} \\
        \textit{Grenoble INP, LCIS, 26000,}\\
        Valence, France \\
        julien.soule@lcis.grenoble-inp.fr}

    \and

    \IEEEauthorblockN{Louis-Marie Traonouez}
    \IEEEauthorblockA{\textit{Thales LAS / IAS / La Ruche} \\
        Rennes, France \\
        louis-marie.traonouez@thalesgroup.com}

    % }

    % \and

    \linebreakand

    \hspace{1.8cm}
    \IEEEauthorblockN{Paul Théron}
    \IEEEauthorblockA{
        \hspace{1.8cm}
        \textit{AICA IWG} \\
        \hspace{1.8cm}
        La Guillermie, France \\
        %lieu-dit Le Bourg, France \\
        \hspace{1.8cm}
        paul.theron@orange.fr}

    \and

    \hspace{0.3cm}
    \IEEEauthorblockN{Jean-Paul Jamont\IEEEauthorrefmark{1}, Michel Occello\IEEEauthorrefmark{2}}
    \IEEEauthorblockA{
        \hspace{0.3cm}
        \textit{Univ. Grenoble Alpes,} \\
        \hspace{0.3cm}
        \textit{Grenoble INP, LCIS, 26000,}\\
        \hspace{0.3cm}
        Valence, France \\
        \hspace{0.3cm}
        \{\IEEEauthorrefmark{1}jean-paul.jamont,\IEEEauthorrefmark{2}michel.occello\}@lcis.grenoble-inp.fr
    }
}

% \IEEEauthorblockN{Michel Occello}
% \IEEEauthorblockA{\textit{Univ. Grenoble Alpes,} \\
% \textit{Grenoble INP, LCIS, 26000,}\\
% Valence, France \\
% michel.occello@lcis.grenoble-inp.fr}

% ================ CONFERENCE INSTRUCTIONS ========================
% Deadline paper abstract: 1st of October
% Deadline paper: 13th of December
% Format: IEEE double columns, 10 pages max
% =================================================================

\maketitle

\begin{abstract}
    Kubernetes has become the de facto container orchestration platform for cloud-native applications. However, auto-scaling mechanisms such as Horizontal Pod Autoscaler (HPA) struggle in dynamically adapting to complex service chains with varying processing speeds, leading to bottlenecks. In this paper, we propose a novel Multi-Agent Reinforcement Learning (MARL) approach to optimize dynamic replica orchestration in Kubernetes. Our method trains agents to predict future resource needs and adjust replicas accordingly, addressing bottlenecks in service chains. We evaluate the approach through simulations and validate it in an emulated Kubernetes environment. Results show that MARL-based orchestration significantly reduces latency and improves resource utilization compared to existing auto-scaling methods.
\end{abstract}

\begin{IEEEkeywords}
    Kubernetes, Reinforcement Learning, Multi-Agent Systems, Auto-scaling, Microservices, Cloud Computing
\end{IEEEkeywords}

\section{Introduction}
Kubernetes has emerged as the dominant platform for container orchestration, particularly for managing microservices-based applications in the cloud. One of Kubernetes' key features is its ability to automatically scale applications based on demand, primarily using Horizontal Pod Autoscaler (HPA). However, HPA and similar methods are reactive and often inadequate for complex service chains where different services may process data at different speeds, leading to bottlenecks.

In this paper, we address this limitation by proposing a Multi-Agent Reinforcement Learning (MARL) approach to dynamically orchestrate replicas in a Kubernetes environment. Unlike traditional scaling methods, our approach enables distributed learning among agents, allowing them to anticipate and mitigate bottlenecks by adjusting the number of replicas in real-time.

Our contributions are threefold:
\begin{itemize}
    \item We propose a MARL-based framework for dynamic replica orchestration in Kubernetes.
    \item We develop a simulation and emulation tool to train and validate the MARL agents in Kubernetes-like environments.
    \item We demonstrate the effectiveness of our approach through extensive simulations and experiments, showing significant improvements over existing methods.
\end{itemize}

The rest of the paper is organized as follows. Section II reviews related work. Section III presents our proposed MARL-based orchestration framework. Section IV details the simulation and experimental setup. Section V presents the results and discusses the findings. Section VI introduces the tool we developed, and Section VII concludes the paper with future research directions.

\section{Related Work}
Kubernetes' default auto-scaling mechanisms, HPA and VPA, have been widely adopted but suffer from limitations in dynamic environments with complex service chains. Existing approaches in both industry and academia focus on reactive threshold-based or single-agent reinforcement learning methods. However, these do not adequately address the challenges posed by interdependent services with varying processing capacities. 

For example, Toka et al. \cite{toka2020} proposed an AI-based auto-scaling solution that uses reinforcement learning for Kubernetes. However, their approach does not focus on service chains or MARL. Similarly, other works such as \cite{related1,related2} address container orchestration using machine learning but do not incorporate MARL for replica management in chained services.

Our work fills this gap by leveraging MARL to orchestrate replicas dynamically in service chains, thus improving performance in scenarios where existing methods fall short.

\section{Proposed Approach}
\subsection{Problem Formulation}
The orchestration problem in Kubernetes arises when services are chained together, and each service processes data at different speeds. This leads to bottlenecks, which degrade overall system performance. Our goal is to dynamically manage the number of replicas for each service to avoid these bottlenecks.

\subsection{Multi-Agent Reinforcement Learning Framework}
We design a MARL framework where each agent corresponds to a pod or a group of pods in the Kubernetes cluster. The agents are trained to make scaling decisions based on local and global state observations, such as incoming traffic, current load, and inter-service dependencies. 

We use reinforcement learning algorithms like Q-Learning and Deep Q-Network (DQN) to enable agents to learn optimal scaling policies. The reward function is designed to minimize latency and maximize throughput while keeping resource utilization within acceptable bounds.

\subsection{Simulation Environment}
To validate our approach, we simulate a Kubernetes environment with chained services. The simulation includes custom controllers to manage the dynamic behavior of services, and agents are trained in this environment to optimize replica management. Once trained, the agents are deployed in an emulated Kubernetes environment for real-world validation.

\section{Simulation and Experimental Setup}
\subsection{Scenario Design}
We evaluate our MARL-based orchestration approach in several scenarios:
\begin{itemize}
    \item \textbf{Static Load Scenario:} The system experiences a constant load, and agents manage replicas to maintain an optimal performance level.
    \item \textbf{Dynamic Load Scenario:} The load varies significantly over time, and agents must dynamically adjust replicas to avoid bottlenecks.
    \item \textbf{Complex Service Chain Scenario:} Multiple services are chained together, and agents manage replicas to ensure smooth data flow across the services.
\end{itemize}

\subsection{Tools and Metrics}
We use a combination of Kubernetes emulators, Prometheus for monitoring, and custom scripts to simulate different load patterns. Key performance metrics include latency, throughput, and resource utilization.

\section{Results}
\subsection{Simulation Results}
Our simulations show that the MARL-based approach significantly outperforms traditional auto-scaling methods in terms of reducing latency and improving throughput. In scenarios with complex service chains, the MARL agents effectively anticipate bottlenecks and adjust replicas accordingly.

\subsection{Comparison with Baselines}
We compare our results with standard Kubernetes autoscaling mechanisms such as HPA. The MARL-based approach consistently achieves better performance, particularly in dynamic environments with fluctuating loads.

\section{Tool and Framework}
We developed a simulation and emulation tool that can be used by researchers and practitioners to test various orchestration strategies in Kubernetes. The tool allows for the easy configuration of different scenarios and provides detailed performance metrics for analysis.

\section{Conclusion}
In this paper, we presented a novel MARL-based approach to dynamic replica orchestration in Kubernetes. Our method addresses the limitations of existing auto-scaling mechanisms by enabling distributed learning and decision-making among pods. The results from our simulations and experiments demonstrate that MARL can significantly improve performance in complex service chain environments. Future work will focus on extending the approach to more diverse environments and exploring other reinforcement learning algorithms.

\section*{Acknowledgment}

This work was supported by \emph{Thales Land Air Systems} within the framework of the \emph{Cyb'Air} chair and the \emph{AICA IWG}

\section*{References}

% \bibliographystyle{abbrv}
\bibliographystyle{IEEEtran}

\bibliography{references}

\end{document}
