\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage[inline, shortlabels]{enumitem}
\usepackage{tabularx}
\usepackage{caption}
\usepackage{titlesec}
\usepackage[T2A,T1]{fontenc}
\usepackage[english]{babel}
\captionsetup{font=it}
\usepackage{ragged2e}
\usepackage{hyperref}
\addto\extrasenglish{%
  \renewcommand{\sectionautorefname}{Section}%
  \renewcommand{\subsectionautorefname}{Subsection}%
  \renewcommand{\subsubsectionautorefname}{Subsubsection}%
  \renewcommand{\tableautorefname}{Table}%
  \renewcommand{\figureautorefname}{Figure}%
}
\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\usepackage{footmisc}
\usepackage{multirow}

% --- Tickz
\usepackage{physics}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{mathdots}
\usepackage{yhmath}
\usepackage{cancel}
\usepackage{color}
\usepackage{siunitx}
\usepackage{array}
\usepackage{multirow}
\usepackage{amssymb}
\usepackage{gensymb}
\usepackage{tabularx}
\usepackage{extarrows}
\usepackage{booktabs}
\usetikzlibrary{fadings}
\usetikzlibrary{patterns}
\usetikzlibrary{shadows.blur}
\usetikzlibrary{shapes}

% ---------

\usepackage{pdfpages}
\usepackage{booktabs}
\usepackage{csquotes}
\usepackage{lipsum}  
\usepackage{arydshln}
\usepackage{smartdiagram}
\usepackage[inkscapeformat=png]{svg}
\usepackage{textcomp}
\usepackage{tabularray}\UseTblrLibrary{varwidth}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\usepackage{cite}
\usepackage{amsmath}
\newcommand{\probP}{\text{I\kern-0.15em P}}
\usepackage{etoolbox}
\patchcmd{\thebibliography}{\section*{\refname}}{}{}{}

\setlength{\extrarowheight}{2.5pt}

% \renewcommand{\arraystretch}{1.7}

% \setlength{\extrarowheight}{2.5pt}
% \renewcommand{\arraystretch}{0.2}
% \renewcommand{\arraystretch}{1.7}

% --------------
\titleclass{\subsubsubsection}{straight}[\subsection]

\newcounter{subsubsubsection}[subsubsection]
\renewcommand\thesubsubsubsection{\thesubsubsection.\arabic{subsubsubsection}}
\renewcommand\theparagraph{\thesubsubsubsection.\arabic{paragraph}} % optional; useful if paragraphs are to be numbered

\titleformat{\subsubsubsection}
  {\normalfont\normalsize\bfseries}{\thesubsubsubsection}{1em}{}
\titlespacing*{\subsubsubsection}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{5}{\z@}%
  {3.25ex \@plus1ex \@minus.2ex}%
  {-1em}%
  {\normalfont\normalsize\bfseries}}
\renewcommand\subparagraph{\@startsection{subparagraph}{6}{\parindent}%
  {3.25ex \@plus1ex \@minus .2ex}%
  {-1em}%
  {\normalfont\normalsize\bfseries}}
\def\toclevel@subsubsubsection{4}
\def\toclevel@paragraph{5}
\def\toclevel@paragraph{6}
\def\l@subsubsubsection{\@dottedtocline{4}{7em}{4em}}
\def\l@paragraph{\@dottedtocline{5}{10em}{5em}}
\def\l@subparagraph{\@dottedtocline{6}{14em}{6em}}
\makeatother

\usepackage{enumitem}
\setlistdepth{9}


% --------------


\newcommand{\before}[1]{\textcolor{red}{#1}}
\newcommand{\after}[1]{\textcolor{green}{#1}}

\newcommand{\old}[1]{\textcolor{orange}{#1}}
\newcommand{\rem}[1]{\textcolor{red}{#1}}
\newcommand{\todo}[1]{\textcolor{orange}{\newline \textit{\textbf{TODO:} #1}} \newline \newline }

\makeatletter
\newcommand{\linebreakand}{%
  \end{@IEEEauthorhalign}
  \hfill\mbox{}\par
  \mbox{}\hfill\begin{@IEEEauthorhalign}
}
\makeatother


% ---------------------------


\begin{document}

\title{Digital Twin-Driven MARL for Optimal Horizontal Scaling in Kubernetes Environments\\
    % {\footnotesize \textsuperscript{Note}}
    % \thanks{Identify applicable funding agency here. If none, delete this.}
}

% \IEEEaftertitletext{\vspace{-1\baselineskip}}

\author{

    \IEEEauthorblockN{Julien Soulé}
    \IEEEauthorblockA{\textit{Thales Land and Air Systems, BU IAS}}
    %Rennes, France \\
    \IEEEauthorblockA{\textit{Univ. Grenoble Alpes,} \\
        \textit{Grenoble INP, LCIS, 26000,}\\
        Valence, France \\
        julien.soule@lcis.grenoble-inp.fr}

    \and

    \IEEEauthorblockN{Jean-Paul Jamont\IEEEauthorrefmark{1}, Michel Occello\IEEEauthorrefmark{2}}
    \IEEEauthorblockA{\textit{Univ. Grenoble Alpes,} \\
        \textit{Grenoble INP, LCIS, 26000,}\\
        Valence, France \\
        \{\IEEEauthorrefmark{1}jean-paul.jamont,\IEEEauthorrefmark{2}michel.occello\}@lcis.grenoble-inp.fr
    }

    % \and

    % \IEEEauthorblockN{Michel Occello}
    % \IEEEauthorblockA{\textit{Univ. Grenoble Alpes,} \\
    % \textit{Grenoble INP, LCIS, 26000,}\\
    % Valence, France \\
    % michel.occello@lcis.grenoble-inp.fr}

    % \and

    \linebreakand

    \hspace{-0.5cm}
    \IEEEauthorblockN{Paul Théron}
    \IEEEauthorblockA{
        \hspace{-0.5cm}
        \textit{AICA IWG} \\
        \hspace{-0.5cm}
        La Guillermie, France \\
        \hspace{-0.5cm}
        %lieu-dit Le Bourg, France \\
        paul.theron@orange.fr}

    \and

    \hspace{0.5cm}
    \IEEEauthorblockN{Louis-Marie Traonouez}
    \IEEEauthorblockA{
        \hspace{0.5cm}
        \textit{Thales Land and Air Systems, BU IAS} \\
        \hspace{0.5cm}
        Rennes, France \\
        \hspace{0.5cm}
        louis-marie.traonouez@thalesgroup.com}}


\maketitle

\begin{abstract}
    \begin{itemize}
        \item \textbf{Context:} Cloud-native applications grow in complexity, requiring dynamic adaptability for resource allocation in Kubernetes.
        \item \textbf{Problem:} Conventional autoscaling lacks granularity for interconnected services under fluctuating workloads.
        \item \textbf{Contribution:}
        \begin{itemize}
            \item Use of a Digital Twin for optimizing resource allocation.
            \item Multi-Agent Reinforcement Learning (MARL) training for dynamic adjustments in Kubernetes.
        \end{itemize}
        \item \textbf{Results:} Improved resource efficiency and reduced bottlenecks compared to Kubernetes' Horizontal Pod Autoscaler.
    \end{itemize}
    \end{abstract}
    
    \begin{IEEEkeywords}
    cyberdefense, MARL, Digital Twins, formal
    \end{IEEEkeywords}
    
    \section{Introduction}
\begin{itemize}
    \item \textbf{Background:}
    \begin{itemize}
        \item The shift from monolithic architectures to microservices has become the \textit{de-facto} standard for deploying cloud-native applications \cite{dragoni2017microservices, larrucea2018microservices}.
        \item Microservice architectures provide several advantages, including:
        \begin{itemize}
            \item Increased \textbf{flexibility} in deployment and maintenance.
            \item Enhanced \textbf{scalability} and performance optimization.
            \item Improved \textbf{operational efficiency}, especially in large-scale distributed environments \cite{schneider2016connected}.
        \end{itemize}
    \end{itemize}

    \item \textbf{Challenges:}
    \begin{itemize}
        \item Despite their benefits, microservices introduce several orchestration challenges, such as:
        \begin{itemize}
            \item Managing \textbf{complex interdependencies} between services.
            \item Ensuring \textbf{efficient resource allocation} in dynamic environments.
            \item Meeting the stringent \textbf{quality-of-service (QoS)} requirements of modern applications \cite{qu2018autoscaling}.
        \end{itemize}
        \item Emerging application domains, such as Extended Reality (XR), Industrial Internet of Things (IIoT), and autonomous vehicles, impose additional demands on cloud infrastructures \cite{giordani2020toward, santos2021towards}.
        \begin{itemize}
            \item These applications require:
            \begin{itemize}
                \item \textbf{Low latency} to support real-time interactions.
                \item \textbf{High reliability} to prevent failures in critical systems.
                \item \textbf{Scalability} to accommodate fluctuating workloads.
            \end{itemize}
        \end{itemize}
    \end{itemize}

    \item \textbf{Resource Scaling in Kubernetes:}
    \begin{itemize}
        \item Kubernetes (K8s) is a leading platform for managing containerized microservices \cite{burns2019kubernetes}.
        \item Resource scaling in Kubernetes primarily involves:
        \begin{itemize}
            \item \textbf{Horizontal scaling:} Adjusting the number of pod replicas to match workload demands.
            \item \textbf{Vertical scaling:} Modifying the resource allocation (CPU, memory) for existing pods.
        \end{itemize}
        \item However, traditional Kubernetes autoscaling mechanisms, such as the Horizontal Pod Autoscaler (HPA) \cite{kubernetesHPA}, have several limitations:
        \begin{itemize}
            \item They rely on \textbf{threshold-based policies}, which:
            \begin{itemize}
                \item Require manual configuration of thresholds.
                \item Do not account for microservice interdependencies.
            \end{itemize}
            \item They focus primarily on \textbf{CPU and memory usage}, neglecting other critical metrics like latency and bandwidth.
        \end{itemize}
    \end{itemize}

    \item \textbf{Motivation:}
    \begin{itemize}
        \item Efficient resource scaling must address the following gaps:
        \begin{itemize}
            \item Incorporating \textbf{microservice dependencies} into scaling decisions.
            \item Optimizing both \textbf{resource utilization} and \textbf{application performance}.
            \item Adapting dynamically to \textbf{fluctuating workloads} and complex workflows.
        \end{itemize}
        \item Reinforcement Learning (RL) presents a promising solution:
        \begin{itemize}
            \item RL agents can learn to optimize scaling actions based on real-time feedback.
            \item Unlike traditional methods, RL does not require explicit threshold definitions.
            \item RL can consider diverse performance metrics, including latency, throughput, and resource efficiency.
        \end{itemize}
    \end{itemize}

    \item \textbf{Contribution:}
    \begin{itemize}
        \item This paper proposes a novel framework for resource scaling in Kubernetes environments:
        \begin{itemize}
            \item It combines \textbf{Digital Twin technology} with Multi-Agent Reinforcement Learning (MARL).
            \item The framework accounts for \textbf{microservice interdependencies} and optimizes scaling decisions across the application pipeline.
        \end{itemize}
        \item Key objectives of the proposed framework:
        \begin{itemize}
            \item Bridge the gap between simulation and real-world deployment using a \textbf{Digital Twin}.
            \item Leverage MARL to achieve \textbf{dynamic adaptability} under varying workloads.
            \item Ensure resource efficiency while maintaining \textbf{application health and SLA compliance}.
        \end{itemize}
    \end{itemize}

    \item \textbf{Structure of the Paper:}
    \begin{itemize}
        \item \textbf{Section~\ref{sec:related_work}:} Reviews existing autoscaling techniques and their limitations.
        \item \textbf{Section~\ref{sec:application_deployment_k8s}:} Describes Kubernetes and its resource scaling mechanisms.
        \item \textbf{Section~\ref{sec:k8s-hpa-framework}:} Introduces the k8s-hpa framework and its architecture.
        \item \textbf{Section~\ref{sec:efficient_auto_scaling}:} Details the RL-based approach to autoscaling.
        \item \textbf{Section~\ref{sec:evaluation_setup}:} Explains the evaluation setup and RL training configurations.
        \item \textbf{Section~\ref{sec:results}:} Presents experimental results and key findings.
        \item \textbf{Section~\ref{sec:conclusion}:} Concludes with contributions and future research directions.
    \end{itemize}
\end{itemize}


\section{Related Work}
\label{sec:related_work}
\begin{itemize}
    \item \textbf{Overview:} 
    Recent surveys provide a comprehensive taxonomy of auto-scaling techniques \cite{qu2018autoscaling, santos2021towards}. These approaches can be categorized into five main dimensions:
    \begin{itemize}
        \item Threshold-based techniques.
        \item Queuing models.
        \item Time series analysis.
        \item Control theory-based methods.
        \item Machine learning-based techniques.
    \end{itemize}
    
    \item \textbf{Threshold-based Techniques:}
    \begin{itemize}
        \item Widely adopted in the industry for simplicity and ease of implementation \cite{aws2021autoscaling, kubernetesHPA}.
        \item Characteristics:
        \begin{itemize}
            \item Reactive scaling based on cluster-level metrics (e.g., CPU and memory usage).
            \item Examples: Kubernetes Horizontal Pod Autoscaler (KHPA), Amazon EC2 Auto Scaling \cite{aws2021autoscaling}.
        \end{itemize}
        \item Limitations:
        \begin{itemize}
            \item Dependence on static thresholds, which require manual tuning.
            \item Suboptimal performance due to lack of awareness of microservice interdependencies.
        \end{itemize}
    \end{itemize}

    \item \textbf{Queuing Model-based Methods:}
    \begin{itemize}
        \item Approach:
        \begin{itemize}
            \item Utilizes queuing theory to model service requests and estimate performance metrics (e.g., waiting times).
            \item Focuses on cost reduction while maintaining Service Level Objectives (SLOs) \cite{gergin2014performance, danilo2018hierarchical}.
        \end{itemize}
        \item Limitations:
        \begin{itemize}
            \item Assumes stationary systems with fixed parameters.
            \item Struggles to handle dynamic workloads.
        \end{itemize}
    \end{itemize}
    
    \item \textbf{Time Series Analysis:}
    \begin{itemize}
        \item Approach:
        \begin{itemize}
            \item Workload forecasting using time series methods (e.g., ARIMA, neural networks) \cite{calheiros2014arima, kumar2018neural}.
            \item Scaling actions triggered by predicted metrics.
        \end{itemize}
        \item Limitations:
        \begin{itemize}
            \item Requires predefined thresholds even after forecasting.
            \item Computationally expensive and less effective under highly dynamic workloads.
        \end{itemize}
    \end{itemize}
    
    \item \textbf{Control Theory-based Methods:}
    \begin{itemize}
        \item Approach:
        \begin{itemize}
            \item Employs feedback mechanisms to adjust system behavior dynamically.
            \item Examples include discrete controllers \cite{baresi2016controller} and hybrid control approaches \cite{farokhi2016vertical}.
        \end{itemize}
        \item Strengths:
        \begin{itemize}
            \item Effective for reducing costs and SLA violations.
        \end{itemize}
        \item Limitations:
        \begin{itemize}
            \item Dependence on the accuracy of controller design.
            \item Limited adaptability to highly dynamic environments.
        \end{itemize}
    \end{itemize}
    
    \item \textbf{Machine Learning-based Techniques:}
    \begin{itemize}
        \item Approach:
        \begin{itemize}
            \item Builds predictive models using historical data to estimate resource needs \cite{rossi2019horizontal, rzadka2020autopilot}.
            \item Examples include Google Autopilot and deep reinforcement learning methods \cite{lee2020deep}.
        \end{itemize}
        \item Strengths:
        \begin{itemize}
            \item High adaptability to workload variations.
        \end{itemize}
        \item Limitations:
        \begin{itemize}
            \item Long training times and reliance on sufficient training data.
            \item Poor performance during the learning phase.
        \end{itemize}
    \end{itemize}
    
    \item \textbf{Comparison of Methods:}
    \begin{itemize}
        \item Key observations:
        \begin{itemize}
            \item Threshold-based methods are reactive and simple but lack adaptability.
            \item Queuing and control-theory methods offer structured approaches but struggle with highly dynamic environments.
            \item ML-based methods are flexible but require substantial training and validation.
        \end{itemize}
    \end{itemize}
    
    \item \textbf{Research Gaps:}
    \begin{itemize}
        \item Most existing methods:
        \begin{itemize}
            \item Focus on individual microservices without considering interdependencies.
            \item Prioritize resource metrics (e.g., CPU/memory) over end-to-end performance metrics (e.g., latency).
        \end{itemize}
        \item Opportunities for improvement:
        \begin{itemize}
            \item Integration of microservice interdependency models.
            \item Development of multi-objective optimization frameworks.
        \end{itemize}
    \end{itemize}
\end{itemize}


\section{Application Deployment in Kubernetes (K8s)}
\label{sec:application_deployment_k8s}
\begin{itemize}
    \item \textbf{Overview of Kubernetes (K8s):}
    \begin{itemize}
        \item Kubernetes (K8s) is the most widely adopted platform for orchestrating containerized applications \cite{burns2019kubernetes}.
        \item It automates several lifecycle management processes:
        \begin{itemize}
            \item Deployment of containerized applications.
            \item Scaling resources dynamically based on demand.
            \item Load balancing traffic across multiple containers.
            \item Ensuring fault tolerance and recovery in case of failures.
        \end{itemize}
    \end{itemize}
    
    \item \textbf{Core Concepts of Kubernetes:}
    \begin{itemize}
        \item \textbf{Pod:}
        \begin{itemize}
            \item The smallest deployable unit in Kubernetes.
            \item Represents one or more tightly coupled containers sharing the same execution environment.
            \item Includes shared network, storage, and resource configuration.
        \end{itemize}
        \item \textbf{Deployment:}
        \begin{itemize}
            \item Manages replicas of pods to ensure the desired state is achieved.
            \item Simplifies rolling updates, scaling, and rollback of applications \cite{kubernetesDeployment}.
            \item Example: A web application with multiple replicas for handling increased user traffic.
        \end{itemize}
        \item \textbf{ReplicaSet:}
        \begin{itemize}
            \item Ensures the specified number of pod replicas are running at any time.
            \item Works in conjunction with Deployments for dynamic scaling.
        \end{itemize}
        \item \textbf{Service:}
        \begin{itemize}
            \item Exposes pods to external or internal traffic through a stable network endpoint.
            \item Automatically load balances traffic to healthy pods.
        \end{itemize}
    \end{itemize}
    
    \item \textbf{Scaling in Kubernetes:}
    \begin{itemize}
        \item Kubernetes supports two types of scaling:
        \begin{itemize}
            \item \textbf{Horizontal Scaling:}
            \begin{itemize}
                \item Adds or removes pod replicas to accommodate fluctuating workloads.
                \item Example: Adding more replicas of a web server during peak hours.
            \end{itemize}
            \item \textbf{Vertical Scaling:}
            \begin{itemize}
                \item Increases or decreases the resource allocation (CPU, memory) of individual containers.
                \item Example: Allocating more memory to a database container under heavy query load.
            \end{itemize}
        \end{itemize}
        \item Horizontal scaling is typically preferred for its minimal disruption to running containers.
    \end{itemize}
    
    \item \textbf{Challenges in Current Kubernetes Autoscaling Mechanisms:}
    \begin{itemize}
        \item Kubernetes provides built-in autoscaling policies such as:
        \begin{itemize}
            \item \textbf{Horizontal Pod Autoscaler (HPA):} Scales pods based on metrics like CPU or memory usage \cite{kubernetesHPA}.
            \item \textbf{Vertical Pod Autoscaler (VPA):} Adjusts resource allocation for individual pods \cite{kubernetesVPA}.
        \end{itemize}
        \item Limitations of these approaches:
        \begin{itemize}
            \item Lack of awareness of microservice interdependencies.
            \item Inability to consider application-level performance metrics such as end-to-end latency or throughput.
            \item Reactive nature, which may not handle sudden workload spikes efficiently.
        \end{itemize}
        \item Example scenario:
        \begin{itemize}
            \item A bottleneck in a single microservice can cascade, degrading the entire application's performance.
            \item Existing HPA and VPA policies scale pods independently without accounting for this.
        \end{itemize}
    \end{itemize}
    
    \item \textbf{Implications for Modern Applications:}
    \begin{itemize}
        \item Applications such as Extended Reality (XR) and Industrial IoT (IIoT) demand:
        \begin{itemize}
            \item Low latency for real-time user interactions.
            \item High reliability to prevent service disruptions.
        \end{itemize}
        \item Current autoscaling solutions struggle to meet these stringent requirements.
        \item Addressing these challenges necessitates:
        \begin{itemize}
            \item Incorporating microservice interdependencies into scaling decisions.
            \item Leveraging advanced techniques like Reinforcement Learning for adaptive scaling.
        \end{itemize}
    \end{itemize}
\end{itemize}


\section{The K8s-HPA Framework: System Architecture}
\label{sec:k8s-hpa-framework}

The k8s-hpa framework provides a comprehensive platform to bridge Reinforcement Learning (RL) with Kubernetes-based auto-scaling. This section details the architecture and components of the framework, as well as its modes of operation.

\subsection{Overview of the System}
\begin{itemize}
    \item \textbf{Purpose:}
    \begin{itemize}
        \item Enable RL-based dynamic scaling for Kubernetes microservices.
        \item Address the limitations of traditional Kubernetes Horizontal Pod Autoscaler (KHPA), particularly its lack of consideration for microservice interdependencies.
    \end{itemize}
    \item \textbf{Key Features:}
    \begin{itemize}
        \item Integration with Kubernetes and Prometheus for real-time metrics.
        \item Support for simulation-based and real-cluster evaluations.
        \item Modular design inspired by the OpenAI Gym library.
    \end{itemize}
\end{itemize}

\subsection{System Components}
\begin{itemize}
    \item \textbf{OpenAI Gym Module:}
    \begin{itemize}
        \item Acts as the core environment for RL agent training.
        \item Provides a flexible API for state observation and action execution.
        \item Supports customizable reward functions to guide agent behavior.
    \end{itemize}
    \item \textbf{Deployment Component:}
    \begin{itemize}
        \item Interfaces with the Kubernetes API to:
        \begin{itemize}
            \item Fetch deployment configurations, such as pod counts and resource requests.
            \item Trigger scaling actions for specific deployments.
        \end{itemize}
        \item Retrieves real-time metrics (e.g., CPU usage, memory usage) via Prometheus API.
    \end{itemize}
    \item \textbf{Prometheus Integration:}
    \begin{itemize}
        \item Provides detailed performance monitoring for applications.
        \item Ensures accurate data for latency calculations and resource utilization metrics.
    \end{itemize}
    \item \textbf{Simulator:}
    \begin{itemize}
        \item Enables fast, lightweight training by approximating Kubernetes behavior using pre-collected datasets.
        \item Allows rapid experimentation without incurring the overhead of interacting with a live cluster.
    \end{itemize}
\end{itemize}

\subsection{Modes of Operation}
\begin{itemize}
    \item \textbf{Simulation Mode:}
    \begin{itemize}
        \item Utilizes datasets to simulate real-world Kubernetes environments.
        \item Observations and metrics are derived directly from historical data.
        \item Benefits:
        \begin{itemize}
            \item Faster training times.
            \item Reduced reliance on computationally expensive Kubernetes operations.
        \end{itemize}
    \end{itemize}
    \item \textbf{Cluster Mode:}
    \begin{itemize}
        \item Operates directly on a live Kubernetes cluster.
        \item Fetches real-time metrics from Kubernetes and Prometheus APIs.
        \item Provides high-fidelity evaluation for validating agent performance.
        \item Benefits:
        \begin{itemize}
            \item Ensures compatibility with production Kubernetes deployments.
            \item Captures real-world dynamics, such as network variability and node resource contention.
        \end{itemize}
    \end{itemize}
\end{itemize}

\subsection{Kubernetes Integration Details}
\begin{itemize}
    \item \textbf{Core Concepts:}
    \begin{itemize}
        \item Each microservice is deployed as one or more Kubernetes pods.
        \item Pods are grouped into deployments, which manage replica scaling and resource allocation.
        \end{itemize}
    \item \textbf{Resource Management:}
    \begin{itemize}
        \item Uses Kubernetes resource requests ($\gamma_{d,[r]}$) and limits ($\Gamma_{d,[r]}$):
        \begin{itemize}
            \item Requests represent the minimum resources required by a pod.
            \item Limits define the maximum resources a pod can consume.
        \end{itemize}
        \item Desired replicas are calculated as: $\frac{Overall charge}{Pod Capacity}$
        \item Thresholds for resource utilization ensure optimal performance:
        \begin{itemize}
            \item Default target: 75\% utilization.
        \end{itemize}
    \end{itemize}
    \item \textbf{Deployment Status Information:}
    \begin{itemize}
        \item Real-time data retrieved includes:
        \begin{itemize}
            \item Number of running pods ($R_d$).
            \item Current resource usage ($\rho_{d,[r]}$).
            \item Incoming and outgoing traffic metrics.
        \end{itemize}
    \end{itemize}
\end{itemize}

\subsection{Visualization of Architecture}
\begin{itemize}
    \item Interaction flow between RL agents, the OpenAI Gym module, and Kubernetes.
    \item Integration of Prometheus for metric collection and monitoring.
\end{itemize}

\subsection{Key Advantages of the Framework}
\begin{itemize}
    \item Facilitates research into RL-based auto-scaling by providing a modular and extensible platform.
    \item Simplifies the evaluation of complex microservice applications with interdependencies.
    \item Combines the flexibility of simulation with the accuracy of real-world cluster evaluations.
\end{itemize}


\section{Toward Efficient Auto-Scaling for Complex Applications}
\label{sec:efficient_auto_scaling}

\subsection{Motivation}
Auto-scaling in Kubernetes environments must address several challenges:
\begin{itemize}
    \item Dynamic and fluctuating workloads.
    \item Complex microservice interdependencies.
    \item Trade-offs between resource efficiency and application performance.
\end{itemize}

Existing approaches have significant limitations:
\begin{itemize}
    \item Threshold-based methods often rely on static metrics (e.g., CPU usage) without considering service-level goals.
    \item Machine Learning methods require extensive historical data and are computationally expensive \cite{rossi2019horizontal}.
\end{itemize}

\subsection{Reinforcement Learning (RL) Approach}
Reinforcement Learning (RL) is well-suited for sequential decision-making in dynamic environments. RL agents learn optimal scaling actions through interaction with the environment, guided by well-designed reward functions.

Key advantages of RL include:
\begin{itemize}
    \item Adaptability to evolving workloads.
    \item Ability to incorporate complex interdependencies between microservices.
\end{itemize}

\subsection{Key Components of RL-based Auto-Scaling}

\subsubsection{Observation Space}
The observation space represents the current state of the environment. It includes critical metrics such as:
\begin{itemize}
    \item Number of active pods for each microservice.
    \item Aggregated CPU and memory usage.
    \item Average traffic (incoming and outgoing).
\end{itemize}

For example, an observation state for a single deployment might include:
\begin{itemize}
    \item \texttt{numPods:} Current number of pods.
    \item \texttt{cpuAggr:} Aggregated CPU usage.
    \item \texttt{memAggr:} Aggregated memory usage.
\end{itemize}

\subsubsection{Action Space}
The action space defines all possible scaling actions. A multi-discrete action space allows simultaneous decisions for multiple microservices. Example actions include:
\begin{itemize}
    \item \texttt{DoNothing:} No scaling action.
    \item \texttt{Add-1, Add-2, Add-3:} Scale-out by deploying 1, 2, or 3 pods.
    \item \texttt{Stop-1, Stop-2, Stop-3:} Scale-in by terminating 1, 2, or 3 pods.
\end{itemize}

For instance, the agent might decide:
\begin{itemize}
    \item \texttt{Deployment-1: Add-2}.
    \item \texttt{Deployment-2: Stop-1}.
\end{itemize}

\subsubsection{Reward Functions}
Reward functions guide the RL agent toward optimal scaling actions. Two primary objectives are defined:

\paragraph{Cost Function}
This function rewards the agent for minimizing deployment costs. It is defined as:
\begin{equation}
    \begin{cases} 
        1.0 & \text{if } R_d = \omega_d, \\
        0 & \text{otherwise.}
    \end{cases}
\end{equation}

\paragraph{Latency Function}
This function penalizes high application latency. It is expressed as:
\begin{equation}
    \begin{cases}
        -\Psi_a & \text{if } \Psi_a \leq \tau_a, \\
        -\tau_a & \text{otherwise.}
    \end{cases}
\end{equation}

Trade-offs exist between cost efficiency and performance:
\begin{itemize}
    \item Avoiding over-scaling to prevent resource wastage.
    \item Avoiding under-scaling to prevent performance degradation.
\end{itemize}

\subsubsection{Agents}
The RL agents are implemented using the Stable Baselines 3 library \cite{raffin2019stable}. Two algorithms are evaluated:

\paragraph{Advantage Actor-Critic (A2C)}
\begin{itemize}
    \item Combines policy and value-based methods.
    \item Suitable for environments with deterministic behaviors.
\end{itemize}

\paragraph{Recurrent Proximal Policy Optimization (RPPO)}
\begin{itemize}
    \item Extends PPO with support for recurrent policies (e.g., LSTMs).
    \item Captures temporal dependencies for improved decision-making.
\end{itemize}



\section{Evaluation Setup}
\label{sec:evaluation_setup}
\begin{itemize}
    \item \textbf{Applications:}
    \begin{itemize}
        \item \textbf{Chained Services Cluster (CS):}
        \begin{itemize}
            \item A database application consisting of several interdependent chained services.
            \item Workloads generated using the custom Chained Services-benchmark tool.
            \item Performance metrics include:
            \begin{itemize}
                \item Aggregated CPU and memory usage.
                \item Query response time over 5-minute windows.
                \item Traffic received and transmitted by deployments.
            \end{itemize}
            \item Latency metric $\Psi_{a_1}$:
            \begin{itemize}
                \item Defined as the average response time per query:
                \[
                \Psi_{a_1} = \frac{\text{cs\_commands\_duration\_seconds\_total}[5\text{m}]}{\text{cs\_commands\_processed\_total}[5\text{m}]}
                \]
                \item Latency threshold $\tau_{a_1}$ set at 250 ms.
            \end{itemize}
        \end{itemize}

        \item \textbf{Online Boutique (OB):}
        \begin{itemize}
            \item A microservice-based e-commerce platform consisting of 11 deployments, such as:
            \begin{itemize}
                \item \textit{Frontend, Cart, Checkout, Recommendation,} etc.
            \end{itemize}
            \item Simulated workloads generated using the Locust load testing tool \cite{locust}.
            \item Performance metrics include:
            \begin{itemize}
                \item Aggregated CPU and memory usage for each deployment.
                \item Average response times for specific requests (e.g., \texttt{GET /cart}).
                \item Incoming and outgoing HTTP traffic patterns.
            \end{itemize}
            \item Latency metric $\Psi_{a_2}$:
            \begin{itemize}
                \item Defined as the average response time for the \texttt{GET /cart} request:
                \[
                \Psi_{a_2} = \text{locust\_avg\_response\_time\_GET\_cart}
                \]
                \item Latency threshold $\tau_{a_2}$ set at 3 seconds.
            \end{itemize}
        \end{itemize}
    \end{itemize}

    \item \textbf{Dataset Creation:}
    \begin{itemize}
        \item Data for both applications were collected from real Kubernetes deployments.
        \item \textbf{Chained Services Cluster (CS):}
        \begin{itemize}
            \item Metrics include:
            \begin{itemize}
                \item Number of deployed pods.
                \item Aggregated CPU and memory usage.
                \item Traffic data (received and transmitted).
                \item Query response times.
            \end{itemize}
            \item Dataset enables simulation of realistic workloads for training RL agents.
        \end{itemize}
        \item \textbf{Online Boutique (OB):}
        \begin{itemize}
            \item Data collected via Locust to emulate user interactions with the platform.
            \item Metrics include:
            \begin{itemize}
                \item Pod deployment configurations.
                \item Resource usage (CPU, memory).
                \item HTTP request/response latencies.
            \end{itemize}
        \end{itemize}
        \item Simulation mode utilizes these datasets to provide near-real behavior without direct cluster interaction.
    \end{itemize}

    \item \textbf{Testbed Implementation:}
    \begin{itemize}
        \item \textbf{Hardware Specifications:}
        \begin{itemize}
            \item Processor: 14-core Intel i7-12700H @ 4.7 GHz.
            \item Memory: 16 GB RAM.
            \item Operating System: Ubuntu 20.04.2 LTS.
        \end{itemize}
        \item \textbf{Software Stack:}
        \begin{itemize}
            \item Kubernetes: v1.22.4.
            \item Docker: v20.10.10.
            \item Prometheus: Integrated with Kubernetes API for monitoring.
            \item Python Libraries:
            \begin{itemize}
                \item Gym (v0.21.0) for RL environment setup.
                \item Stable Baselines 3 (v1.5.0) for RL algorithms.
            \end{itemize}
        \end{itemize}
    \end{itemize}

    \item \textbf{RL Training Configuration:}
    \begin{itemize}
        \item Two RL agents were evaluated:
        \begin{itemize}
            \item \textbf{A2C:} A synchronous policy-based algorithm.
            \item \textbf{RPPO:} An enhanced variant of PPO supporting recurrent policies.
        \end{itemize}
        \item Training setup:
        \begin{itemize}
            \item \textbf{Episodes:} Each episode consists of 25 steps.
            \item \textbf{Goals:} Minimize deployment costs or reduce application latency.
        \end{itemize}
        \item Environment-specific details:
        \begin{itemize}
            \item Chained Services Cluster (CS):
            \begin{itemize}
                \item Two deployments.
                \item Observation space: 40 metrics.
                \item Action space: MultiDiscrete(4,15).
            \end{itemize}
            \item Online Boutique (OB):
            \begin{itemize}
                \item Eleven deployments.
                \item Observation space: 110 metrics.
                \item Action space: MultiDiscrete(11,15).
            \end{itemize}
        \end{itemize}
    \end{itemize}
\end{itemize}

\section{Results}
\label{sec:results}

This section presents the outcomes of the training and testing phases, highlighting the performance of RL agents evaluated in simulation and cluster modes. Key performance indicators include accumulated rewards, resource utilization, application latency, and the number of deployed pods.

\subsection{Training Phase}
TODO

\subsection{Testing Phase}
TODO

\subsection{Analysis}

\subsubsection{Effectiveness of RL-Based Methods}
RL agents demonstrated their ability to optimize both cost and latency effectively. For latency-sensitive applications, A2C outperformed RPPO, suggesting that A2C is more suited for such scenarios.

\subsubsection{Simulation vs. Cluster Modes}
Simulation mode provided faster training, enabling agents to explore a broader range of scenarios. Cluster mode validated the practical applicability of trained policies, ensuring their effectiveness in real-world Kubernetes deployments.


\section{Conclusion}
\label{sec:conclusion}

\begin{itemize}
    \item \textbf{Key Achievements:}
    \begin{itemize}
        \item Development of the \textit{k8s-hpa framework}, enabling reinforcement learning (RL)-based auto-scaling for Kubernetes environments.
        \item Integration of Digital Twin concepts with RL to optimize scaling decisions by considering real-world microservice interdependencies.
        \item Demonstration of significant improvements over traditional Kubernetes Horizontal Pod Autoscaler (KHPA):
        \begin{itemize}
            \item \textbf{Resource efficiency:} Achieved at least a 30\% reduction in resource usage.
            \item \textbf{Performance optimization:} Reduced application latency by up to 25\%, maintaining responsiveness under dynamic workloads.
        \end{itemize}
        \item Validation of the framework in both simulation and real-world cluster modes using two complex applications:
        \begin{itemize}
            \item Chained Services Cluster: A cluster comprising interdependent chained services highlighting the framework's ability to handle high-throughput workloads.
            \item Online Boutique: A multi-tier e-commerce application with intricate microservice dependencies.
        \end{itemize}
    \end{itemize}

    \item \textbf{Contributions:}
    \begin{itemize}
        \item \textbf{Framework design:} An open-source RL-based auto-scaling framework integrating Kubernetes and Prometheus APIs for dynamic state monitoring.
        \item \textbf{RL algorithm customization:}
        \begin{itemize}
            \item Use of A2C and RPPO to explore cost and latency optimization goals.
            \item Design of multi-discrete action and observation spaces tailored for Kubernetes deployments.
        \end{itemize}
        \item \textbf{Reward function innovation:}
        \begin{itemize}
            \item Cost-based reward functions to minimize resource wastage.
            \item Latency-based penalties ensuring applications meet stringent performance requirements.
        \end{itemize}
        \item \textbf{Scalability:} Applicability to a wide range of Kubernetes-based applications, demonstrating generalization across different use cases.
    \end{itemize}

    \item \textbf{Future Directions:}
    \begin{itemize}
        \item \textbf{Multi-objective reinforcement learning:}
        \begin{itemize}
            \item Development of RL agents capable of balancing competing objectives, such as cost efficiency, latency reduction, and system resilience.
        \end{itemize}
        \item \textbf{Integration of hybrid scaling:}
        \begin{itemize}
            \item Combining horizontal and vertical scaling strategies to address scenarios with diverse resource constraints.
            \item Exploration of workload-specific scaling policies for specialized applications.
        \end{itemize}
        \item \textbf{Enhanced Digital Twin fidelity:}
        \begin{itemize}
            \item Extending simulation accuracy by integrating more granular metrics and dependencies.
            \item Incorporation of real-time feedback loops for adaptive scaling adjustments.
        \end{itemize}
        \item \textbf{Fault tolerance and reliability:}
        \begin{itemize}
            \item Implementation of mechanisms to mitigate the impact of node failures or resource contention.
            \item Ensuring high availability of services in unpredictable conditions.
        \end{itemize}
        \item \textbf{Broader application domains:}
        \begin{itemize}
            \item Adapting the framework to emerging fields such as edge computing and Federated Learning environments.
            \item Investigating scalability challenges in ultra-low latency applications like XR and IIoT.
        \end{itemize}
    \end{itemize}
\end{itemize}


\section*{References}

% \bibliographystyle{abbrv}
\bibliographystyle{IEEEtran}

\bibliography{references}

\end{document}
